{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70f81fcfa0e44bf2b8ecc59cec7309ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88ffcc03be69443ca79b084ca66bf5a4",
              "IPY_MODEL_b3465724e8894ac59f7da13795a7f20e",
              "IPY_MODEL_5294634afd5f4c84977f7cbcc2853470"
            ],
            "layout": "IPY_MODEL_cf2a13854fc94e5997d55c0d81f2590a"
          }
        },
        "88ffcc03be69443ca79b084ca66bf5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae754e7bef694933ac24e9bbd1480624",
            "placeholder": "​",
            "style": "IPY_MODEL_d8d55f04b2e842c6854406fa74d6f9a1",
            "value": "README.md: "
          }
        },
        "b3465724e8894ac59f7da13795a7f20e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e081423956ac4e2eb805d04af5ba6f7c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f17908302e004ac7808cc9777b055561",
            "value": 1
          }
        },
        "5294634afd5f4c84977f7cbcc2853470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a7165aa89a14c2b892f26112487a9af",
            "placeholder": "​",
            "style": "IPY_MODEL_735d95b0fb124b4a948713586494c6a1",
            "value": " 3.89k/? [00:00&lt;00:00, 257kB/s]"
          }
        },
        "cf2a13854fc94e5997d55c0d81f2590a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae754e7bef694933ac24e9bbd1480624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d55f04b2e842c6854406fa74d6f9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e081423956ac4e2eb805d04af5ba6f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f17908302e004ac7808cc9777b055561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a7165aa89a14c2b892f26112487a9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "735d95b0fb124b4a948713586494c6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d91502221ba2476b8bd6ef3692f1b22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78dc941655b94f8381a08f48e45260e5",
              "IPY_MODEL_04efd86c45c94e39a59ea30acf408c2c",
              "IPY_MODEL_5abc8e9e5eae41fc81b8743b87209404"
            ],
            "layout": "IPY_MODEL_eaf7e1abe31d4d8a8b47529ab215c328"
          }
        },
        "78dc941655b94f8381a08f48e45260e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc7ecb81a5114a3fb6e6c26b22f4ea2f",
            "placeholder": "​",
            "style": "IPY_MODEL_ad113f0a554340b79b344b3082ee765e",
            "value": "data/train-00000-of-00001.parquet: 100%"
          }
        },
        "04efd86c45c94e39a59ea30acf408c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43b73861e57b44e685b52e023f377eaf",
            "max": 191395900,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec61f6480f044e409c87f91bb0fb86db",
            "value": 191395900
          }
        },
        "5abc8e9e5eae41fc81b8743b87209404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d17b040f13634a8fbdf47dfc64a18e69",
            "placeholder": "​",
            "style": "IPY_MODEL_e26dd3d06bf74d5fafa6099d31660e5f",
            "value": " 191M/191M [00:01&lt;00:00, 159MB/s]"
          }
        },
        "eaf7e1abe31d4d8a8b47529ab215c328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7ecb81a5114a3fb6e6c26b22f4ea2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad113f0a554340b79b344b3082ee765e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43b73861e57b44e685b52e023f377eaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec61f6480f044e409c87f91bb0fb86db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d17b040f13634a8fbdf47dfc64a18e69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e26dd3d06bf74d5fafa6099d31660e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b2c2ad89e704cffbbce24c10d3e1ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ffacee06df64a489b8e29b6b35c2054",
              "IPY_MODEL_d3c35d8059054034bf5976b40b4133fc",
              "IPY_MODEL_3edca076eb33482888ff2096c6d61909"
            ],
            "layout": "IPY_MODEL_d22b525d3cd34fc99407919da448b178"
          }
        },
        "5ffacee06df64a489b8e29b6b35c2054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d05e84be2f42b2946bd55faccb0a85",
            "placeholder": "​",
            "style": "IPY_MODEL_db2d60673b2844219d191828ee2ed56b",
            "value": "Generating train split: 100%"
          }
        },
        "d3c35d8059054034bf5976b40b4133fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dad782727db243ebabfd905aba2fc03b",
            "max": 9991,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee24448c0d994c42966fde3dd22762b3",
            "value": 9991
          }
        },
        "3edca076eb33482888ff2096c6d61909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c29929d54d3454fbfa7016297c64459",
            "placeholder": "​",
            "style": "IPY_MODEL_df821934aabc4f8481fc986d3959c0e7",
            "value": " 9991/9991 [00:03&lt;00:00, 1756.61 examples/s]"
          }
        },
        "d22b525d3cd34fc99407919da448b178": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4d05e84be2f42b2946bd55faccb0a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db2d60673b2844219d191828ee2ed56b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dad782727db243ebabfd905aba2fc03b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee24448c0d994c42966fde3dd22762b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c29929d54d3454fbfa7016297c64459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df821934aabc4f8481fc986d3959c0e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "819bb0159f7740ffa51769b7c8c17720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ced93086217a4292b6eb612a59c0bf6e",
              "IPY_MODEL_5f2aeaf51bc841ce8576664077be1155",
              "IPY_MODEL_8439ce979c3746df8d2799d79af0ab66"
            ],
            "layout": "IPY_MODEL_aec16d06a77048158fb9fd43519ea042"
          }
        },
        "ced93086217a4292b6eb612a59c0bf6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26feb3f87cdb400e98d1db0db128f1cd",
            "placeholder": "​",
            "style": "IPY_MODEL_4c76bb74d7ca48d082b2c6cbd861e4f7",
            "value": "Exporting PACS: 100%"
          }
        },
        "5f2aeaf51bc841ce8576664077be1155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9629e9dd934244beb4b7849adff2bc5a",
            "max": 9991,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afe038877f3744d480b4dc8499404a3f",
            "value": 9991
          }
        },
        "8439ce979c3746df8d2799d79af0ab66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca6639ad5fad4f9f902847c9e344cb9b",
            "placeholder": "​",
            "style": "IPY_MODEL_407879211df14a319a1ec3d9155703b0",
            "value": " 9991/9991 [01:36&lt;00:00, 105.86it/s]"
          }
        },
        "aec16d06a77048158fb9fd43519ea042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26feb3f87cdb400e98d1db0db128f1cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c76bb74d7ca48d082b2c6cbd861e4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9629e9dd934244beb4b7849adff2bc5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe038877f3744d480b4dc8499404a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca6639ad5fad4f9f902847c9e344cb9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "407879211df14a319a1ec3d9155703b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 0 — Baseline Training + Spectral Introspection (PACS, ResNet-18)"
      ],
      "metadata": {
        "id": "vDrAutzzqkBJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIljK3tIqWV9",
        "outputId": "af2d9a2d-87a0-4594-83dc-f07be3f7ba99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ===== Colab / Drive setup =====\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/SoMA_PACS\"\n",
        "import os\n",
        "os.makedirs(PROJECT_ROOT, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install datasets huggingface_hub pillow\n"
      ],
      "metadata": {
        "id": "rDyYBQY4voPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "VYUqDWR9vvuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "\n",
        "PACS_ROOT = \"/content/drive/MyDrive/NEW_PACS/PACS\"\n",
        "assert \"PACS\" in PACS_ROOT\n",
        "if not os.path.exists(PACS_ROOT):\n",
        "    os.makedirs(PACS_ROOT, exist_ok=True)\n",
        "    print(\"Created PACS folder.\")\n",
        "else:\n",
        "    print(\"PACS folder exists. Skipping deletion.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTAgGoZI9NQK",
        "outputId": "7253635d-eaad-4f88-90ef-c8e85fd3702f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PACS folder exists. Skipping deletion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from datasets import load_dataset\n",
        "# from tqdm.auto import tqdm\n",
        "# import os\n",
        "\n",
        "# ds = load_dataset(\"flwrlabs/pacs\")\n",
        "\n",
        "# DOMAIN_MAP = {\n",
        "#     \"photo\": \"photo\",\n",
        "#     \"art_painting\": \"art_painting\",\n",
        "#     \"cartoon\": \"cartoon\",\n",
        "#     \"sketch\": \"sketch\",\n",
        "# }\n",
        "\n",
        "# def safe(s):\n",
        "#     return str(s).strip().lower().replace(\" \", \"_\")\n",
        "\n",
        "# # Per-domain counters to ensure unique filenames\n",
        "# counters = {d: { } for d in DOMAIN_MAP.values()}\n",
        "\n",
        "# for ex in tqdm(ds[\"train\"], desc=\"Exporting PACS\"):\n",
        "#     img = ex[\"image\"]\n",
        "\n",
        "#     domain = ex[\"domain\"]\n",
        "#     label  = ex[\"label\"]\n",
        "\n",
        "#     if not isinstance(domain, str):\n",
        "#         domain = ds[\"train\"].features[\"domain\"].int2str(domain)\n",
        "#     if not isinstance(label, str):\n",
        "#         label = ds[\"train\"].features[\"label\"].int2str(label)\n",
        "\n",
        "#     domain = DOMAIN_MAP[safe(domain)]\n",
        "#     label  = safe(label)\n",
        "\n",
        "#     # initialize counter\n",
        "#     counters[domain].setdefault(label, 0)\n",
        "#     idx = counters[domain][label]\n",
        "#     counters[domain][label] += 1\n",
        "\n",
        "#     out_dir = os.path.join(PACS_ROOT, domain, label)\n",
        "#     os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "#     out_path = os.path.join(out_dir, f\"{label}_{idx:05d}.jpg\")\n",
        "#     img.save(out_path, quality=95)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "70f81fcfa0e44bf2b8ecc59cec7309ee",
            "88ffcc03be69443ca79b084ca66bf5a4",
            "b3465724e8894ac59f7da13795a7f20e",
            "5294634afd5f4c84977f7cbcc2853470",
            "cf2a13854fc94e5997d55c0d81f2590a",
            "ae754e7bef694933ac24e9bbd1480624",
            "d8d55f04b2e842c6854406fa74d6f9a1",
            "e081423956ac4e2eb805d04af5ba6f7c",
            "f17908302e004ac7808cc9777b055561",
            "6a7165aa89a14c2b892f26112487a9af",
            "735d95b0fb124b4a948713586494c6a1",
            "d91502221ba2476b8bd6ef3692f1b22a",
            "78dc941655b94f8381a08f48e45260e5",
            "04efd86c45c94e39a59ea30acf408c2c",
            "5abc8e9e5eae41fc81b8743b87209404",
            "eaf7e1abe31d4d8a8b47529ab215c328",
            "bc7ecb81a5114a3fb6e6c26b22f4ea2f",
            "ad113f0a554340b79b344b3082ee765e",
            "43b73861e57b44e685b52e023f377eaf",
            "ec61f6480f044e409c87f91bb0fb86db",
            "d17b040f13634a8fbdf47dfc64a18e69",
            "e26dd3d06bf74d5fafa6099d31660e5f",
            "5b2c2ad89e704cffbbce24c10d3e1ec1",
            "5ffacee06df64a489b8e29b6b35c2054",
            "d3c35d8059054034bf5976b40b4133fc",
            "3edca076eb33482888ff2096c6d61909",
            "d22b525d3cd34fc99407919da448b178",
            "a4d05e84be2f42b2946bd55faccb0a85",
            "db2d60673b2844219d191828ee2ed56b",
            "dad782727db243ebabfd905aba2fc03b",
            "ee24448c0d994c42966fde3dd22762b3",
            "7c29929d54d3454fbfa7016297c64459",
            "df821934aabc4f8481fc986d3959c0e7",
            "819bb0159f7740ffa51769b7c8c17720",
            "ced93086217a4292b6eb612a59c0bf6e",
            "5f2aeaf51bc841ce8576664077be1155",
            "8439ce979c3746df8d2799d79af0ab66",
            "aec16d06a77048158fb9fd43519ea042",
            "26feb3f87cdb400e98d1db0db128f1cd",
            "4c76bb74d7ca48d082b2c6cbd861e4f7",
            "9629e9dd934244beb4b7849adff2bc5a",
            "afe038877f3744d480b4dc8499404a3f",
            "ca6639ad5fad4f9f902847c9e344cb9b",
            "407879211df14a319a1ec3d9155703b0"
          ]
        },
        "id": "gZclgg-4v4Rv",
        "outputId": "e7629020-4f73-4e75-c4f7-d290d2e2e4fd",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70f81fcfa0e44bf2b8ecc59cec7309ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001.parquet:   0%|          | 0.00/191M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d91502221ba2476b8bd6ef3692f1b22a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/9991 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b2c2ad89e704cffbbce24c10d3e1ec1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Exporting PACS:   0%|          | 0/9991 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "819bb0159f7740ffa51769b7c8c17720"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import os\n",
        "\n",
        "for d in [\"sketch\",\"photo\",\"art_painting\",\"cartoon\"]:\n",
        "    ds = datasets.ImageFolder(os.path.join(PACS_ROOT, d))\n",
        "    print(d, ds.class_to_idx)\n",
        "    assert len(ds.class_to_idx) == 7, f\"{d} does not have 7 classes!\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APKKzaX9v7PE",
        "outputId": "ea65a07d-fc54-4ae6-9a3d-083607ce74df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sketch {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "photo {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "art_painting {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "cartoon {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import os\n",
        "\n",
        "def get_class_to_idx(domain):\n",
        "    ds = datasets.ImageFolder(root=os.path.join(PACS_ROOT, domain))\n",
        "    return ds.class_to_idx\n",
        "\n",
        "mappings = {d: get_class_to_idx(d) for d in [\"photo\",\"art_painting\",\"cartoon\",\"sketch\"]}\n",
        "for d, m in mappings.items():\n",
        "    print(d, m)\n",
        "\n",
        "# Compare\n",
        "base = mappings[\"photo\"]\n",
        "for d in mappings:\n",
        "    print(d, \"matches photo:\", mappings[d] == base)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLeEk0W78h3U",
        "outputId": "c9369d32-f56a-4dff-a3f4-f9d4e16565c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "photo {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "art_painting {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "cartoon {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "sketch {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "photo matches photo: True\n",
            "art_painting matches photo: True\n",
            "cartoon matches photo: True\n",
            "sketch matches photo: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Reproducibility =====\n",
        "import random, numpy as np, torch\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ===== Imports =====\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "B1BKeNMtqweA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== PACS paths (edit if needed) =====\n",
        "# PACS_ROOT = \"/content/drive/MyDrive/datasets/PACS\"\n",
        "\n",
        "SOURCE_DOMAINS = [\"photo\", \"art_painting\", \"cartoon\"]\n",
        "TARGET_DOMAIN = \"sketch\"\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n"
      ],
      "metadata": {
        "id": "nyuH-0aNqy94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "vxXugoPcq68T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_loader(domain, tf, shuffle):\n",
        "    ds = datasets.ImageFolder(\n",
        "        root=os.path.join(PACS_ROOT, domain),\n",
        "        transform=tf\n",
        "    )\n",
        "    return DataLoader(ds, batch_size=BATCH_SIZE,\n",
        "                      shuffle=shuffle, num_workers=NUM_WORKERS)\n",
        "\n",
        "train_loaders = [make_loader(d, train_tf, True) for d in SOURCE_DOMAINS]\n",
        "test_loader = make_loader(TARGET_DOMAIN, test_tf, False)\n"
      ],
      "metadata": {
        "id": "ttQEGt7Wq77l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18_FeatureHook(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "        self.backbone.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "        self._features = {}\n",
        "\n",
        "        def make_hook(name):\n",
        "            def hook(module, inp, out):\n",
        "                self._features[name] = out\n",
        "            return hook\n",
        "\n",
        "        # IMPORTANT: include layer1 now\n",
        "        for lname in [\"layer1\", \"layer2\", \"layer3\", \"layer4\"]:\n",
        "            layer = getattr(self.backbone, lname)\n",
        "            for i, block in enumerate(layer):\n",
        "                block.bn2.register_forward_hook(\n",
        "                    make_hook(f\"{lname}.{i}.bn2\")\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self._features = {}\n",
        "        return self.backbone(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "l99DjWkirYoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop (Tier-0 backbone)"
      ],
      "metadata": {
        "id": "7Pi4sspmrclb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "DlRWTqesrZmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(loaders):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total = 0, 0, 0\n",
        "\n",
        "    for loader in loaders:\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            total_correct += (logits.argmax(1) == y).sum().item()\n",
        "            total += x.size(0)\n",
        "\n",
        "    return total_loss / total, total_correct / total\n"
      ],
      "metadata": {
        "id": "CLlKwixlri-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_epoch(loader):\n",
        "    model.eval()\n",
        "    total_correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        total_correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += x.size(0)\n",
        "    return total_correct / total\n"
      ],
      "metadata": {
        "id": "2IX_rRa1rmDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
      ],
      "metadata": {
        "id": "hRN6Rvde_EXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "for ep in range(EPOCHS):\n",
        "    tr_loss, tr_acc = train_epoch(train_loaders)\n",
        "    te_acc = eval_epoch(test_loader)\n",
        "\n",
        "    print(f\"[{ep:02d}] loss={tr_loss:.3f} | src_acc={tr_acc:.3f} | tgt_acc={te_acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p88rTDJTrpo1",
        "outputId": "f40de4a0-4b56-409f-f794-e35982f4c7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00] loss=0.386 | src_acc=0.874 | tgt_acc=0.661\n",
            "[01] loss=0.213 | src_acc=0.929 | tgt_acc=0.632\n",
            "[02] loss=0.144 | src_acc=0.953 | tgt_acc=0.680\n",
            "[03] loss=0.123 | src_acc=0.958 | tgt_acc=0.652\n",
            "[04] loss=0.085 | src_acc=0.972 | tgt_acc=0.725\n",
            "[05] loss=0.058 | src_acc=0.981 | tgt_acc=0.718\n",
            "[06] loss=0.105 | src_acc=0.967 | tgt_acc=0.733\n",
            "[07] loss=0.063 | src_acc=0.982 | tgt_acc=0.708\n",
            "[08] loss=0.061 | src_acc=0.981 | tgt_acc=0.688\n",
            "[09] loss=0.074 | src_acc=0.976 | tgt_acc=0.754\n",
            "[10] loss=0.031 | src_acc=0.990 | tgt_acc=0.722\n",
            "[11] loss=0.028 | src_acc=0.991 | tgt_acc=0.732\n",
            "[12] loss=0.063 | src_acc=0.979 | tgt_acc=0.699\n",
            "[13] loss=0.044 | src_acc=0.986 | tgt_acc=0.708\n",
            "[14] loss=0.038 | src_acc=0.987 | tgt_acc=0.736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save trained backbone"
      ],
      "metadata": {
        "id": "rhPHDh_2k18U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE_PATH = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "\n",
        "torch.save(model.state_dict(), BACKBONE_PATH)\n",
        "print(\"Saved PACS-trained backbone.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEjSvSJ4kQNh",
        "outputId": "2ce6a611-c9e2-45c0-a00e-28b5740a3cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PACS-trained backbone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TIER 0 — SPECTRAL INTROSPECTION"
      ],
      "metadata": {
        "id": "wzZQ1Auvrz-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy.linalg as LA\n",
        "\n",
        "def conv_svd(conv):\n",
        "    # conv.weight: [C_out, C_in, k, k]\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    Cout = W.shape[0]\n",
        "    Wmat = W.reshape(Cout, -1)\n",
        "    U, S, Vt = LA.svd(Wmat, full_matrices=False)\n",
        "    return U, S\n"
      ],
      "metadata": {
        "id": "Yi-RCY5grvg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectra = {}\n",
        "\n",
        "for lname in [\"layer2\", \"layer3\", \"layer4\"]:\n",
        "    for i, block in enumerate(getattr(model.backbone, lname)):\n",
        "        conv = block.conv2\n",
        "        U, S = conv_svd(conv)\n",
        "        spectra[f\"{lname}.{i}\"] = S\n"
      ],
      "metadata": {
        "id": "qjj5dqeur4O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(f\"{PROJECT_ROOT}/tier0_spectra.pkl\", \"wb\") as f:\n",
        "    pickle.dump(spectra, f)\n"
      ],
      "metadata": {
        "id": "pAuAenK-r5Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-0 Feature Statistics (Energy by Spectral Rank)"
      ],
      "metadata": {
        "id": "LFyi2onlsIIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def collect_feature_energy(loader):\n",
        "    model.eval()\n",
        "    energy = {}\n",
        "\n",
        "    for x, _ in loader:\n",
        "        x = x.to(device)\n",
        "        _ = model(x)\n",
        "\n",
        "        for k, feat in model._features.items():\n",
        "            # GAP → channel vector\n",
        "            h = feat.mean(dim=[2,3])  # [B, C]\n",
        "            e = (h**2).mean(0).cpu().numpy()\n",
        "            energy.setdefault(k, []).append(e)\n",
        "\n",
        "    for k in energy:\n",
        "        energy[k] = np.mean(energy[k], axis=0)\n",
        "\n",
        "    return energy\n"
      ],
      "metadata": {
        "id": "_d_MnlDssABX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_energy = collect_feature_energy(train_loaders[0])\n",
        "tgt_energy = collect_feature_energy(test_loader)\n",
        "\n",
        "with open(f\"{PROJECT_ROOT}/tier0_feature_energy.pkl\", \"wb\") as f:\n",
        "    pickle.dump({\"src\": src_energy, \"tgt\": tgt_energy}, f)\n"
      ],
      "metadata": {
        "id": "vEZ4uVIbsMA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saved to Drive\n",
        "\n",
        "- tier0_spectra.pkl → singular values per conv layer\n",
        "\n",
        "- tier0_feature_energy.pkl → channel-wise activation energy (src vs tgt)\n",
        "\n",
        "- trained baseline checkpoint (implicitly in model state)\n",
        "\n",
        "\n",
        "\n",
        "Scientific baseline\n",
        "\n",
        "- no spectral intervention\n",
        "\n",
        "- no leakage\n",
        "\n",
        "- fixed feature definition\n",
        "\n",
        "- BN explicitly visible"
      ],
      "metadata": {
        "id": "4Luz-YI4scu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 1A — Do Minor Singular Subspaces Encode More Domain Information?"
      ],
      "metadata": {
        "id": "WsT1wwp0E6Ev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the minor singular subspace more domain-specific, while the major subspace is more class-semantic?"
      ],
      "metadata": {
        "id": "IMVoG-GiE_wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy.linalg as LA"
      ],
      "metadata": {
        "id": "5dPzmaJQssnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{PROJECT_ROOT}/tier0_spectra.pkl\", \"rb\") as f:\n",
        "    spectra = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "P07aEerqFOQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conv_svd(conv):\n",
        "    \"\"\"\n",
        "    Computes SVD of a conv layer in output-channel space.\n",
        "\n",
        "    conv.weight: [C_out, C_in, k, k]\n",
        "    Returns:\n",
        "        U: [C_out, r]\n",
        "        S: [r]\n",
        "    \"\"\"\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    C_out = W.shape[0]\n",
        "    W_mat = W.reshape(C_out, -1)\n",
        "    U, S, _ = LA.svd(W_mat, full_matrices=False)\n",
        "    return U, S\n",
        "\n"
      ],
      "metadata": {
        "id": "7hpgWpgrFPxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Subspace Bases (Major / Minor / Random)"
      ],
      "metadata": {
        "id": "iGd-88nHFiby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subspace(U, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Returns an orthonormal basis of shape [C_out, r]\n",
        "    \"\"\"\n",
        "    C = U.shape[0]\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    if kind == \"major\":\n",
        "        return U[:, :r]\n",
        "\n",
        "    if kind == \"minor\":\n",
        "        return U[:, -r:]\n",
        "\n",
        "    if kind == \"random\":\n",
        "        Q, _ = np.linalg.qr(rng.standard_normal((C, r)))\n",
        "        return Q\n",
        "\n",
        "    raise ValueError(f\"Unknown subspace kind: {kind}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NMQHtlawFWbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def extract_gap_features(domains, layer_name):\n",
        "    DOMAIN_TO_ID = {\n",
        "        \"photo\": 0,\n",
        "        \"art_painting\": 1,\n",
        "        \"cartoon\": 2,\n",
        "        \"sketch\": 3,\n",
        "    }\n",
        "\n",
        "    X, y_class, y_domain = [], [], []\n",
        "    model.eval()\n",
        "\n",
        "    for domain in domains:\n",
        "        loader = make_loader(domain, test_tf, shuffle=False)\n",
        "        d_id = DOMAIN_TO_ID[domain]\n",
        "\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            _ = model(x)\n",
        "\n",
        "            feat = model._features[f\"{layer_name}.bn2\"]\n",
        "            h = feat.mean(dim=[2, 3]).cpu().numpy()  # GAP\n",
        "\n",
        "            X.append(h)\n",
        "            y_class.append(y.numpy())\n",
        "            y_domain.append(np.full(h.shape[0], d_id))\n",
        "\n",
        "    return (\n",
        "        np.concatenate(X),\n",
        "        np.concatenate(y_class),\n",
        "        np.concatenate(y_domain),\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "qEgRXkPQhart"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectedDataset(Dataset):\n",
        "    def __init__(self, X, y, Usub):\n",
        "        Z = X @ Usub\n",
        "        self.X = torch.tensor(Z, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n"
      ],
      "metadata": {
        "id": "JkqxrCMGFu5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearProbe(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "def train_probe(dataset, num_classes, seed=0, epochs=50, train_frac=0.7):\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    n = len(dataset)\n",
        "    n_train = int(train_frac * n)\n",
        "    n_val = n - n_train\n",
        "\n",
        "    train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
        "    train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "    probe = LinearProbe(dataset.X.shape[1], num_classes).to(device)\n",
        "    opt = torch.optim.Adam(probe.parameters(), lr=1e-2)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss_fn(probe(x), y).backward()\n",
        "            opt.step()\n",
        "\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = probe(x).argmax(1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "biRDpv3ta-H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-1.1: Domain probe (core SoMA assumption)"
      ],
      "metadata": {
        "id": "v3DLcM-Th1HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Tier 1.1: Domain Probing --------\n",
        "\n",
        "layers = {\n",
        "    \"layer2.1\": model.backbone.layer2[1].conv2,\n",
        "    \"layer3.1\": model.backbone.layer3[1].conv2,\n",
        "    \"layer4.1\": model.backbone.layer4[1].conv2,\n",
        "}\n",
        "\n",
        "domains = [\"photo\", \"art_painting\", \"cartoon\", \"sketch\"]\n",
        "ranks = [4, 8, 16]\n",
        "seeds = [0, 1, 2]\n",
        "\n",
        "for layer_name, conv in layers.items():\n",
        "    print(f\"\\n=== Domain Probe @ {layer_name} ===\")\n",
        "\n",
        "    U, S = get_conv_svd(conv)\n",
        "    X, _, y_domain = extract_gap_features(domains, model, layer_name)\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"\\nRank {r}\")\n",
        "        for kind in [\"major\", \"minor\", \"random\"]:\n",
        "            accs = []\n",
        "            for seed in seeds:\n",
        "                Usub = get_subspace(U, kind, r, seed)\n",
        "                ds = ProjectedDataset(X, y_domain, Usub)\n",
        "                accs.append(train_probe(ds, num_classes=4, seed=seed))\n",
        "\n",
        "            print(f\"{kind:>6}: {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n"
      ],
      "metadata": {
        "id": "dg55ktTUFwi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ead5cb-0fa5-4af3-e652-3f7571347170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Domain Probe @ layer2.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.678 ± 0.007\n",
            " minor: 0.672 ± 0.003\n",
            "random: 0.624 ± 0.064\n",
            "\n",
            "Rank 8\n",
            " major: 0.752 ± 0.003\n",
            " minor: 0.750 ± 0.003\n",
            "random: 0.792 ± 0.023\n",
            "\n",
            "Rank 16\n",
            " major: 0.842 ± 0.003\n",
            " minor: 0.823 ± 0.003\n",
            "random: 0.826 ± 0.012\n",
            "\n",
            "=== Domain Probe @ layer3.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.704 ± 0.004\n",
            " minor: 0.547 ± 0.013\n",
            "random: 0.659 ± 0.040\n",
            "\n",
            "Rank 8\n",
            " major: 0.775 ± 0.007\n",
            " minor: 0.669 ± 0.010\n",
            "random: 0.714 ± 0.053\n",
            "\n",
            "Rank 16\n",
            " major: 0.800 ± 0.003\n",
            " minor: 0.731 ± 0.007\n",
            "random: 0.822 ± 0.017\n",
            "\n",
            "=== Domain Probe @ layer4.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.535 ± 0.016\n",
            " minor: 0.478 ± 0.004\n",
            "random: 0.583 ± 0.022\n",
            "\n",
            "Rank 8\n",
            " major: 0.654 ± 0.001\n",
            " minor: 0.528 ± 0.012\n",
            "random: 0.622 ± 0.012\n",
            "\n",
            "Rank 16\n",
            " major: 0.730 ± 0.005\n",
            " minor: 0.603 ± 0.010\n",
            "random: 0.708 ± 0.012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-1.2: Class probe (complementary assumption)"
      ],
      "metadata": {
        "id": "gW8TYkvYF01Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Tier 1.2: Class Probing --------\n",
        "\n",
        "source_domains = [\"photo\", \"art_painting\", \"cartoon\"]\n",
        "\n",
        "for layer_name, conv in layers.items():\n",
        "    print(f\"\\n=== Class Probe @ {layer_name} ===\")\n",
        "\n",
        "    U, S = get_conv_svd(conv)\n",
        "    X, y_class, _ = extract_gap_features(source_domains, model, layer_name)\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"\\nRank {r}\")\n",
        "        for kind in [\"major\", \"minor\", \"random\"]:\n",
        "            accs = []\n",
        "            for seed in seeds:\n",
        "                Usub = get_subspace(U, kind, r, seed)\n",
        "                ds = ProjectedDataset(X, y_class, Usub)\n",
        "                accs.append(train_probe(ds, num_classes=7, seed=seed))\n",
        "\n",
        "            print(f\"{kind:>6}: {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt5vVKjxdieF",
        "outputId": "329f2d70-43c4-4daa-b3d8-b0f0bc20ed2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Class Probe @ layer2.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.245 ± 0.006\n",
            " minor: 0.299 ± 0.002\n",
            "random: 0.288 ± 0.016\n",
            "\n",
            "Rank 8\n",
            " major: 0.336 ± 0.010\n",
            " minor: 0.331 ± 0.004\n",
            "random: 0.361 ± 0.010\n",
            "\n",
            "Rank 16\n",
            " major: 0.402 ± 0.014\n",
            " minor: 0.374 ± 0.005\n",
            "random: 0.422 ± 0.012\n",
            "\n",
            "=== Class Probe @ layer3.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.342 ± 0.012\n",
            " minor: 0.285 ± 0.004\n",
            "random: 0.338 ± 0.012\n",
            "\n",
            "Rank 8\n",
            " major: 0.470 ± 0.002\n",
            " minor: 0.332 ± 0.010\n",
            "random: 0.416 ± 0.018\n",
            "\n",
            "Rank 16\n",
            " major: 0.624 ± 0.005\n",
            " minor: 0.431 ± 0.005\n",
            "random: 0.528 ± 0.013\n",
            "\n",
            "=== Class Probe @ layer4.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.938 ± 0.004\n",
            " minor: 0.471 ± 0.005\n",
            "random: 0.846 ± 0.018\n",
            "\n",
            "Rank 8\n",
            " major: 0.970 ± 0.004\n",
            " minor: 0.704 ± 0.011\n",
            "random: 0.936 ± 0.010\n",
            "\n",
            "Rank 16\n",
            " major: 0.975 ± 0.001\n",
            " minor: 0.821 ± 0.004\n",
            "random: 0.962 ± 0.007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Domain & Class Probe for all layers"
      ],
      "metadata": {
        "id": "ZxBpJHPnFsVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE_PATH = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "\n",
        "model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "\n",
        "state = torch.load(BACKBONE_PATH, map_location=device)\n",
        "model.load_state_dict(state)\n",
        "\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN3jny8JHATp",
        "outputId": "0800642a-914f-4f6b-a89a-c9cdc8db556d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet18_FeatureHook(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing that the right model was loaded"
      ],
      "metadata": {
        "id": "Gh-QR59d0fpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "te_acc = eval_epoch(test_loader)\n",
        "print(\"Target accuracy:\", te_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGU-IgUhHN9l",
        "outputId": "e9fc85b1-0444-4dc8-e6be-cdfcb2427f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target accuracy: 0.7358106388393993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enumerate all conv2 layers in ResNet-18\n",
        "conv_blocks = {}\n",
        "\n",
        "for lname in [\"layer1\", \"layer2\", \"layer3\", \"layer4\"]:\n",
        "    layer = getattr(model.backbone, lname)\n",
        "    for i, block in enumerate(layer):\n",
        "        key = f\"{lname}.{i}\"\n",
        "        conv_blocks[key] = block.conv2\n"
      ],
      "metadata": {
        "id": "83zN9wzeFzrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domains_all = [\"photo\", \"art_painting\", \"cartoon\", \"sketch\"]\n",
        "domains_source = [\"photo\", \"art_painting\", \"cartoon\"]\n",
        "\n",
        "ranks = [4, 8, 16]\n",
        "seeds = [0, 1, 2]\n"
      ],
      "metadata": {
        "id": "UlOnxCa1GJxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===== DOMAIN PROBES (ALL CONV BLOCKS) =====\")\n",
        "\n",
        "for layer_name, conv in conv_blocks.items():\n",
        "    print(f\"\\n=== Domain probe @ {layer_name} ===\")\n",
        "\n",
        "    # SVD of this conv layer\n",
        "    U, S = get_conv_svd(conv)\n",
        "\n",
        "    # Extract GAP features\n",
        "    X, _, y_domain = extract_gap_features(domains_all, layer_name)\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"Rank {r}\")\n",
        "        for kind in [\"major\", \"minor\", \"random\"]:\n",
        "            accs = []\n",
        "            for seed in seeds:\n",
        "                Usub = get_subspace(U, kind, r, seed)\n",
        "                ds = ProjectedDataset(X, y_domain, Usub)\n",
        "                accs.append(train_probe(ds, num_classes=4, seed=seed))\n",
        "\n",
        "            print(f\"{kind:>6}: {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-J705EvGNeR",
        "outputId": "67fe1f7f-9790-4093-cbbe-bc09ebc1e34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== DOMAIN PROBES (ALL CONV BLOCKS) =====\n",
            "\n",
            "=== Domain probe @ layer1.0 ===\n",
            "Rank 4\n",
            " major: 0.749 ± 0.004\n",
            " minor: 0.585 ± 0.016\n",
            "random: 0.656 ± 0.031\n",
            "Rank 8\n",
            " major: 0.772 ± 0.004\n",
            " minor: 0.715 ± 0.017\n",
            "random: 0.730 ± 0.026\n",
            "Rank 16\n",
            " major: 0.843 ± 0.004\n",
            " minor: 0.780 ± 0.003\n",
            "random: 0.828 ± 0.014\n",
            "\n",
            "=== Domain probe @ layer1.1 ===\n",
            "Rank 4\n",
            " major: 0.601 ± 0.010\n",
            " minor: 0.617 ± 0.013\n",
            "random: 0.626 ± 0.076\n",
            "Rank 8\n",
            " major: 0.700 ± 0.009\n",
            " minor: 0.706 ± 0.012\n",
            "random: 0.705 ± 0.030\n",
            "Rank 16\n",
            " major: 0.823 ± 0.002\n",
            " minor: 0.797 ± 0.004\n",
            "random: 0.805 ± 0.029\n",
            "\n",
            "=== Domain probe @ layer2.0 ===\n",
            "Rank 4\n",
            " major: 0.607 ± 0.008\n",
            " minor: 0.733 ± 0.015\n",
            "random: 0.661 ± 0.054\n",
            "Rank 8\n",
            " major: 0.739 ± 0.008\n",
            " minor: 0.775 ± 0.010\n",
            "random: 0.791 ± 0.018\n",
            "Rank 16\n",
            " major: 0.835 ± 0.006\n",
            " minor: 0.836 ± 0.007\n",
            "random: 0.836 ± 0.008\n",
            "\n",
            "=== Domain probe @ layer2.1 ===\n",
            "Rank 4\n",
            " major: 0.678 ± 0.007\n",
            " minor: 0.672 ± 0.003\n",
            "random: 0.624 ± 0.064\n",
            "Rank 8\n",
            " major: 0.752 ± 0.003\n",
            " minor: 0.750 ± 0.003\n",
            "random: 0.792 ± 0.023\n",
            "Rank 16\n",
            " major: 0.842 ± 0.003\n",
            " minor: 0.823 ± 0.003\n",
            "random: 0.826 ± 0.012\n",
            "\n",
            "=== Domain probe @ layer3.0 ===\n",
            "Rank 4\n",
            " major: 0.729 ± 0.008\n",
            " minor: 0.520 ± 0.010\n",
            "random: 0.660 ± 0.046\n",
            "Rank 8\n",
            " major: 0.810 ± 0.006\n",
            " minor: 0.636 ± 0.007\n",
            "random: 0.715 ± 0.022\n",
            "Rank 16\n",
            " major: 0.877 ± 0.009\n",
            " minor: 0.764 ± 0.008\n",
            "random: 0.833 ± 0.014\n",
            "\n",
            "=== Domain probe @ layer3.1 ===\n",
            "Rank 4\n",
            " major: 0.704 ± 0.004\n",
            " minor: 0.547 ± 0.013\n",
            "random: 0.659 ± 0.040\n",
            "Rank 8\n",
            " major: 0.775 ± 0.007\n",
            " minor: 0.669 ± 0.010\n",
            "random: 0.714 ± 0.053\n",
            "Rank 16\n",
            " major: 0.800 ± 0.003\n",
            " minor: 0.731 ± 0.007\n",
            "random: 0.822 ± 0.017\n",
            "\n",
            "=== Domain probe @ layer4.0 ===\n",
            "Rank 4\n",
            " major: 0.599 ± 0.002\n",
            " minor: 0.628 ± 0.015\n",
            "random: 0.606 ± 0.057\n",
            "Rank 8\n",
            " major: 0.651 ± 0.003\n",
            " minor: 0.671 ± 0.008\n",
            "random: 0.685 ± 0.009\n",
            "Rank 16\n",
            " major: 0.783 ± 0.004\n",
            " minor: 0.752 ± 0.004\n",
            "random: 0.783 ± 0.011\n",
            "\n",
            "=== Domain probe @ layer4.1 ===\n",
            "Rank 4\n",
            " major: 0.535 ± 0.016\n",
            " minor: 0.478 ± 0.004\n",
            "random: 0.583 ± 0.022\n",
            "Rank 8\n",
            " major: 0.654 ± 0.001\n",
            " minor: 0.528 ± 0.012\n",
            "random: 0.622 ± 0.012\n",
            "Rank 16\n",
            " major: 0.730 ± 0.005\n",
            " minor: 0.603 ± 0.010\n",
            "random: 0.708 ± 0.012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== CLASS PROBES (ALL CONV BLOCKS) =====\")\n",
        "\n",
        "for layer_name, conv in conv_blocks.items():\n",
        "    print(f\"\\n=== Class probe @ {layer_name} ===\")\n",
        "\n",
        "    # SVD of this conv layer\n",
        "    U, S = get_conv_svd(conv)\n",
        "\n",
        "    # Extract GAP features (source domains only)\n",
        "    X, y_class, _ = extract_gap_features(domains_source, layer_name)\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"Rank {r}\")\n",
        "        for kind in [\"major\", \"minor\", \"random\"]:\n",
        "            accs = []\n",
        "            for seed in seeds:\n",
        "                Usub = get_subspace(U, kind, r, seed)\n",
        "                ds = ProjectedDataset(X, y_class, Usub)\n",
        "                accs.append(train_probe(ds, num_classes=7, seed=seed))\n",
        "\n",
        "            print(f\"{kind:>6}: {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4AmMVb6GU_R",
        "outputId": "6f1e3d6b-b1ac-4dce-cc4c-c9651160274f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== CLASS PROBES (ALL CONV BLOCKS) =====\n",
            "\n",
            "=== Class probe @ layer1.0 ===\n",
            "Rank 4\n",
            " major: 0.299 ± 0.008\n",
            " minor: 0.265 ± 0.007\n",
            "random: 0.278 ± 0.011\n",
            "Rank 8\n",
            " major: 0.332 ± 0.002\n",
            " minor: 0.296 ± 0.003\n",
            "random: 0.326 ± 0.017\n",
            "Rank 16\n",
            " major: 0.394 ± 0.004\n",
            " minor: 0.348 ± 0.013\n",
            "random: 0.366 ± 0.004\n",
            "\n",
            "=== Class probe @ layer1.1 ===\n",
            "Rank 4\n",
            " major: 0.279 ± 0.008\n",
            " minor: 0.236 ± 0.005\n",
            "random: 0.274 ± 0.018\n",
            "Rank 8\n",
            " major: 0.331 ± 0.006\n",
            " minor: 0.292 ± 0.005\n",
            "random: 0.301 ± 0.020\n",
            "Rank 16\n",
            " major: 0.397 ± 0.005\n",
            " minor: 0.363 ± 0.007\n",
            "random: 0.373 ± 0.005\n",
            "\n",
            "=== Class probe @ layer2.0 ===\n",
            "Rank 4\n",
            " major: 0.262 ± 0.012\n",
            " minor: 0.234 ± 0.008\n",
            "random: 0.287 ± 0.017\n",
            "Rank 8\n",
            " major: 0.378 ± 0.009\n",
            " minor: 0.321 ± 0.011\n",
            "random: 0.358 ± 0.019\n",
            "Rank 16\n",
            " major: 0.439 ± 0.007\n",
            " minor: 0.366 ± 0.002\n",
            "random: 0.409 ± 0.005\n",
            "\n",
            "=== Class probe @ layer2.1 ===\n",
            "Rank 4\n",
            " major: 0.245 ± 0.006\n",
            " minor: 0.299 ± 0.002\n",
            "random: 0.288 ± 0.016\n",
            "Rank 8\n",
            " major: 0.336 ± 0.010\n",
            " minor: 0.331 ± 0.004\n",
            "random: 0.361 ± 0.010\n",
            "Rank 16\n",
            " major: 0.402 ± 0.014\n",
            " minor: 0.374 ± 0.005\n",
            "random: 0.422 ± 0.012\n",
            "\n",
            "=== Class probe @ layer3.0 ===\n",
            "Rank 4\n",
            " major: 0.374 ± 0.006\n",
            " minor: 0.265 ± 0.012\n",
            "random: 0.319 ± 0.015\n",
            "Rank 8\n",
            " major: 0.482 ± 0.011\n",
            " minor: 0.344 ± 0.004\n",
            "random: 0.377 ± 0.005\n",
            "Rank 16\n",
            " major: 0.564 ± 0.014\n",
            " minor: 0.407 ± 0.004\n",
            "random: 0.489 ± 0.029\n",
            "\n",
            "=== Class probe @ layer3.1 ===\n",
            "Rank 4\n",
            " major: 0.342 ± 0.012\n",
            " minor: 0.285 ± 0.004\n",
            "random: 0.338 ± 0.012\n",
            "Rank 8\n",
            " major: 0.470 ± 0.002\n",
            " minor: 0.332 ± 0.010\n",
            "random: 0.416 ± 0.018\n",
            "Rank 16\n",
            " major: 0.624 ± 0.005\n",
            " minor: 0.431 ± 0.005\n",
            "random: 0.528 ± 0.013\n",
            "\n",
            "=== Class probe @ layer4.0 ===\n",
            "Rank 4\n",
            " major: 0.546 ± 0.007\n",
            " minor: 0.264 ± 0.012\n",
            "random: 0.390 ± 0.025\n",
            "Rank 8\n",
            " major: 0.810 ± 0.001\n",
            " minor: 0.392 ± 0.012\n",
            "random: 0.583 ± 0.019\n",
            "Rank 16\n",
            " major: 0.928 ± 0.005\n",
            " minor: 0.574 ± 0.001\n",
            "random: 0.727 ± 0.010\n",
            "\n",
            "=== Class probe @ layer4.1 ===\n",
            "Rank 4\n",
            " major: 0.938 ± 0.004\n",
            " minor: 0.471 ± 0.005\n",
            "random: 0.846 ± 0.018\n",
            "Rank 8\n",
            " major: 0.970 ± 0.004\n",
            " minor: 0.704 ± 0.011\n",
            "random: 0.936 ± 0.010\n",
            "Rank 16\n",
            " major: 0.975 ± 0.001\n",
            " minor: 0.821 ± 0.004\n",
            "random: 0.962 ± 0.007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-2: ΔW-Based Domain-Sensitive Subspace Discovery"
      ],
      "metadata": {
        "id": "Ywa9lmNS0G0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy.linalg as LA\n"
      ],
      "metadata": {
        "id": "PC_Z6HLT0JIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GZyeyPNBZ4Q",
        "outputId": "0ba78df1-e5e6-49c7-d8af-02128e2bfe23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load frozen Tier-0 backbone"
      ],
      "metadata": {
        "id": "aGgDrzPa6QZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE_PATH = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "\n",
        "def load_base_model():\n",
        "    model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "    state = torch.load(BACKBONE_PATH, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "_tjKt4hz6NSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze BatchNorm running statistics: This prevents BN from silently encoding domain identity."
      ],
      "metadata": {
        "id": "ES6TFCeR6cPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_bn_stats(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            m.eval()                  # freeze running mean/var\n",
        "            m.weight.requires_grad = True\n",
        "            m.bias.requires_grad = True\n"
      ],
      "metadata": {
        "id": "AK1t6si36ZIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class-balanced domain loader - This ensures ΔW reflects domain, not class imbalance.\n",
        "\n"
      ],
      "metadata": {
        "id": "3SbadGn56f0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def make_balanced_loader(domain, tf, batch_size):\n",
        "    ds = datasets.ImageFolder(\n",
        "        root=os.path.join(PACS_ROOT, domain),\n",
        "        transform=tf\n",
        "    )\n",
        "\n",
        "    # group indices by class\n",
        "    class_to_indices = defaultdict(list)\n",
        "    for idx, (_, y) in enumerate(ds.samples):\n",
        "        class_to_indices[y].append(idx)\n",
        "\n",
        "    # sample equal counts per class\n",
        "    min_count = min(len(v) for v in class_to_indices.values())\n",
        "    balanced_indices = []\n",
        "    for v in class_to_indices.values():\n",
        "        balanced_indices.extend(v[:min_count])\n",
        "\n",
        "    sampler = torch.utils.data.SubsetRandomSampler(balanced_indices)\n",
        "\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        sampler=sampler,\n",
        "        num_workers=NUM_WORKERS\n",
        "    )\n"
      ],
      "metadata": {
        "id": "tKH5qw1W6iG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train single-domain model (light adaptation)"
      ],
      "metadata": {
        "id": "KRJsL0OS6tMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_single_domain(domain, epochs=2, lr=1e-4):\n",
        "    model = load_base_model()\n",
        "    freeze_bn_stats(model)\n",
        "\n",
        "    loader = make_balanced_loader(domain, train_tf, BATCH_SIZE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Note:\n",
        "\n",
        "# Few epochs\n",
        "\n",
        "# Small learning rate\n",
        "\n",
        "# No over-fitting\n",
        "\n",
        "# This captures early domain pressure.\n"
      ],
      "metadata": {
        "id": "NFmjvh_J6tnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract ΔW for a convolutional layer - ΔW lives in exactly the same space as Tier-1 SVD."
      ],
      "metadata": {
        "id": "bEq6f_nj6wBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_delta_W(base_model, adapted_model, conv_path):\n",
        "    \"\"\"\n",
        "    conv_path example: (\"layer3\", 1, \"conv2\")\n",
        "    \"\"\"\n",
        "    base_conv = getattr(\n",
        "        getattr(base_model.backbone, conv_path[0])[conv_path[1]],\n",
        "        conv_path[2]\n",
        "    )\n",
        "\n",
        "    adapt_conv = getattr(\n",
        "        getattr(adapted_model.backbone, conv_path[0])[conv_path[1]],\n",
        "        conv_path[2]\n",
        "    )\n",
        "\n",
        "    W0 = base_conv.weight.detach().cpu().numpy()\n",
        "    W1 = adapt_conv.weight.detach().cpu().numpy()\n",
        "\n",
        "    dW = W1 - W0\n",
        "    C_out = dW.shape[0]\n",
        "    return dW.reshape(C_out, -1)\n"
      ],
      "metadata": {
        "id": "bqoG4KAD681y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collect ΔW across domains"
      ],
      "metadata": {
        "id": "gRO0cBHT7GeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer1 is intentionally excluded because it mostly captures low-level visual primitives (edges, textures), where ΔW is dominated by generic statistics rather than domain-specific adaptation.\n",
        "\n",
        "conv_layers = {\n",
        "    \"layer2.1\": (\"layer2\", 1, \"conv2\"),\n",
        "    \"layer3.1\": (\"layer3\", 1, \"conv2\"),\n",
        "    \"layer4.1\": (\"layer4\", 1, \"conv2\"),\n",
        "}\n",
        "\n",
        "base_model = load_base_model()\n",
        "deltaWs = {k: [] for k in conv_layers}\n",
        "\n",
        "for domain in SOURCE_DOMAINS:\n",
        "    print(f\"Adapting to domain: {domain}\")\n",
        "    adapted = train_single_domain(domain)\n",
        "\n",
        "    for lname, path in conv_layers.items():\n",
        "        dW = extract_delta_W(base_model, adapted, path)\n",
        "        deltaWs[lname].append(dW)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD3T8SFm7G6t",
        "outputId": "556698b7-c64f-40cb-9ad4-07f6e64b3975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapting to domain: photo\n",
            "Adapting to domain: art_painting\n",
            "Adapting to domain: cartoon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "SAVE_PATH = f\"{PROJECT_ROOT}/tier2_deltaWs_source.npz\"\n",
        "\n",
        "np.savez(\n",
        "    SAVE_PATH,\n",
        "    **{\n",
        "        f\"{lname}_{i}\": dW\n",
        "        for lname, dW_list in deltaWs.items()\n",
        "        for i, dW in enumerate(dW_list)\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Saved raw ΔW matrices to:\", SAVE_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DIU2mRishWI",
        "outputId": "6705e785-68a5-400a-b2f9-cf9f4e5469b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved raw ΔW matrices to: /content/drive/MyDrive/SoMA_PACS/tier2_deltaWs_source.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_deltaWs(path, conv_layers, num_domains=3):\n",
        "    data = np.load(path)\n",
        "    deltaWs = {lname: [] for lname in conv_layers}\n",
        "\n",
        "    for lname in conv_layers:\n",
        "        for i in range(num_domains):\n",
        "            deltaWs[lname].append(data[f\"{lname}_{i}\"])\n",
        "\n",
        "    return deltaWs\n",
        "\n",
        "deltaWs = load_deltaWs(\n",
        "    f\"{PROJECT_ROOT}/tier2_deltaWs_source.npz\",\n",
        "    conv_layers,\n",
        "    num_domains=len(SOURCE_DOMAINS)\n",
        ")\n",
        "\n",
        "print(\"Loaded ΔW matrices from disk.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHgEwJLRsmvp",
        "outputId": "2b3a7ff3-a0db-4fa6-fba4-320d1626b771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded ΔW matrices from disk.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez(\n",
        "    f\"{PROJECT_ROOT}/tier2_deltaW_subspaces.npz\",\n",
        "    **{\n",
        "        f\"{lname}_U\": U\n",
        "        for lname, (U, S) in delta_subspaces.items()\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Saved ΔW subspaces.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddVDF9NYsrGz",
        "outputId": "6de8bfc6-75ba-4aeb-e663-9076516d4bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved ΔW subspaces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_deltaW_subspaces(path, conv_layers):\n",
        "    data = np.load(path)\n",
        "    return {\n",
        "        lname: (data[f\"{lname}_U\"], None)\n",
        "        for lname in conv_layers\n",
        "    }\n",
        "\n",
        "delta_subspaces = load_deltaW_subspaces(\n",
        "    f\"{PROJECT_ROOT}/tier2_deltaW_subspaces.npz\",\n",
        "    conv_layers\n",
        ")\n",
        "\n",
        "print(\"Loaded ΔW subspaces.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Q8XXNhssxU",
        "outputId": "5ffd3eeb-12b1-4768-8c1c-9f3f98fbb2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded ΔW subspaces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-2.2 — Empirical Domain-Sensitive Subspace (Channel Space)"
      ],
      "metadata": {
        "id": "i5_587V-MmWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build channel–channel covariance from ΔW"
      ],
      "metadata": {
        "id": "boPFkp4R6DPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_deltaW_channel_subspace(dW_list):\n",
        "    \"\"\"\n",
        "    dW_list: list of ΔW matrices for one layer\n",
        "             each ΔW has shape [C_out, D]\n",
        "\n",
        "    Returns:\n",
        "        U_domain: [C_out, C_out] eigenvectors (descending order)\n",
        "        S_domain: eigenvalues\n",
        "    \"\"\"\n",
        "    C_out = dW_list[0].shape[0]\n",
        "    C = np.zeros((C_out, C_out))\n",
        "\n",
        "    for dW in dW_list:\n",
        "        C += dW @ dW.T   # channel-channel covariance\n",
        "\n",
        "    # Eigen-decomposition (symmetric PSD matrix)\n",
        "    eigvals, eigvecs = np.linalg.eigh(C)\n",
        "\n",
        "    # Sort descending\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "    eigvals = eigvals[idx]\n",
        "    eigvecs = eigvecs[:, idx]\n",
        "\n",
        "    return eigvecs, eigvals\n"
      ],
      "metadata": {
        "id": "OrB-hf-y5goB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct ΔW domain subspaces per layer"
      ],
      "metadata": {
        "id": "XHJie84q6UnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delta_subspaces = {}\n",
        "\n",
        "for lname, dW_list in deltaWs.items():\n",
        "    U_domain, S_domain = build_deltaW_channel_subspace(dW_list)\n",
        "    delta_subspaces[lname] = (U_domain, S_domain)\n",
        "\n",
        "print(\"Constructed empirical ΔW domain-sensitive subspaces.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwtdmJpS6WAJ",
        "outputId": "b671a339-2580-4c84-9bde-30b2131d50db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constructed empirical ΔW domain-sensitive subspaces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E2.3 — ALIGNMENT WITH SoMA MINOR SUBSPACE"
      ],
      "metadata": {
        "id": "vXDqlmSc7ukm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SoMA subspace constructor"
      ],
      "metadata": {
        "id": "kc5Wea0b757J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_soma_subspace(conv, kind, r):\n",
        "#     \"\"\"\n",
        "#     kind: 'minor', 'major', or 'random'\n",
        "#     Returns: [C_out, r] orthonormal basis\n",
        "#     \"\"\"\n",
        "#     W = conv.weight.detach().cpu().numpy()\n",
        "#     C_out = W.shape[0]\n",
        "#     Wmat = W.reshape(C_out, -1)\n",
        "\n",
        "#     U, S, _ = np.linalg.svd(Wmat, full_matrices=False)\n",
        "\n",
        "#     if kind == \"minor\":\n",
        "#         return U[:, -r:]\n",
        "#     if kind == \"major\":\n",
        "#         return U[:, :r]\n",
        "#     if kind == \"random\":\n",
        "#         Q, _ = np.linalg.qr(np.random.randn(C_out, r))\n",
        "#         return Q\n",
        "\n",
        "#     raise ValueError"
      ],
      "metadata": {
        "id": "e1v9raWM7_Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alignment metric computation"
      ],
      "metadata": {
        "id": "8fu_nFtrO1TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_alignment_metrics(U, V):\n",
        "    \"\"\"\n",
        "    U, V: [C_out, r] orthonormal basis matrices\n",
        "\n",
        "    Returns:\n",
        "        mean_angle_deg\n",
        "        overlap (mean cos^2)\n",
        "        projection_energy\n",
        "    \"\"\"\n",
        "    # Cross-subspace matrix\n",
        "    M = U.T @ V   # [r, r]\n",
        "\n",
        "    # Singular values = cos(theta_i)\n",
        "    sv = np.linalg.svd(M, compute_uv=False)\n",
        "    sv = np.clip(sv, -1.0, 1.0)\n",
        "\n",
        "    # Principal angles (degrees)\n",
        "    angles = np.degrees(np.arccos(sv))\n",
        "    mean_angle = angles.mean()\n",
        "\n",
        "    # Overlap (mean squared cosine)\n",
        "    overlap = np.mean(sv ** 2)\n",
        "\n",
        "    # Projection energy (equivalent to overlap)\n",
        "    proj_energy = np.linalg.norm(M, ord=\"fro\") ** 2 / V.shape[1]\n",
        "\n",
        "    return mean_angle, overlap, proj_energy\n"
      ],
      "metadata": {
        "id": "ePq6nYeOMn6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alignment sweep (SoMA vs ΔW)"
      ],
      "metadata": {
        "id": "qmpikXX0O4iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build conv_blocks mapping (SoMA reference layers)\n",
        "\n",
        "conv_layers = {\n",
        "    \"layer2.1\": (\"layer2\", 1, \"conv2\"),\n",
        "    \"layer3.1\": (\"layer3\", 1, \"conv2\"),\n",
        "    \"layer4.1\": (\"layer4\", 1, \"conv2\"),\n",
        "}\n",
        "base_model = load_base_model()\n",
        "conv_blocks = {\n",
        "    \"layer2.1\": base_model.backbone.layer2[1].conv2,\n",
        "    \"layer3.1\": base_model.backbone.layer3[1].conv2,\n",
        "    \"layer4.1\": base_model.backbone.layer4[1].conv2,\n",
        "}\n",
        "\n",
        "print(\"Defined conv_blocks:\", list(conv_blocks.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bWXt9OqNuCj",
        "outputId": "0b2df095-9688-4a5f-b825-0144277ed923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined conv_blocks: ['layer2.1', 'layer3.1', 'layer4.1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = [2, 4, 8, 16]\n",
        "n_random = 10\n",
        "\n",
        "alignment_results = {}\n",
        "\n",
        "for lname, (U_domain, S_domain) in delta_subspaces.items():\n",
        "    print(f\"\\n=== Alignment @ {lname} ===\")\n",
        "    alignment_results[lname] = {}\n",
        "\n",
        "    conv = conv_blocks[lname]\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"\\nRank {r}\")\n",
        "        V = U_domain[:, :r]   # empirical ΔW subspace\n",
        "\n",
        "        alignment_results[lname][r] = {}\n",
        "\n",
        "        for kind in [\"minor\", \"major\", \"random\"]:\n",
        "            angles, overlaps, energies = [], [], []\n",
        "\n",
        "            for seed in range(n_random):\n",
        "                np.random.seed(seed)\n",
        "                U = get_soma_subspace(conv, kind, r)\n",
        "\n",
        "                mean_angle, overlap, proj_energy = compute_alignment_metrics(U, V)\n",
        "\n",
        "                angles.append(mean_angle)\n",
        "                overlaps.append(overlap)\n",
        "                energies.append(proj_energy)\n",
        "\n",
        "            alignment_results[lname][r][kind] = {\n",
        "                \"mean_angle_deg\": (np.mean(angles), np.std(angles)),\n",
        "                \"overlap\": (np.mean(overlaps), np.std(overlaps)),\n",
        "                \"proj_energy\": (np.mean(energies), np.std(energies)),\n",
        "            }\n",
        "\n",
        "            print(\n",
        "                f\"{kind:>6} | \"\n",
        "                f\"angle={np.mean(angles):.2f}° ± {np.std(angles):.2f} | \"\n",
        "                f\"overlap={np.mean(overlaps):.3f} ± {np.std(overlaps):.3f} | \"\n",
        "                f\"energy={np.mean(energies):.3f} ± {np.std(energies):.3f}\"\n",
        "            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xt7dxH-O6sP",
        "outputId": "303e593b-8cfb-476b-981f-a222e10e8261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Alignment @ layer2.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=88.70° ± 0.00 | overlap=0.001 ± 0.000 | energy=0.001 ± 0.000\n",
            " major | angle=71.25° ± 0.00 | overlap=0.123 ± 0.000 | energy=0.123 ± 0.000\n",
            "random | angle=84.26° ± 2.56 | overlap=0.014 ± 0.011 | energy=0.014 ± 0.011\n",
            "\n",
            "Rank 4\n",
            " minor | angle=84.59° ± 0.00 | overlap=0.012 ± 0.000 | energy=0.012 ± 0.000\n",
            " major | angle=75.95° ± 0.00 | overlap=0.085 ± 0.000 | energy=0.085 ± 0.000\n",
            "random | angle=81.61° ± 1.29 | overlap=0.031 ± 0.009 | energy=0.031 ± 0.009\n",
            "\n",
            "Rank 8\n",
            " minor | angle=82.35° ± 0.00 | overlap=0.024 ± 0.000 | energy=0.024 ± 0.000\n",
            " major | angle=70.81° ± 0.00 | overlap=0.146 ± 0.000 | energy=0.146 ± 0.000\n",
            "random | angle=77.92° ± 1.28 | overlap=0.061 ± 0.012 | energy=0.061 ± 0.012\n",
            "\n",
            "Rank 16\n",
            " minor | angle=78.92° ± 0.00 | overlap=0.051 ± 0.000 | energy=0.051 ± 0.000\n",
            " major | angle=61.52° ± 0.00 | overlap=0.271 ± 0.000 | energy=0.271 ± 0.000\n",
            "random | angle=72.06° ± 0.96 | overlap=0.125 ± 0.012 | energy=0.125 ± 0.012\n",
            "\n",
            "=== Alignment @ layer3.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=87.03° ± 0.00 | overlap=0.003 ± 0.000 | energy=0.003 ± 0.000\n",
            " major | angle=82.30° ± 0.00 | overlap=0.022 ± 0.000 | energy=0.022 ± 0.000\n",
            "random | angle=85.58° ± 0.98 | overlap=0.008 ± 0.003 | energy=0.008 ± 0.003\n",
            "\n",
            "Rank 4\n",
            " minor | angle=85.59° ± 0.00 | overlap=0.006 ± 0.000 | energy=0.006 ± 0.000\n",
            " major | angle=77.32° ± 0.00 | overlap=0.068 ± 0.000 | energy=0.068 ± 0.000\n",
            "random | angle=84.36° ± 0.96 | overlap=0.015 ± 0.005 | energy=0.015 ± 0.005\n",
            "\n",
            "Rank 8\n",
            " minor | angle=85.12° ± 0.00 | overlap=0.010 ± 0.000 | energy=0.010 ± 0.000\n",
            " major | angle=66.69° ± 0.00 | overlap=0.203 ± 0.000 | energy=0.203 ± 0.000\n",
            "random | angle=81.19° ± 0.76 | overlap=0.033 ± 0.005 | energy=0.033 ± 0.005\n",
            "\n",
            "Rank 16\n",
            " minor | angle=82.40° ± 0.00 | overlap=0.025 ± 0.000 | energy=0.025 ± 0.000\n",
            " major | angle=59.98° ± 0.00 | overlap=0.293 ± 0.000 | energy=0.293 ± 0.000\n",
            "random | angle=77.89° ± 0.33 | overlap=0.061 ± 0.004 | energy=0.061 ± 0.004\n",
            "\n",
            "=== Alignment @ layer4.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=89.54° ± 0.00 | overlap=0.000 ± 0.000 | energy=0.000 ± 0.000\n",
            " major | angle=61.46° ± 0.00 | overlap=0.255 ± 0.000 | energy=0.255 ± 0.000\n",
            "random | angle=87.05° ± 0.94 | overlap=0.005 ± 0.003 | energy=0.005 ± 0.003\n",
            "\n",
            "Rank 4\n",
            " minor | angle=89.50° ± 0.00 | overlap=0.000 ± 0.000 | energy=0.000 ± 0.000\n",
            " major | angle=37.02° ± 0.00 | overlap=0.646 ± 0.000 | energy=0.646 ± 0.000\n",
            "random | angle=86.04° ± 1.08 | overlap=0.007 ± 0.003 | energy=0.007 ± 0.003\n",
            "\n",
            "Rank 8\n",
            " minor | angle=88.71° ± 0.00 | overlap=0.001 ± 0.000 | energy=0.001 ± 0.000\n",
            " major | angle=24.99° ± 0.00 | overlap=0.801 ± 0.000 | energy=0.801 ± 0.000\n",
            "random | angle=83.85° ± 0.32 | overlap=0.016 ± 0.001 | energy=0.016 ± 0.001\n",
            "\n",
            "Rank 16\n",
            " minor | angle=86.35° ± 0.00 | overlap=0.007 ± 0.000 | energy=0.007 ± 0.000\n",
            " major | angle=47.10° ± 0.00 | overlap=0.478 ± 0.000 | energy=0.478 ± 0.000\n",
            "random | angle=81.47° ± 0.31 | overlap=0.031 ± 0.002 | energy=0.031 ± 0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Optional) Save results"
      ],
      "metadata": {
        "id": "dQf_z8v1PJ2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "for lname, layer_data in alignment_results.items():\n",
        "    for r, r_data in layer_data.items():\n",
        "        for kind, metrics in r_data.items():\n",
        "            rows.append({\n",
        "                \"layer\": lname,\n",
        "                \"rank\": r,\n",
        "                \"subspace\": kind,\n",
        "                \"mean_angle_deg\": metrics[\"mean_angle_deg\"][0],\n",
        "                \"angle_std\": metrics[\"mean_angle_deg\"][1],\n",
        "                \"overlap\": metrics[\"overlap\"][0],\n",
        "                \"overlap_std\": metrics[\"overlap\"][1],\n",
        "                \"proj_energy\": metrics[\"proj_energy\"][0],\n",
        "                \"energy_std\": metrics[\"proj_energy\"][1],\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(f\"{PROJECT_ROOT}/tier2_alignment_metrics.csv\", index=False)\n",
        "\n",
        "print(\"Saved Tier-2.3 alignment results.\")"
      ],
      "metadata": {
        "id": "4uVbQ6H7uU-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Adapting baseline model to Sketch domain...\")\n",
        "adapted_sketch = train_single_domain(\"sketch\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJHKeetOiSO3",
        "outputId": "8bee406f-4609-4726-aecb-17310a59dcd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapting baseline model to Sketch domain...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deltaWs_sketch = {}\n",
        "\n",
        "for lname, path in conv_layers.items():\n",
        "    dW = extract_delta_W(base_model, adapted_sketch, path)\n",
        "    deltaWs_sketch[lname] = dW\n",
        "    print(f\"{lname}: ΔW shape = {dW.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVwJfxVGiSwz",
        "outputId": "75ec2764-27b2-4b41-9b20-709e6a38ab41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer2.1: ΔW shape = (128, 1152)\n",
            "layer3.1: ΔW shape = (256, 2304)\n",
            "layer4.1: ΔW shape = (512, 4608)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Sketch ΔW into a subspace"
      ],
      "metadata": {
        "id": "NTpNbMSZihyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_deltaW_subspace(dW, r):\n",
        "    \"\"\"\n",
        "    Convert ΔW matrix into rank-r subspace via SVD.\n",
        "    \"\"\"\n",
        "    U, S, _ = np.linalg.svd(dW, full_matrices=False)\n",
        "    return U[:, :r]\n"
      ],
      "metadata": {
        "id": "79o_VSLDie6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Align Sketch ΔW subspace with SoMA subspaces"
      ],
      "metadata": {
        "id": "e_LUenC9ir4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = [2, 4, 8, 16]\n",
        "n_random = 10\n",
        "\n",
        "print(\"\\n=== Sketch ΔW vs SoMA Subspace Alignment ===\")\n",
        "\n",
        "sketch_alignment_results = {}\n",
        "\n",
        "for lname in conv_layers:\n",
        "    print(f\"\\n=== Layer {lname} ===\")\n",
        "    sketch_alignment_results[lname] = {}\n",
        "\n",
        "    dW = deltaWs_sketch[lname]\n",
        "    conv = conv_blocks[lname]\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"\\nRank {r}\")\n",
        "        sketch_alignment_results[lname][r] = {}\n",
        "\n",
        "        # Sketch ΔW subspace\n",
        "        U_sketch = get_deltaW_subspace(dW, r)\n",
        "\n",
        "        for kind in [\"minor\", \"major\", \"random\"]:\n",
        "            angles, overlaps, energies = [], [], []\n",
        "\n",
        "            for seed in range(n_random):\n",
        "                np.random.seed(seed)\n",
        "\n",
        "                # SoMA subspace\n",
        "                U_soma = get_soma_subspace(conv, kind, r)\n",
        "\n",
        "                mean_angle, overlap, proj_energy = compute_alignment_metrics(\n",
        "                    U_soma, U_sketch\n",
        "                )\n",
        "\n",
        "                angles.append(mean_angle)\n",
        "                overlaps.append(overlap)\n",
        "                energies.append(proj_energy)\n",
        "\n",
        "            sketch_alignment_results[lname][r][kind] = {\n",
        "                \"mean_angle_deg\": (np.mean(angles), np.std(angles)),\n",
        "                \"overlap\": (np.mean(overlaps), np.std(overlaps)),\n",
        "                \"proj_energy\": (np.mean(energies), np.std(energies)),\n",
        "            }\n",
        "\n",
        "            print(\n",
        "                f\"{kind:>6} | \"\n",
        "                f\"angle={np.mean(angles):.2f}° ± {np.std(angles):.2f} | \"\n",
        "                f\"overlap={np.mean(overlaps):.3f} ± {np.std(overlaps):.3f} | \"\n",
        "                f\"energy={np.mean(energies):.3f} ± {np.std(energies):.3f}\"\n",
        "            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m3r3ymqimvI",
        "outputId": "0393dd77-6625-49f0-d28d-b5a14cdf7142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sketch ΔW vs SoMA Subspace Alignment ===\n",
            "\n",
            "=== Layer layer2.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=86.56° ± 0.00 | overlap=0.006 ± 0.000 | energy=0.006 ± 0.000\n",
            " major | angle=80.82° ± 0.00 | overlap=0.035 ± 0.000 | energy=0.035 ± 0.000\n",
            "random | angle=85.68° ± 1.70 | overlap=0.008 ± 0.006 | energy=0.008 ± 0.006\n",
            "\n",
            "Rank 4\n",
            " minor | angle=84.65° ± 0.00 | overlap=0.014 ± 0.000 | energy=0.014 ± 0.000\n",
            " major | angle=79.65° ± 0.00 | overlap=0.052 ± 0.000 | energy=0.052 ± 0.000\n",
            "random | angle=81.75° ± 1.56 | overlap=0.030 ± 0.011 | energy=0.030 ± 0.011\n",
            "\n",
            "Rank 8\n",
            " minor | angle=81.52° ± 0.00 | overlap=0.033 ± 0.000 | energy=0.033 ± 0.000\n",
            " major | angle=72.98° ± 0.00 | overlap=0.119 ± 0.000 | energy=0.119 ± 0.000\n",
            "random | angle=77.64° ± 1.45 | overlap=0.065 ± 0.014 | energy=0.065 ± 0.014\n",
            "\n",
            "Rank 16\n",
            " minor | angle=77.17° ± 0.00 | overlap=0.072 ± 0.000 | energy=0.072 ± 0.000\n",
            " major | angle=64.74° ± 0.00 | overlap=0.224 ± 0.000 | energy=0.224 ± 0.000\n",
            "random | angle=72.19° ± 0.45 | overlap=0.123 ± 0.005 | energy=0.123 ± 0.005\n",
            "\n",
            "=== Layer layer3.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=85.05° ± 0.00 | overlap=0.008 ± 0.000 | energy=0.008 ± 0.000\n",
            " major | angle=85.64° ± 0.00 | overlap=0.008 ± 0.000 | energy=0.008 ± 0.000\n",
            "random | angle=86.47° ± 1.57 | overlap=0.006 ± 0.005 | energy=0.006 ± 0.005\n",
            "\n",
            "Rank 4\n",
            " minor | angle=86.65° ± 0.00 | overlap=0.006 ± 0.000 | energy=0.006 ± 0.000\n",
            " major | angle=81.91° ± 0.00 | overlap=0.031 ± 0.000 | energy=0.031 ± 0.000\n",
            "random | angle=83.73° ± 1.41 | overlap=0.018 ± 0.007 | energy=0.018 ± 0.007\n",
            "\n",
            "Rank 8\n",
            " minor | angle=84.73° ± 0.00 | overlap=0.013 ± 0.000 | energy=0.013 ± 0.000\n",
            " major | angle=73.54° ± 0.00 | overlap=0.109 ± 0.000 | energy=0.109 ± 0.000\n",
            "random | angle=81.43° ± 0.58 | overlap=0.031 ± 0.005 | energy=0.031 ± 0.005\n",
            "\n",
            "Rank 16\n",
            " minor | angle=82.21° ± 0.00 | overlap=0.026 ± 0.000 | energy=0.026 ± 0.000\n",
            " major | angle=63.72° ± 0.00 | overlap=0.235 ± 0.000 | energy=0.235 ± 0.000\n",
            "random | angle=77.59° ± 0.72 | overlap=0.063 ± 0.006 | energy=0.063 ± 0.006\n",
            "\n",
            "=== Layer layer4.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=89.81° ± 0.00 | overlap=0.000 ± 0.000 | energy=0.000 ± 0.000\n",
            " major | angle=63.69° ± 0.00 | overlap=0.271 ± 0.000 | energy=0.271 ± 0.000\n",
            "random | angle=86.92° ± 0.80 | overlap=0.004 ± 0.002 | energy=0.004 ± 0.002\n",
            "\n",
            "Rank 4\n",
            " minor | angle=89.34° ± 0.00 | overlap=0.000 ± 0.000 | energy=0.000 ± 0.000\n",
            " major | angle=45.64° ± 0.00 | overlap=0.512 ± 0.000 | energy=0.512 ± 0.000\n",
            "random | angle=85.87° ± 0.78 | overlap=0.007 ± 0.003 | energy=0.007 ± 0.003\n",
            "\n",
            "Rank 8\n",
            " minor | angle=88.17° ± 0.00 | overlap=0.002 ± 0.000 | energy=0.002 ± 0.000\n",
            " major | angle=28.21° ± 0.00 | overlap=0.765 ± 0.000 | energy=0.765 ± 0.000\n",
            "random | angle=83.60° ± 0.43 | overlap=0.017 ± 0.002 | energy=0.017 ± 0.002\n",
            "\n",
            "Rank 16\n",
            " minor | angle=86.14° ± 0.00 | overlap=0.008 ± 0.000 | energy=0.008 ± 0.000\n",
            " major | angle=48.01° ± 0.00 | overlap=0.472 ± 0.000 | energy=0.472 ± 0.000\n",
            "random | angle=81.40° ± 0.47 | overlap=0.031 ± 0.003 | energy=0.031 ± 0.003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if Sketch's ΔW aligns with 3-domain ΔW subspace"
      ],
      "metadata": {
        "id": "MyGin4tUpeOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def project_matrix_onto_subspace(U, dW):\n",
        "    \"\"\"\n",
        "    U  : [C_out, r] subspace basis (3-domain ΔW subspace)\n",
        "    dW : [C_out, D] Sketch ΔW matrix\n",
        "\n",
        "    Returns:\n",
        "        projection_energy (fraction of ΔW energy captured)\n",
        "        effective_angle_deg\n",
        "    \"\"\"\n",
        "    # Project ΔW onto subspace\n",
        "    P = U.T @ dW\n",
        "\n",
        "    proj_energy = (np.linalg.norm(P, ord=\"fro\") ** 2) / \\\n",
        "                  (np.linalg.norm(dW, ord=\"fro\") ** 2)\n",
        "\n",
        "    # Effective angle (for interpretability)\n",
        "    eff_angle = np.degrees(\n",
        "        np.arccos(np.sqrt(np.clip(proj_energy, 0.0, 1.0)))\n",
        "    )\n",
        "\n",
        "    return proj_energy, eff_angle\n"
      ],
      "metadata": {
        "id": "ymnO12Cgpg6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = [2, 4, 8, 16]\n",
        "\n",
        "print(\"\\n=== Sketch ΔW vs 3-Domain ΔW Subspace (Approach B) ===\")\n",
        "\n",
        "sketch_vs_deltaW_results = {}\n",
        "\n",
        "for lname, (U_domain, S_domain) in delta_subspaces.items():\n",
        "    print(f\"\\n=== Layer {lname} ===\")\n",
        "    sketch_vs_deltaW_results[lname] = {}\n",
        "\n",
        "    dW_sketch = deltaWs_sketch[lname]\n",
        "    C_out = dW_sketch.shape[0]\n",
        "\n",
        "    for r in ranks:\n",
        "        U_sub = U_domain[:, :r]\n",
        "\n",
        "        proj_energy, eff_angle = project_matrix_onto_subspace(\n",
        "            U_sub, dW_sketch\n",
        "        )\n",
        "\n",
        "        random_baseline = r / C_out\n",
        "\n",
        "        sketch_vs_deltaW_results[lname][r] = {\n",
        "            \"projection_energy\": proj_energy,\n",
        "            \"effective_angle_deg\": eff_angle,\n",
        "            \"random_baseline\": random_baseline\n",
        "        }\n",
        "\n",
        "        print(\n",
        "            f\"Rank {r:2d} | \"\n",
        "            f\"proj={proj_energy:.3f} | \"\n",
        "            f\"angle={eff_angle:.1f}° | \"\n",
        "            f\"random≈{random_baseline:.3f}\"\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EnU_vqdprpE",
        "outputId": "57c1c648-f239-43f1-8e25-22e988c5e794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sketch ΔW vs 3-Domain ΔW Subspace (Approach B) ===\n",
            "\n",
            "=== Layer layer2.1 ===\n",
            "Rank  2 | proj=0.041 | angle=78.4° | random≈0.016\n",
            "Rank  4 | proj=0.097 | angle=71.8° | random≈0.031\n",
            "Rank  8 | proj=0.173 | angle=65.4° | random≈0.062\n",
            "Rank 16 | proj=0.289 | angle=57.5° | random≈0.125\n",
            "\n",
            "=== Layer layer3.1 ===\n",
            "Rank  2 | proj=0.039 | angle=78.6° | random≈0.008\n",
            "Rank  4 | proj=0.083 | angle=73.3° | random≈0.016\n",
            "Rank  8 | proj=0.154 | angle=66.9° | random≈0.031\n",
            "Rank 16 | proj=0.256 | angle=59.6° | random≈0.062\n",
            "\n",
            "=== Layer layer4.1 ===\n",
            "Rank  2 | proj=0.208 | angle=62.8° | random≈0.004\n",
            "Rank  4 | proj=0.482 | angle=46.0° | random≈0.008\n",
            "Rank  8 | proj=0.666 | angle=35.3° | random≈0.016\n",
            "Rank 16 | proj=0.708 | angle=32.7° | random≈0.031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 3.1 — Subspace Swap Experiment"
      ],
      "metadata": {
        "id": "7E_dunLL0JFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np, random\n",
        "\n",
        "def set_seed(seed=0):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(0)\n"
      ],
      "metadata": {
        "id": "4IN9DuBH0Kyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Path to the baseline (source-trained) ResNet-18\n",
        "base_model_path = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "\n",
        "def load_baseline_model(path):\n",
        "    model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "    state = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7UJnYVkD0NVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_soma_subspace(conv, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Returns an orthonormal basis U [C_out, r]\n",
        "    for the requested subspace of conv2 weights.\n",
        "    \"\"\"\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    C_out = W.shape[0]\n",
        "    Wmat = W.reshape(C_out, -1)\n",
        "\n",
        "    U, S, _ = np.linalg.svd(Wmat, full_matrices=False)\n",
        "\n",
        "    if kind == \"major\":\n",
        "        return U[:, :r]\n",
        "\n",
        "    if kind == \"minor\":\n",
        "        return U[:, -r:]\n",
        "\n",
        "    if kind == \"middle\":\n",
        "        start = (C_out // 2) - (r // 2)\n",
        "        return U[:, start:start + r]\n",
        "\n",
        "    if kind == \"random\":\n",
        "        rng = np.random.default_rng(seed)\n",
        "        Q, _ = np.linalg.qr(rng.standard_normal((C_out, r)))\n",
        "        return Q\n",
        "\n",
        "    raise ValueError(f\"Unknown subspace kind: {kind}\")\n"
      ],
      "metadata": {
        "id": "jxHI4Ajp7-y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Tier-3 Data Loaders =====\n",
        "\n",
        "train_loaders = [\n",
        "    make_balanced_loader(\"photo\", train_tf, BATCH_SIZE),\n",
        "    make_balanced_loader(\"art_painting\", train_tf, BATCH_SIZE),\n",
        "    make_balanced_loader(\"cartoon\", train_tf, BATCH_SIZE),\n",
        "]\n",
        "\n",
        "test_loader = make_loader(\"sketch\", test_tf, shuffle=False)\n",
        "\n",
        "print(\"Tier-3 loaders ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1dKPart2F0s",
        "outputId": "534acdc4-1cac-4b83-fcb2-b51e16c0f3d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tier-3 loaders ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient projection hook (core mechanism)"
      ],
      "metadata": {
        "id": "mPkNYPl70b-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def register_gradient_projection(param, U_np):\n",
        "    \"\"\"\n",
        "    param : torch.nn.Parameter\n",
        "    U_np  : numpy array [C_out, r]\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert once, outside the hook\n",
        "    U = torch.tensor(U_np, dtype=torch.float32, device=param.device)\n",
        "    U.requires_grad_(False)\n",
        "\n",
        "    def hook(grad):\n",
        "        # grad: [C_out, C_in, k, k]\n",
        "        g = grad.view(grad.shape[0], -1)     # [C_out, D]\n",
        "        g_proj = U @ (U.T @ g)               # projection in torch\n",
        "        return g_proj.view_as(grad)\n",
        "\n",
        "    param.register_hook(hook)\n",
        "\n"
      ],
      "metadata": {
        "id": "0QDnj23a0Qgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply subspace constraint to selected layers"
      ],
      "metadata": {
        "id": "LUzdQ18z0fp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_subspace_constraints(model, conv_layers, subspaces):\n",
        "    \"\"\"\n",
        "    subspaces: {layer_name: U (C_out x r)}\n",
        "    \"\"\"\n",
        "    for lname, U in subspaces.items():\n",
        "        layer, idx, conv_name = conv_layers[lname]\n",
        "        conv = getattr(getattr(model.backbone, layer)[idx], conv_name)\n",
        "        register_gradient_projection(conv.weight, U)\n"
      ],
      "metadata": {
        "id": "K6HiUJaM0UtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop (shared across all variants)"
      ],
      "metadata": {
        "id": "bIlCNxDk0kjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_constraints(\n",
        "    model,\n",
        "    train_loaders,\n",
        "    epochs=3,\n",
        "    lr=1e-4\n",
        "):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for ep in range(epochs):\n",
        "        for loader in train_loaders:\n",
        "            for x, y in loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(model(x), y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "Zg9H345N0YsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation (target domain)"
      ],
      "metadata": {
        "id": "j-gx3Ez40paZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        preds = model(x).argmax(1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "d5MwIdKb0mwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = [4, 8, 16]\n",
        "variants = [\"minor\", \"major\", \"middle\", \"random\"]\n",
        "\n",
        "tier3_results = {}\n",
        "\n",
        "for r in ranks:\n",
        "    print(f\"\\n=== Rank {r} ===\")\n",
        "    tier3_results[r] = {}\n",
        "\n",
        "    for variant in variants:\n",
        "        print(f\"\\nVariant: {variant}\")\n",
        "\n",
        "        # 1. Fresh baseline\n",
        "        model = load_baseline_model(base_model_path)\n",
        "\n",
        "        # 2. Build subspaces\n",
        "        subspaces = {}\n",
        "        for lname, (layer, idx, conv_name) in conv_layers.items():\n",
        "            conv = getattr(getattr(model.backbone, layer)[idx], conv_name)\n",
        "            U = get_soma_subspace(conv, variant, r)\n",
        "            subspaces[lname] = U\n",
        "\n",
        "        # 3. Apply constraints\n",
        "        apply_subspace_constraints(model, conv_layers, subspaces)\n",
        "\n",
        "        # 4. Train\n",
        "        train_with_constraints(model, train_loaders)\n",
        "\n",
        "        # 5. Evaluate\n",
        "        acc = eval_accuracy(model, test_loader)\n",
        "        tier3_results[r][variant] = acc\n",
        "\n",
        "        print(f\"Target accuracy: {acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGUmZT6v1ACW",
        "outputId": "47bc65ce-e63a-4092-88b0-e72e0cc56391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Rank 4 ===\n",
            "\n",
            "Variant: minor\n",
            "Target accuracy: 0.711\n",
            "\n",
            "Variant: major\n",
            "Target accuracy: 0.744\n",
            "\n",
            "Variant: middle\n",
            "Target accuracy: 0.735\n",
            "\n",
            "Variant: random\n",
            "Target accuracy: 0.728\n",
            "\n",
            "=== Rank 8 ===\n",
            "\n",
            "Variant: minor\n",
            "Target accuracy: 0.658\n",
            "\n",
            "Variant: major\n",
            "Target accuracy: 0.745\n",
            "\n",
            "Variant: middle\n",
            "Target accuracy: 0.717\n",
            "\n",
            "Variant: random\n",
            "Target accuracy: 0.728\n",
            "\n",
            "=== Rank 16 ===\n",
            "\n",
            "Variant: minor\n",
            "Target accuracy: 0.729\n",
            "\n",
            "Variant: major\n",
            "Target accuracy: 0.737\n",
            "\n",
            "Variant: middle\n",
            "Target accuracy: 0.712\n",
            "\n",
            "Variant: random\n",
            "Target accuracy: 0.730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 3.4 — BatchNorm Confound Controls"
      ],
      "metadata": {
        "id": "03pXpiGaBr9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, copy, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def set_seed(seed=0):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "yZNnhPEKBvQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You must have PROJECT_ROOT already\n",
        "base_model_path = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "assert os.path.exists(base_model_path), f\"Missing baseline weights at {base_model_path}\"\n",
        "\n",
        "def load_baseline_model():\n",
        "    model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "    state = torch.load(base_model_path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Mc4ppNFNBygn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses your existing make_balanced_loader, make_loader, train_tf, test_tf, BATCH_SIZE\n",
        "train_loaders = [\n",
        "    make_balanced_loader(\"photo\", train_tf, BATCH_SIZE),\n",
        "    make_balanced_loader(\"art_painting\", train_tf, BATCH_SIZE),\n",
        "    make_balanced_loader(\"cartoon\", train_tf, BATCH_SIZE),\n",
        "]\n",
        "test_loader = make_loader(\"sketch\", test_tf, shuffle=False)\n",
        "\n",
        "print(\"Tier-3 data loaders ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7CUENHQB0oU",
        "outputId": "5c94bd36-eed1-4141-f1f6-81b940839403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tier-3 data loaders ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_subspace_constraints(model, conv_layers, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Apply gradient projection constraints to conv2 weights.\n",
        "\n",
        "    model       : nn.Module\n",
        "    conv_layers : dict {lname: (layer, idx, conv_name)}\n",
        "    kind        : {\"minor\", \"major\", \"middle\", \"random\"}\n",
        "    r           : rank of subspace\n",
        "    seed        : random seed (used only for 'random')\n",
        "    \"\"\"\n",
        "    for lname, (layer, idx, conv_name) in conv_layers.items():\n",
        "        conv = getattr(getattr(model.backbone, layer)[idx], conv_name)\n",
        "\n",
        "        # get subspace basis (numpy)\n",
        "        U = get_soma_subspace(conv, kind, r, seed=seed)\n",
        "\n",
        "        # register gradient projection hook\n",
        "        register_gradient_projection(conv.weight, U)\n"
      ],
      "metadata": {
        "id": "a4hH2OAeCTvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_bn_mode(model, mode: str):\n",
        "    \"\"\"\n",
        "    mode in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\"}\n",
        "    \"\"\"\n",
        "    assert mode in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\"}\n",
        "\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            if mode == \"bn_default\":\n",
        "                m.train()  # stats update\n",
        "                m.weight.requires_grad_(True)\n",
        "                m.bias.requires_grad_(True)\n",
        "\n",
        "            elif mode == \"bn_frozen\":\n",
        "                m.eval()   # stats frozen\n",
        "                m.weight.requires_grad_(False)\n",
        "                m.bias.requires_grad_(False)\n",
        "\n",
        "            elif mode == \"bn_affine_only\":\n",
        "                m.eval()   # stats frozen\n",
        "                m.weight.requires_grad_(True)\n",
        "                m.bias.requires_grad_(True)\n",
        "\n",
        "\n",
        "def replace_bn_with_gn(module: nn.Module, num_groups: int = 32):\n",
        "    \"\"\"\n",
        "    Recursively replace all BatchNorm2d layers with GroupNorm,\n",
        "    ensuring the new layers are placed on the same device.\n",
        "    \"\"\"\n",
        "    for name, child in module.named_children():\n",
        "        if isinstance(child, nn.BatchNorm2d):\n",
        "            num_channels = child.num_features\n",
        "\n",
        "            # choose valid group count\n",
        "            g = min(num_groups, num_channels)\n",
        "            while num_channels % g != 0 and g > 1:\n",
        "                g -= 1\n",
        "\n",
        "            gn = nn.GroupNorm(\n",
        "                num_groups=g,\n",
        "                num_channels=num_channels,\n",
        "                affine=True\n",
        "            )\n",
        "\n",
        "            # 🔑 MOVE TO SAME DEVICE AS ORIGINAL BN\n",
        "            gn = gn.to(child.weight.device)\n",
        "\n",
        "            setattr(module, name, gn)\n",
        "\n",
        "        else:\n",
        "            replace_bn_with_gn(child, num_groups=num_groups)\n",
        "\n",
        "\n",
        "\n",
        "def apply_norm_config(model, norm_cfg: str):\n",
        "    \"\"\"\n",
        "    norm_cfg in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\", \"groupnorm\"}\n",
        "    \"\"\"\n",
        "    assert norm_cfg in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\", \"groupnorm\"}\n",
        "\n",
        "    if norm_cfg == \"groupnorm\":\n",
        "        replace_bn_with_gn(model)\n",
        "        # GroupNorm has no running stats; keep train mode.\n",
        "        model.train()\n",
        "    else:\n",
        "        set_bn_mode(model, norm_cfg)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "HxyNA4GkB32l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_soma_subspace(conv, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Returns U basis [C_out, r] as numpy array (orthonormal).\n",
        "    \"\"\"\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    C_out = W.shape[0]\n",
        "    Wmat = W.reshape(C_out, -1)\n",
        "    U, S, _ = np.linalg.svd(Wmat, full_matrices=False)\n",
        "\n",
        "    if kind == \"major\":\n",
        "        return U[:, :r]\n",
        "    if kind == \"minor\":\n",
        "        return U[:, -r:]\n",
        "    if kind == \"middle\":\n",
        "        start = (C_out // 2) - (r // 2)\n",
        "        return U[:, start:start + r]\n",
        "    if kind == \"random\":\n",
        "        rng = np.random.default_rng(seed)\n",
        "        Q, _ = np.linalg.qr(rng.standard_normal((C_out, r)))\n",
        "        return Q\n",
        "\n",
        "    raise ValueError(f\"Unknown kind: {kind}\")\n"
      ],
      "metadata": {
        "id": "IXZsy980B5d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def register_gradient_projection(param, U_np):\n",
        "    \"\"\"\n",
        "    Project gradient onto span(U).\n",
        "    U_np is numpy [C_out, r].\n",
        "    \"\"\"\n",
        "    U = torch.tensor(U_np, dtype=torch.float32, device=param.device)\n",
        "    U.requires_grad_(False)\n",
        "\n",
        "    def hook(grad):\n",
        "        g = grad.view(grad.shape[0], -1)         # [C_out, D]\n",
        "        g_proj = U @ (U.T @ g)                   # [C_out, D]\n",
        "        return g_proj.view_as(grad)\n",
        "\n",
        "    param.register_hook(hook)\n",
        "\n",
        "\n",
        "def apply_subspace_constraints(model, conv_layers, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Apply gradient projection to conv2 weights for selected layers.\n",
        "    conv_layers: dict {lname: (layer, idx, \"conv2\")}\n",
        "    \"\"\"\n",
        "    for lname, (layer, idx, conv_name) in conv_layers.items():\n",
        "        conv = getattr(getattr(model.backbone, layer)[idx], conv_name)\n",
        "        U = get_soma_subspace(conv, kind, r, seed=seed)\n",
        "        register_gradient_projection(conv.weight, U)\n"
      ],
      "metadata": {
        "id": "xXEZg180B87y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = model(x).argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "def train_with_logging(model, train_loaders, epochs=3, lr=1e-4):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    logs = {\n",
        "        \"epoch_loss\": [],\n",
        "        \"grad_norm\": [],\n",
        "        \"update_norm\": [],\n",
        "    }\n",
        "\n",
        "    # snapshot params for update norm\n",
        "    with torch.no_grad():\n",
        "        init_params = {n: p.detach().clone() for n, p in model.named_parameters() if p.requires_grad}\n",
        "\n",
        "    model.train()\n",
        "    for ep in range(epochs):\n",
        "        ep_loss_sum, ep_n = 0.0, 0\n",
        "        grad_norm_sum, grad_n = 0.0, 0\n",
        "\n",
        "        for loader in train_loaders:\n",
        "            for x, y in loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y)\n",
        "                loss.backward()\n",
        "\n",
        "                # grad norm (after projection, since hooks already applied)\n",
        "                with torch.no_grad():\n",
        "                    total_g = 0.0\n",
        "                    for p in model.parameters():\n",
        "                        if p.grad is not None:\n",
        "                            total_g += p.grad.detach().float().norm().item() ** 2\n",
        "                    grad_norm_sum += total_g ** 0.5\n",
        "                    grad_n += 1\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                ep_loss_sum += loss.item() * x.size(0)\n",
        "                ep_n += x.size(0)\n",
        "\n",
        "        logs[\"epoch_loss\"].append(ep_loss_sum / max(ep_n, 1))\n",
        "        logs[\"grad_norm\"].append(grad_norm_sum / max(grad_n, 1))\n",
        "\n",
        "    # update norm (final minus initial)\n",
        "    with torch.no_grad():\n",
        "        total_u = 0.0\n",
        "        for n, p in model.named_parameters():\n",
        "            if n in init_params:\n",
        "                total_u += (p.detach() - init_params[n]).float().norm().item() ** 2\n",
        "        logs[\"update_norm\"].append(total_u ** 0.5)\n",
        "\n",
        "    return logs\n"
      ],
      "metadata": {
        "id": "SrUCtn62CBSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = [8, 16]\n",
        "subspaces = [\"major\", \"minor\", \"random\"]\n",
        "seeds = [0, 1]   # reduce to [0] if still slow\n",
        "\n",
        "def run_experiment(norm_cfg):\n",
        "    rows = []\n",
        "\n",
        "    print(f\"\\n===== Running BN variant: {norm_cfg} =====\")\n",
        "\n",
        "    for r in ranks:\n",
        "        for kind in subspaces:\n",
        "            for seed in seeds:\n",
        "                set_seed(seed)\n",
        "\n",
        "                model = load_baseline_model()\n",
        "                model = apply_norm_config(model, norm_cfg)\n",
        "                apply_subspace_constraints(model, conv_layers, kind, r, seed=seed)\n",
        "\n",
        "                logs = train_with_logging(\n",
        "                    model,\n",
        "                    train_loaders,\n",
        "                    epochs=3,\n",
        "                    lr=1e-4\n",
        "                )\n",
        "\n",
        "                acc = eval_accuracy(model, test_loader)\n",
        "\n",
        "                row = {\n",
        "                    \"norm_cfg\": norm_cfg,\n",
        "                    \"rank\": r,\n",
        "                    \"subspace\": kind,\n",
        "                    \"seed\": seed,\n",
        "                    \"target_acc\": acc,\n",
        "                    \"gradnorm_mean\": float(np.mean(logs[\"grad_norm\"])),\n",
        "                    \"update_norm\": logs[\"update_norm\"][0],\n",
        "                }\n",
        "                rows.append(row)\n",
        "\n",
        "                print(\n",
        "                    f\"[{norm_cfg}] r={r:2d} {kind:>6} seed={seed} \"\n",
        "                    f\"acc={acc:.3f} gn={row['gradnorm_mean']:.3f} upd={row['update_norm']:.3f}\"\n",
        "                )\n",
        "\n",
        "    return rows\n"
      ],
      "metadata": {
        "id": "XYT5NgDxCBw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_bn_default = run_experiment(\"bn_default\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhjK0HXJd6Gv",
        "outputId": "a52c10b0-c2b1-4278-b2f2-8796c9178a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Running BN variant: bn_default =====\n",
            "[bn_default] r= 8  major seed=0 acc=0.734 gn=0.658 upd=4.545\n",
            "[bn_default] r= 8  major seed=1 acc=0.734 gn=0.539 upd=4.621\n",
            "[bn_default] r= 8  minor seed=0 acc=0.734 gn=0.611 upd=4.376\n",
            "[bn_default] r= 8  minor seed=1 acc=0.722 gn=0.538 upd=4.545\n",
            "[bn_default] r= 8 random seed=0 acc=0.735 gn=0.612 upd=4.453\n",
            "[bn_default] r= 8 random seed=1 acc=0.727 gn=0.548 upd=4.718\n",
            "[bn_default] r=16  major seed=0 acc=0.734 gn=0.664 upd=4.546\n",
            "[bn_default] r=16  major seed=1 acc=0.723 gn=0.552 upd=4.625\n",
            "[bn_default] r=16  minor seed=0 acc=0.733 gn=0.616 upd=4.397\n",
            "[bn_default] r=16  minor seed=1 acc=0.722 gn=0.537 upd=4.584\n",
            "[bn_default] r=16 random seed=0 acc=0.735 gn=0.616 upd=4.439\n",
            "[bn_default] r=16 random seed=1 acc=0.728 gn=0.533 upd=4.628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_bn_affine = run_experiment(\"bn_affine_only\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfUPlsXAd8bt",
        "outputId": "8c7f18ec-aadf-43d6-db10-2dbc43fd859e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Running BN variant: bn_affine_only =====\n",
            "[bn_affine_only] r= 8  major seed=0 acc=0.734 gn=0.658 upd=4.545\n",
            "[bn_affine_only] r= 8  major seed=1 acc=0.734 gn=0.539 upd=4.621\n",
            "[bn_affine_only] r= 8  minor seed=0 acc=0.734 gn=0.611 upd=4.376\n",
            "[bn_affine_only] r= 8  minor seed=1 acc=0.722 gn=0.538 upd=4.545\n",
            "[bn_affine_only] r= 8 random seed=0 acc=0.735 gn=0.612 upd=4.453\n",
            "[bn_affine_only] r= 8 random seed=1 acc=0.727 gn=0.548 upd=4.718\n",
            "[bn_affine_only] r=16  major seed=0 acc=0.734 gn=0.664 upd=4.546\n",
            "[bn_affine_only] r=16  major seed=1 acc=0.723 gn=0.552 upd=4.625\n",
            "[bn_affine_only] r=16  minor seed=0 acc=0.733 gn=0.616 upd=4.397\n",
            "[bn_affine_only] r=16  minor seed=1 acc=0.722 gn=0.537 upd=4.584\n",
            "[bn_affine_only] r=16 random seed=0 acc=0.735 gn=0.616 upd=4.439\n",
            "[bn_affine_only] r=16 random seed=1 acc=0.728 gn=0.533 upd=4.628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_bn_frozen = run_experiment(\"bn_frozen\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vp5-icBd9ad",
        "outputId": "492bbc08-71fe-47d7-91cc-0d4fa46653eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Running BN variant: bn_frozen =====\n",
            "[bn_frozen] r= 8  major seed=0 acc=0.738 gn=0.609 upd=4.517\n",
            "[bn_frozen] r= 8  major seed=1 acc=0.728 gn=0.503 upd=4.616\n",
            "[bn_frozen] r= 8  minor seed=0 acc=0.735 gn=0.570 upd=4.373\n",
            "[bn_frozen] r= 8  minor seed=1 acc=0.720 gn=0.501 upd=4.549\n",
            "[bn_frozen] r= 8 random seed=0 acc=0.738 gn=0.574 upd=4.469\n",
            "[bn_frozen] r= 8 random seed=1 acc=0.723 gn=0.509 upd=4.712\n",
            "[bn_frozen] r=16  major seed=0 acc=0.732 gn=0.613 upd=4.511\n",
            "[bn_frozen] r=16  major seed=1 acc=0.722 gn=0.517 upd=4.623\n",
            "[bn_frozen] r=16  minor seed=0 acc=0.735 gn=0.577 upd=4.423\n",
            "[bn_frozen] r=16  minor seed=1 acc=0.722 gn=0.500 upd=4.585\n",
            "[bn_frozen] r=16 random seed=0 acc=0.739 gn=0.579 upd=4.466\n",
            "[bn_frozen] r=16 random seed=1 acc=0.725 gn=0.501 upd=4.647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_groupnorm = run_experiment(\"groupnorm\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laKa601Kd_gD",
        "outputId": "0fd4d894-60ce-4c3a-b026-1139fec0f052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Running BN variant: groupnorm =====\n",
            "[groupnorm] r= 8  major seed=0 acc=0.620 gn=8.665 upd=5.543\n",
            "[groupnorm] r= 8  major seed=1 acc=0.583 gn=8.732 upd=5.609\n",
            "[groupnorm] r= 8  minor seed=0 acc=0.605 gn=8.218 upd=5.565\n",
            "[groupnorm] r= 8  minor seed=1 acc=0.557 gn=8.216 upd=5.664\n",
            "[groupnorm] r= 8 random seed=0 acc=0.602 gn=8.246 upd=5.588\n",
            "[groupnorm] r= 8 random seed=1 acc=0.567 gn=8.382 upd=5.552\n",
            "[groupnorm] r=16  major seed=0 acc=0.600 gn=8.779 upd=5.480\n",
            "[groupnorm] r=16  major seed=1 acc=0.576 gn=8.622 upd=5.563\n",
            "[groupnorm] r=16  minor seed=0 acc=0.629 gn=8.261 upd=5.565\n",
            "[groupnorm] r=16  minor seed=1 acc=0.562 gn=8.311 upd=5.603\n",
            "[groupnorm] r=16 random seed=0 acc=0.643 gn=8.285 upd=5.556\n",
            "[groupnorm] r=16 random seed=1 acc=0.588 gn=8.391 upd=5.633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Corrected Grad-Projection SoMA Subspace Swap (Fixes BN + Adam subtlety + freezing)\n",
        "# =============================================================================\n",
        "# Fixes vs your friend's original:\n",
        "# 1) BatchNorm confound: BN running stats are frozen (BN in eval mode).\n",
        "#    You can choose:\n",
        "#      - bn_frozen      : freeze running stats AND freeze affine params\n",
        "#      - bn_affine_only : freeze running stats, but train gamma/beta\n",
        "# 2) Adam subtlety: use SGD with momentum=0 so projected gradients correspond\n",
        "#    to projected updates (clean projected-gradient method).\n",
        "# 3) Freezing outside convs: freeze all params by default, then selectively\n",
        "#    unfreeze:\n",
        "#      - the constrained conv weights (conv2 weights in selected layers)\n",
        "#      - classifier head (fc)\n",
        "#      - optional BN affine (if bn_affine_only)\n",
        "#\n",
        "# Assumptions:\n",
        "# - PROJECT_ROOT, base_model_path exists\n",
        "# - ResNet18_FeatureHook exposes .backbone like torchvision resnet\n",
        "# - conv_layers is a dict {lname: (layer_name, block_idx, conv_name)}\n",
        "# - make_balanced_loader / make_loader already defined\n",
        "# - train_tf, test_tf, BATCH_SIZE already defined\n",
        "# =============================================================================\n",
        "\n",
        "import torch, numpy as np, random\n",
        "import torch.nn as nn\n",
        "\n",
        "def set_seed(seed=0):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ---------------------------\n",
        "# Baseline loader\n",
        "# ---------------------------\n",
        "base_model_path = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "\n",
        "def load_baseline_model(path):\n",
        "    model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "    state = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# Subspace basis\n",
        "# ---------------------------\n",
        "def get_soma_subspace(conv, kind, r, seed=0, layer_key=\"\"):\n",
        "    \"\"\"\n",
        "    Returns orthonormal basis U [C_out, r] for conv weight space (output-channel subspace).\n",
        "    \"\"\"\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    C_out = W.shape[0]\n",
        "    Wmat = W.reshape(C_out, -1)\n",
        "    U, S, _ = np.linalg.svd(Wmat, full_matrices=False)\n",
        "\n",
        "    if kind == \"major\":\n",
        "        return U[:, :r]\n",
        "    if kind == \"minor\":\n",
        "        return U[:, -r:]\n",
        "    if kind == \"middle\":\n",
        "        start = (C_out // 2) - (r // 2)\n",
        "        return U[:, start:start + r]\n",
        "    if kind == \"random\":\n",
        "        # deterministic per-layer (optional); improves reproducibility across layers\n",
        "        rng = np.random.default_rng(seed + (abs(hash(layer_key)) % 10_000))\n",
        "        Q, _ = np.linalg.qr(rng.standard_normal((C_out, r)))\n",
        "        return Q\n",
        "\n",
        "    raise ValueError(f\"Unknown subspace kind: {kind}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Gradient projection hook (with duplicate-hook guard)\n",
        "# ---------------------------\n",
        "def register_gradient_projection(param, U_np):\n",
        "    \"\"\"\n",
        "    Projects grad onto span(U). Guard against duplicate hook stacking.\n",
        "    \"\"\"\n",
        "    if getattr(param, \"_has_soma_hook\", False):\n",
        "        return\n",
        "\n",
        "    U = torch.tensor(U_np, dtype=torch.float32, device=param.device)\n",
        "    U.requires_grad_(False)\n",
        "\n",
        "    def hook(grad):\n",
        "        # grad: [C_out, C_in, k, k]\n",
        "        g = grad.view(grad.shape[0], -1)     # [C_out, D]\n",
        "        g_proj = U @ (U.T @ g)               # [C_out, D]\n",
        "        return g_proj.view_as(grad)\n",
        "\n",
        "    h = param.register_hook(hook)\n",
        "    param._has_soma_hook = True\n",
        "    param._soma_hook_handle = h\n",
        "\n",
        "def apply_subspace_constraints(model, conv_layers, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Applies gradient projection to the conv weight tensors of specified layers.\n",
        "    \"\"\"\n",
        "    for lname, (layer, idx, conv_name) in conv_layers.items():\n",
        "        conv = getattr(getattr(model.backbone, layer)[idx], conv_name)\n",
        "        U = get_soma_subspace(conv, kind, r, seed=seed, layer_key=lname)\n",
        "        register_gradient_projection(conv.weight, U)\n",
        "\n",
        "# ---------------------------\n",
        "# BN control\n",
        "# ---------------------------\n",
        "def set_bn_mode(model, mode: str):\n",
        "    \"\"\"\n",
        "    mode in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\"}\n",
        "    \"\"\"\n",
        "    assert mode in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\"}\n",
        "\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            if mode == \"bn_default\":\n",
        "                m.train()  # running stats update\n",
        "                m.weight.requires_grad_(True)\n",
        "                m.bias.requires_grad_(True)\n",
        "            elif mode == \"bn_frozen\":\n",
        "                m.eval()   # freeze running stats\n",
        "                m.weight.requires_grad_(False)\n",
        "                m.bias.requires_grad_(False)\n",
        "            elif mode == \"bn_affine_only\":\n",
        "                m.eval()   # freeze running stats\n",
        "                m.weight.requires_grad_(True)\n",
        "                m.bias.requires_grad_(True)\n",
        "\n",
        "def enforce_bn_mode_during_training(model, mode: str):\n",
        "    \"\"\"\n",
        "    model.train() will set BN modules to train mode unless we override.\n",
        "    Call this after model.train(), and optionally inside the loop.\n",
        "    \"\"\"\n",
        "    if mode == \"bn_default\":\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.train()\n",
        "    else:\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.eval()\n",
        "\n",
        "# ---------------------------\n",
        "# Freeze / unfreeze policy (fixes \"no freezing of layers outside convs\")\n",
        "# ---------------------------\n",
        "def freeze_all_params(model):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def unfreeze_classifier(model):\n",
        "    # torchvision resnet: backbone.fc\n",
        "    for p in model.backbone.fc.parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def unfreeze_constrained_convs(model, conv_layers):\n",
        "    \"\"\"\n",
        "    Only unfreeze the conv weights that are being projected.\n",
        "    (Projection hook only matters if the parameter is trainable.)\n",
        "    \"\"\"\n",
        "    for lname, (layer, idx, conv_name) in conv_layers.items():\n",
        "        conv = getattr(getattr(model.backbone, layer)[idx], conv_name)\n",
        "        conv.weight.requires_grad = True\n",
        "        # conv bias in ResNet convs is typically None, but safe:\n",
        "        if getattr(conv, \"bias\", None) is not None:\n",
        "            conv.bias.requires_grad = True\n",
        "\n",
        "# ---------------------------\n",
        "# Train + Eval\n",
        "# ---------------------------\n",
        "@torch.no_grad()\n",
        "def eval_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    print(\"yes\")\n",
        "    correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        preds = model(x).argmax(1)\n",
        "        print(\"hmm\")\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "        print(\"hmm\")\n",
        "    print(\"yeah\")\n",
        "    return correct / max(total, 1)\n",
        "\n",
        "def train_with_constraints(model, train_loaders, bn_mode=\"bn_affine_only\", epochs=3, lr=1e-4, weight_decay=0.0):\n",
        "    \"\"\"\n",
        "    Uses SGD(m=0) to avoid Adam subtlety so projection is clean.\n",
        "    Balanced loader list is preserved (one domain at a time).\n",
        "    \"\"\"\n",
        "    # Train only params with requires_grad=True\n",
        "    optimizer = torch.optim.SGD(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=lr, momentum=0.0, weight_decay=weight_decay\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        enforce_bn_mode_during_training(model, bn_mode)\n",
        "\n",
        "        for loader in train_loaders:\n",
        "            for x, y in loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "\n",
        "                enforce_bn_mode_during_training(model, bn_mode)\n",
        "\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4lpW4crvLeN",
        "outputId": "c66b14f2-24d0-4655-bac5-cf89f771e042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# RUN: Subspace Swap via Grad Projection (Corrected)\n",
        "# =============================================================================\n",
        "\n",
        "# ----- Data loaders (as in your friend's code; assumes these exist) -----\n",
        "train_loaders = [\n",
        "    make_balanced_loader(\"photo\", train_tf, BATCH_SIZE),\n",
        "    make_balanced_loader(\"art_painting\", train_tf, BATCH_SIZE),\n",
        "    make_balanced_loader(\"cartoon\", train_tf, BATCH_SIZE),\n",
        "]\n",
        "test_loader = make_loader(\"sketch\", test_tf, shuffle=False)\n",
        "\n",
        "print(\"Tier-3 loaders ready (assumed).\")\n",
        "\n",
        "ranks = [4, 8, 16]\n",
        "variants = [\"minor\", \"major\", \"middle\", \"random\"]\n",
        "\n",
        "# Choose BN control for this experiment:\n",
        "# - \"bn_affine_only\" is typically the best compromise for DG (stats frozen, affine trainable)\n",
        "# - \"bn_frozen\" is stricter (affine frozen too)\n",
        "BN_MODE = \"bn_affine_only\"\n",
        "\n",
        "EPOCHS = 3\n",
        "LR = 1e-4\n",
        "\n",
        "tier3_results = {}\n",
        "\n",
        "for r in ranks:\n",
        "    print(f\"\\n=== Rank {r} ===\")\n",
        "    tier3_results[r] = {}\n",
        "    for variant in variants:\n",
        "        print(f\"\\nVariant: {variant}\")\n",
        "\n",
        "        for seed in [0]:  # add more seeds if you want\n",
        "            set_seed(seed)\n",
        "\n",
        "            # 1) Fresh baseline\n",
        "            model = load_baseline_model(base_model_path)\n",
        "            print(\"1\")\n",
        "            # 2) Freeze everything, then unfreeze only what we allow to adapt\n",
        "            freeze_all_params(model)\n",
        "            unfreeze_classifier(model)\n",
        "            unfreeze_constrained_convs(model, conv_layers)\n",
        "            print(\"2\")\n",
        "            # 3) Set BN mode (and ensure requires_grad matches)\n",
        "            set_bn_mode(model, BN_MODE)\n",
        "            print(\"3\")\n",
        "\n",
        "            # 4) Apply constraints (projection hooks) to the trainable conv weights\n",
        "            apply_subspace_constraints(model, conv_layers, variant, r, seed=seed)\n",
        "            print(\"4\")\n",
        "\n",
        "            # 5) Train\n",
        "            train_with_constraints(model, train_loaders, bn_mode=BN_MODE, epochs=EPOCHS, lr=LR)\n",
        "            print(\"5\")\n",
        "\n",
        "            # 6) Evaluate\n",
        "            acc = eval_accuracy(model, test_loader)\n",
        "            print(\"6\")\n",
        "            tier3_results[r].setdefault(variant, []).append(acc)\n",
        "\n",
        "            print(f\"  seed={seed} | Target accuracy: {acc:.3f}\")\n",
        "\n",
        "# Optional: summarize\n",
        "print(\"\\n==== Summary (mean over seeds) ====\")\n",
        "for r in ranks:\n",
        "    for v in variants:\n",
        "        vals = tier3_results[r].get(v, [])\n",
        "        if vals:\n",
        "            print(f\"r={r:2d} {v:>6}: mean={np.mean(vals):.3f} std={np.std(vals):.3f} n={len(vals)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPPzxj5wvGim",
        "outputId": "82c4636b-b6bd-4ad4-a5f2-3f1fa5b308a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tier-3 loaders ready (assumed).\n",
            "\n",
            "=== Rank 4 ===\n",
            "\n",
            "Variant: minor\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.735\n",
            "\n",
            "Variant: major\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.734\n",
            "\n",
            "Variant: middle\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.735\n",
            "\n",
            "Variant: random\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.734\n",
            "\n",
            "=== Rank 8 ===\n",
            "\n",
            "Variant: minor\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.735\n",
            "\n",
            "Variant: major\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.734\n",
            "\n",
            "Variant: middle\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.735\n",
            "\n",
            "Variant: random\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.735\n",
            "\n",
            "=== Rank 16 ===\n",
            "\n",
            "Variant: minor\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.735\n",
            "\n",
            "Variant: major\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.734\n",
            "\n",
            "Variant: middle\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "hmm\n",
            "yeah\n",
            "6\n",
            "  seed=0 | Target accuracy: 0.734\n",
            "\n",
            "Variant: random\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    results_bn_default +\n",
        "    results_bn_affine +\n",
        "    results_bn_frozen +\n",
        "    results_groupnorm\n",
        ")\n",
        "\n",
        "summary = (\n",
        "    df.groupby([\"norm_cfg\", \"rank\", \"subspace\"])\n",
        "      .agg(\n",
        "          acc_mean=(\"target_acc\", \"mean\"),\n",
        "          acc_std=(\"target_acc\", \"std\"),\n",
        "          gradnorm=(\"gradnorm_mean\", \"mean\"),\n",
        "          update_norm=(\"update_norm\", \"mean\"),\n",
        "      )\n",
        "      .reset_index()\n",
        "      .sort_values([\"norm_cfg\", \"rank\", \"acc_mean\"], ascending=[True, True, False])\n",
        ")\n",
        "\n",
        "display(summary)\n",
        "\n",
        "summary.to_csv(f\"{PROJECT_ROOT}/tier3_bn_light_summary.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "UlSVqH6dCEzc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7da91cf-6bd1-4a2a-af84-ba3a173b1093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          norm_cfg  rank subspace  acc_mean   acc_std  gradnorm  update_norm\n",
              "0   bn_affine_only     8    major  0.733902  0.000540  0.598962     4.582831\n",
              "2   bn_affine_only     8   random  0.730720  0.005759  0.579620     4.585551\n",
              "1   bn_affine_only     8    minor  0.727666  0.008639  0.574564     4.460609\n",
              "5   bn_affine_only    16   random  0.731357  0.005219  0.574653     4.533898\n",
              "3   bn_affine_only    16    major  0.728557  0.007379  0.608302     4.585496\n",
              "4   bn_affine_only    16    minor  0.727793  0.007739  0.576844     4.490437\n",
              "6       bn_default     8    major  0.733902  0.000540  0.598962     4.582831\n",
              "8       bn_default     8   random  0.730720  0.005759  0.579620     4.585551\n",
              "7       bn_default     8    minor  0.727666  0.008639  0.574564     4.460609\n",
              "11      bn_default    16   random  0.731357  0.005219  0.574653     4.533898\n",
              "9       bn_default    16    major  0.728557  0.007379  0.608302     4.585496\n",
              "10      bn_default    16    minor  0.727793  0.007739  0.576844     4.490437\n",
              "12       bn_frozen     8    major  0.732756  0.006839  0.555976     4.566568\n",
              "14       bn_frozen     8   random  0.730593  0.010258  0.541793     4.590447\n",
              "13       bn_frozen     8    minor  0.727666  0.010798  0.535614     4.461212\n",
              "17       bn_frozen    16   random  0.731993  0.009359  0.539953     4.556338\n",
              "16       bn_frozen    16    minor  0.728430  0.009718  0.538545     4.504263\n",
              "15       bn_frozen    16    major  0.727284  0.007019  0.564857     4.567027\n",
              "18       groupnorm     8    major  0.601425  0.025916  8.698674     5.575939\n",
              "20       groupnorm     8   random  0.584500  0.024656  8.314387     5.570050\n",
              "19       groupnorm     8    minor  0.580937  0.034374  8.216900     5.614601\n",
              "23       groupnorm    16   random  0.615678  0.038514  8.338040     5.594794\n",
              "22       groupnorm    16    minor  0.595317  0.047512  8.285936     5.583605\n",
              "21       groupnorm    16    major  0.587681  0.016917  8.700881     5.521835"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb6d82b4-06ac-46cd-ab5e-e9908f1ada24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>norm_cfg</th>\n",
              "      <th>rank</th>\n",
              "      <th>subspace</th>\n",
              "      <th>acc_mean</th>\n",
              "      <th>acc_std</th>\n",
              "      <th>gradnorm</th>\n",
              "      <th>update_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bn_affine_only</td>\n",
              "      <td>8</td>\n",
              "      <td>major</td>\n",
              "      <td>0.733902</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.598962</td>\n",
              "      <td>4.582831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bn_affine_only</td>\n",
              "      <td>8</td>\n",
              "      <td>random</td>\n",
              "      <td>0.730720</td>\n",
              "      <td>0.005759</td>\n",
              "      <td>0.579620</td>\n",
              "      <td>4.585551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>bn_affine_only</td>\n",
              "      <td>8</td>\n",
              "      <td>minor</td>\n",
              "      <td>0.727666</td>\n",
              "      <td>0.008639</td>\n",
              "      <td>0.574564</td>\n",
              "      <td>4.460609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>bn_affine_only</td>\n",
              "      <td>16</td>\n",
              "      <td>random</td>\n",
              "      <td>0.731357</td>\n",
              "      <td>0.005219</td>\n",
              "      <td>0.574653</td>\n",
              "      <td>4.533898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bn_affine_only</td>\n",
              "      <td>16</td>\n",
              "      <td>major</td>\n",
              "      <td>0.728557</td>\n",
              "      <td>0.007379</td>\n",
              "      <td>0.608302</td>\n",
              "      <td>4.585496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bn_affine_only</td>\n",
              "      <td>16</td>\n",
              "      <td>minor</td>\n",
              "      <td>0.727793</td>\n",
              "      <td>0.007739</td>\n",
              "      <td>0.576844</td>\n",
              "      <td>4.490437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>bn_default</td>\n",
              "      <td>8</td>\n",
              "      <td>major</td>\n",
              "      <td>0.733902</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.598962</td>\n",
              "      <td>4.582831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>bn_default</td>\n",
              "      <td>8</td>\n",
              "      <td>random</td>\n",
              "      <td>0.730720</td>\n",
              "      <td>0.005759</td>\n",
              "      <td>0.579620</td>\n",
              "      <td>4.585551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>bn_default</td>\n",
              "      <td>8</td>\n",
              "      <td>minor</td>\n",
              "      <td>0.727666</td>\n",
              "      <td>0.008639</td>\n",
              "      <td>0.574564</td>\n",
              "      <td>4.460609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>bn_default</td>\n",
              "      <td>16</td>\n",
              "      <td>random</td>\n",
              "      <td>0.731357</td>\n",
              "      <td>0.005219</td>\n",
              "      <td>0.574653</td>\n",
              "      <td>4.533898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>bn_default</td>\n",
              "      <td>16</td>\n",
              "      <td>major</td>\n",
              "      <td>0.728557</td>\n",
              "      <td>0.007379</td>\n",
              "      <td>0.608302</td>\n",
              "      <td>4.585496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>bn_default</td>\n",
              "      <td>16</td>\n",
              "      <td>minor</td>\n",
              "      <td>0.727793</td>\n",
              "      <td>0.007739</td>\n",
              "      <td>0.576844</td>\n",
              "      <td>4.490437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>bn_frozen</td>\n",
              "      <td>8</td>\n",
              "      <td>major</td>\n",
              "      <td>0.732756</td>\n",
              "      <td>0.006839</td>\n",
              "      <td>0.555976</td>\n",
              "      <td>4.566568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>bn_frozen</td>\n",
              "      <td>8</td>\n",
              "      <td>random</td>\n",
              "      <td>0.730593</td>\n",
              "      <td>0.010258</td>\n",
              "      <td>0.541793</td>\n",
              "      <td>4.590447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>bn_frozen</td>\n",
              "      <td>8</td>\n",
              "      <td>minor</td>\n",
              "      <td>0.727666</td>\n",
              "      <td>0.010798</td>\n",
              "      <td>0.535614</td>\n",
              "      <td>4.461212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>bn_frozen</td>\n",
              "      <td>16</td>\n",
              "      <td>random</td>\n",
              "      <td>0.731993</td>\n",
              "      <td>0.009359</td>\n",
              "      <td>0.539953</td>\n",
              "      <td>4.556338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>bn_frozen</td>\n",
              "      <td>16</td>\n",
              "      <td>minor</td>\n",
              "      <td>0.728430</td>\n",
              "      <td>0.009718</td>\n",
              "      <td>0.538545</td>\n",
              "      <td>4.504263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>bn_frozen</td>\n",
              "      <td>16</td>\n",
              "      <td>major</td>\n",
              "      <td>0.727284</td>\n",
              "      <td>0.007019</td>\n",
              "      <td>0.564857</td>\n",
              "      <td>4.567027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>groupnorm</td>\n",
              "      <td>8</td>\n",
              "      <td>major</td>\n",
              "      <td>0.601425</td>\n",
              "      <td>0.025916</td>\n",
              "      <td>8.698674</td>\n",
              "      <td>5.575939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>groupnorm</td>\n",
              "      <td>8</td>\n",
              "      <td>random</td>\n",
              "      <td>0.584500</td>\n",
              "      <td>0.024656</td>\n",
              "      <td>8.314387</td>\n",
              "      <td>5.570050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>groupnorm</td>\n",
              "      <td>8</td>\n",
              "      <td>minor</td>\n",
              "      <td>0.580937</td>\n",
              "      <td>0.034374</td>\n",
              "      <td>8.216900</td>\n",
              "      <td>5.614601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>groupnorm</td>\n",
              "      <td>16</td>\n",
              "      <td>random</td>\n",
              "      <td>0.615678</td>\n",
              "      <td>0.038514</td>\n",
              "      <td>8.338040</td>\n",
              "      <td>5.594794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>groupnorm</td>\n",
              "      <td>16</td>\n",
              "      <td>minor</td>\n",
              "      <td>0.595317</td>\n",
              "      <td>0.047512</td>\n",
              "      <td>8.285936</td>\n",
              "      <td>5.583605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>groupnorm</td>\n",
              "      <td>16</td>\n",
              "      <td>major</td>\n",
              "      <td>0.587681</td>\n",
              "      <td>0.016917</td>\n",
              "      <td>8.700881</td>\n",
              "      <td>5.521835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb6d82b4-06ac-46cd-ab5e-e9908f1ada24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb6d82b4-06ac-46cd-ab5e-e9908f1ada24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb6d82b4-06ac-46cd-ab5e-e9908f1ada24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-97ba0a0f-a233-4c9c-aa94-cf78d12e2651\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97ba0a0f-a233-4c9c-aa94-cf78d12e2651')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-97ba0a0f-a233-4c9c-aa94-cf78d12e2651 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_80f540f4-7715-4813-8fcd-95d0bf7288f0\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('summary')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_80f540f4-7715-4813-8fcd-95d0bf7288f0 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('summary');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "summary",
              "summary": "{\n  \"name\": \"summary\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"norm_cfg\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"bn_default\",\n          \"groupnorm\",\n          \"bn_affine_only\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 8,\n        \"max\": 16,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          16,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subspace\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"major\",\n          \"random\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06034157455570226,\n        \"min\": 0.5809366250954441,\n        \"max\": 0.733901756172054,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.733901756172054,\n          0.7307202850598117\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"acc_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012194312074885723,\n        \"min\": 0.00053991355142783,\n        \"max\": 0.04751239252564229,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.00053991355142783,\n          0.005759077881896016\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gradnorm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.4752941746357497,\n        \"min\": 0.5356140572666546,\n        \"max\": 8.700880753466866,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.5989620121886359,\n          0.5796200660442659\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"update_norm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.46070217166284017,\n        \"min\": 4.460608984432955,\n        \"max\": 5.614601388531883,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          4.582830887636172,\n          4.585550901876318\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BatchNorm Confound Controls — Corrected + Stricter"
      ],
      "metadata": {
        "id": "0sSWkhNYKV4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# BatchNorm Confound Controls — Corrected + Stricter\n",
        "# =============================================================================\n",
        "# What this experiment tests\n",
        "# - Whether SoMA-style subspace-constrained learning effects are actually BN artifacts.\n",
        "#\n",
        "# What is fixed vs your draft:\n",
        "#  (1) BN mode is NOT accidentally undone by model.train() during training.\n",
        "#  (2) Gradient hooks are guarded to prevent accidental duplicate hook stacking.\n",
        "#  (3) Optimizer caveat fixed: use SGD (momentum=0) so \"projected gradient\" = \"projected update direction\".\n",
        "#  (4) Domain-imbalance caveat fixed: balanced per-step multi-domain training (equal contribution each step).\n",
        "#\n",
        "# Assumptions:\n",
        "# - PACS is already exported to ImageFolder layout under PACS_ROOT.\n",
        "# - You have a baseline source-trained model checkpoint.\n",
        "# - Model exposes `model.backbone` like torchvision ResNet.\n",
        "# - You define `PROJECT_ROOT`, `PACS_ROOT`, and `base_model_path`.\n",
        "# =============================================================================\n",
        "\n",
        "import os, json, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from typing import Dict, Tuple, List\n",
        "\n",
        "# ---------------------------\n",
        "# Reproducibility\n",
        "# ---------------------------\n",
        "def set_seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ---------------------------\n",
        "# Config\n",
        "# ---------------------------\n",
        "SOURCE_DOMAINS = [\"photo\", \"art_painting\", \"cartoon\"]\n",
        "TARGET_DOMAIN = \"sketch\"\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "IMG_SIZE = 224\n",
        "\n",
        "EPOCHS = 3\n",
        "LR = 1e-4\n",
        "WEIGHT_DECAY = 0.0\n",
        "\n",
        "ranks = [8, 16]\n",
        "subspaces = [\"major\", \"minor\", \"random\"]\n",
        "seeds = [0, 1]\n",
        "\n",
        "# Chosen layers where we constrain conv2 updates.\n",
        "# conv_layers: dict {lname: (layer_name, block_idx, conv_name)}\n",
        "conv_layers: Dict[str, Tuple[str, int, str]] = {\n",
        "    \"l2_b0_c2\": (\"layer2\", 0, \"conv2\"),\n",
        "    \"l2_b1_c2\": (\"layer2\", 1, \"conv2\"),\n",
        "    \"l3_b0_c2\": (\"layer3\", 0, \"conv2\"),\n",
        "    \"l3_b1_c2\": (\"layer3\", 1, \"conv2\"),\n",
        "    \"l4_b0_c2\": (\"layer4\", 0, \"conv2\"),\n",
        "    \"l4_b1_c2\": (\"layer4\", 1, \"conv2\"),\n",
        "}\n",
        "\n",
        "# ---------------------------\n",
        "# Data\n",
        "# ---------------------------\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def make_loader(domain: str, tfm, shuffle: bool):\n",
        "    ds = datasets.ImageFolder(root=os.path.join(PACS_ROOT, domain), transform=tfm)\n",
        "    return DataLoader(ds, batch_size=BATCH_SIZE, shuffle=shuffle,\n",
        "                      num_workers=NUM_WORKERS, pin_memory=(device == \"cuda\"))\n",
        "\n",
        "# Per-domain loaders so we can train with equal contribution per domain\n",
        "train_loaders = [make_loader(d, train_tf, shuffle=True) for d in SOURCE_DOMAINS]\n",
        "test_loader = make_loader(TARGET_DOMAIN, test_tf, shuffle=False)\n",
        "\n",
        "# ---------------------------\n",
        "# Baseline model loader\n",
        "# ---------------------------\n",
        "class ResNet18_Base(nn.Module):\n",
        "    \"\"\"Simple ResNet18 wrapper (adjust if your baseline class differs).\"\"\"\n",
        "    def __init__(self, num_classes=7):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(weights=None)\n",
        "        self.backbone.fc = nn.Linear(512, num_classes)\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "def load_baseline_model(path: str):\n",
        "    m = ResNet18_Base(num_classes=7).to(device)\n",
        "    state = torch.load(path, map_location=device)\n",
        "    m.load_state_dict(state)\n",
        "    return m\n",
        "\n",
        "# ---------------------------\n",
        "# Normalization controls\n",
        "# ---------------------------\n",
        "def set_bn_mode(model, mode: str):\n",
        "    \"\"\"\n",
        "    mode in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\"}\n",
        "    \"\"\"\n",
        "    assert mode in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\"}\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            if mode == \"bn_default\":\n",
        "                m.train()  # running stats update\n",
        "                m.weight.requires_grad_(True)\n",
        "                m.bias.requires_grad_(True)\n",
        "            elif mode == \"bn_frozen\":\n",
        "                m.eval()   # freeze running stats\n",
        "                m.weight.requires_grad_(False)\n",
        "                m.bias.requires_grad_(False)\n",
        "            elif mode == \"bn_affine_only\":\n",
        "                m.eval()   # freeze running stats\n",
        "                m.weight.requires_grad_(True)\n",
        "                m.bias.requires_grad_(True)\n",
        "\n",
        "def replace_bn_with_gn(module: nn.Module, num_groups: int = 32):\n",
        "    \"\"\"\n",
        "    Recursively replace BatchNorm2d with GroupNorm.\n",
        "    Copies affine params (gamma/beta) to reduce confound from random GN init.\n",
        "    \"\"\"\n",
        "    for name, child in module.named_children():\n",
        "        if isinstance(child, nn.BatchNorm2d):\n",
        "            num_channels = child.num_features\n",
        "            g = min(num_groups, num_channels)\n",
        "            while num_channels % g != 0 and g > 1:\n",
        "                g -= 1\n",
        "\n",
        "            gn = nn.GroupNorm(num_groups=g, num_channels=num_channels, affine=True)\n",
        "\n",
        "            # copy affine params if BN had affine\n",
        "            with torch.no_grad():\n",
        "                if child.affine:\n",
        "                    gn.weight.copy_(child.weight.detach().cpu())\n",
        "                    gn.bias.copy_(child.bias.detach().cpu())\n",
        "\n",
        "            # move to same device\n",
        "            gn = gn.to(next(module.parameters()).device if any(True for _ in module.parameters()) else device)\n",
        "            setattr(module, name, gn)\n",
        "        else:\n",
        "            replace_bn_with_gn(child, num_groups=num_groups)\n",
        "\n",
        "def apply_norm_config(model, norm_cfg: str):\n",
        "    \"\"\"\n",
        "    norm_cfg in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\", \"groupnorm\"}\n",
        "    \"\"\"\n",
        "    assert norm_cfg in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\", \"groupnorm\"}\n",
        "\n",
        "    if norm_cfg == \"groupnorm\":\n",
        "        replace_bn_with_gn(model, num_groups=32)\n",
        "        # GN has no running stats; train() is fine\n",
        "        return model\n",
        "    else:\n",
        "        set_bn_mode(model, norm_cfg)\n",
        "        return model\n",
        "\n",
        "def enforce_bn_behavior_during_training(model, norm_cfg: str):\n",
        "    \"\"\"\n",
        "    Critical: model.train() will flip BN modules to train mode.\n",
        "    We must re-enforce BN mode each time training starts and (optionally) each step.\n",
        "    \"\"\"\n",
        "    if norm_cfg == \"bn_default\":\n",
        "        # allow BN stats update\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.train()\n",
        "        return\n",
        "\n",
        "    if norm_cfg in {\"bn_frozen\", \"bn_affine_only\"}:\n",
        "        # freeze running stats by keeping BN in eval mode\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.eval()\n",
        "\n",
        "# ---------------------------\n",
        "# Subspace basis + gradient projection\n",
        "# ---------------------------\n",
        "def get_soma_subspace(conv: nn.Conv2d, kind: str, r: int, seed: int = 0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Returns U basis [C_out, r] as numpy array (orthonormal).\n",
        "    \"\"\"\n",
        "    assert kind in {\"major\", \"minor\", \"middle\", \"random\"}\n",
        "\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    C_out = W.shape[0]\n",
        "    Wmat = W.reshape(C_out, -1)\n",
        "    U, S, _ = np.linalg.svd(Wmat, full_matrices=False)\n",
        "\n",
        "    if kind == \"major\":\n",
        "        return U[:, :r]\n",
        "    if kind == \"minor\":\n",
        "        return U[:, -r:]\n",
        "    if kind == \"middle\":\n",
        "        start = (C_out // 2) - (r // 2)\n",
        "        return U[:, start:start + r]\n",
        "    if kind == \"random\":\n",
        "        rng = np.random.default_rng(seed)\n",
        "        Q, _ = np.linalg.qr(rng.standard_normal((C_out, r)))\n",
        "        return Q\n",
        "\n",
        "    raise ValueError(f\"Unknown kind: {kind}\")\n",
        "\n",
        "def register_gradient_projection(param: torch.nn.Parameter, U_np: np.ndarray):\n",
        "    \"\"\"\n",
        "    Project gradient onto span(U). U_np is numpy [C_out, r].\n",
        "    Guard against duplicate hook stacking.\n",
        "    \"\"\"\n",
        "    if getattr(param, \"_has_soma_hook\", False):\n",
        "        return\n",
        "\n",
        "    U = torch.tensor(U_np, dtype=torch.float32, device=param.device)\n",
        "    U.requires_grad_(False)\n",
        "\n",
        "    def hook(grad):\n",
        "        # grad: [C_out, C_in, k, k]\n",
        "        g = grad.view(grad.shape[0], -1)         # [C_out, D]\n",
        "        g_proj = U @ (U.T @ g)                   # [C_out, D]\n",
        "        return g_proj.view_as(grad)\n",
        "\n",
        "    handle = param.register_hook(hook)\n",
        "    param._has_soma_hook = True\n",
        "    param._soma_hook_handle = handle  # in case you want to remove later\n",
        "\n",
        "def apply_subspace_constraints(model, conv_layers: Dict[str, Tuple[str, int, str]],\n",
        "                               kind: str, r: int, seed: int = 0):\n",
        "    \"\"\"\n",
        "    Apply gradient projection to conv2 weights for selected layers.\n",
        "    \"\"\"\n",
        "    for lname, (layer_name, idx, conv_name) in conv_layers.items():\n",
        "        block = getattr(model.backbone, layer_name)[idx]\n",
        "        conv = getattr(block, conv_name)\n",
        "        U = get_soma_subspace(conv, kind, r, seed=seed)\n",
        "        register_gradient_projection(conv.weight, U)\n",
        "\n",
        "# ---------------------------\n",
        "# Training / Evaluation\n",
        "# ---------------------------\n",
        "@torch.no_grad()\n",
        "def eval_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = model(x).argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / max(total, 1)\n",
        "\n",
        "def train_with_logging(model, train_loaders: List[DataLoader], norm_cfg: str,\n",
        "                       epochs: int = 3, lr: float = 1e-4, weight_decay: float = 0.0):\n",
        "    \"\"\"\n",
        "    Balanced multi-domain training:\n",
        "      - At each step, we take one batch from EACH domain loader\n",
        "      - Accumulate gradients (averaged across domains)\n",
        "      - Do one optimizer step\n",
        "    This ensures equal contribution per domain, fixing the \"domain imbalance\" caveat.\n",
        "    \"\"\"\n",
        "    # Use SGD with momentum=0 so projected grad corresponds to projected update direction.\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=lr,\n",
        "        momentum=0.0,\n",
        "        weight_decay=weight_decay\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    logs = {\"epoch_loss\": [], \"grad_norm\": [], \"update_norm\": None}\n",
        "\n",
        "    # snapshot params for update norm (trainable only)\n",
        "    with torch.no_grad():\n",
        "        init_params = {n: p.detach().clone() for n, p in model.named_parameters() if p.requires_grad}\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        enforce_bn_behavior_during_training(model, norm_cfg)\n",
        "\n",
        "        # Equalize steps across domains using the minimum loader length\n",
        "        iters = [iter(ld) for ld in train_loaders]\n",
        "        steps = min(len(ld) for ld in train_loaders)\n",
        "\n",
        "        ep_loss_sum = 0.0\n",
        "        ep_ex = 0\n",
        "        grad_norm_sum = 0.0\n",
        "        grad_n = 0\n",
        "\n",
        "        for step in range(steps):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # accumulate gradients across domains, averaging losses\n",
        "            loss_accum = 0.0\n",
        "            for di, it_ in enumerate(iters):\n",
        "                try:\n",
        "                    x, y = next(it_)\n",
        "                except StopIteration:\n",
        "                    # should not happen given steps=min(len)\n",
        "                    break\n",
        "                x, y = x.to(device), y.to(device)\n",
        "\n",
        "                # Keep BN behavior consistent even inside training loop\n",
        "                enforce_bn_behavior_during_training(model, norm_cfg)\n",
        "\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y) / len(train_loaders)\n",
        "                loss.backward()\n",
        "                loss_accum += loss.item() * x.size(0)  # scaled loss; ok for logging\n",
        "\n",
        "                ep_ex += x.size(0)\n",
        "\n",
        "            # grad norm after projection (hooks already applied)\n",
        "            with torch.no_grad():\n",
        "                total_g2 = 0.0\n",
        "                for p in model.parameters():\n",
        "                    if p.grad is not None:\n",
        "                        total_g2 += float(p.grad.detach().float().norm().item() ** 2)\n",
        "                grad_norm_sum += total_g2 ** 0.5\n",
        "                grad_n += 1\n",
        "\n",
        "            optimizer.step()\n",
        "            ep_loss_sum += loss_accum\n",
        "\n",
        "        logs[\"epoch_loss\"].append(ep_loss_sum / max(ep_ex, 1))\n",
        "        logs[\"grad_norm\"].append(grad_norm_sum / max(grad_n, 1))\n",
        "\n",
        "    # update norm (final minus initial)\n",
        "    with torch.no_grad():\n",
        "        total_u2 = 0.0\n",
        "        for n, p in model.named_parameters():\n",
        "            if n in init_params:\n",
        "                total_u2 += float((p.detach() - init_params[n]).float().norm().item() ** 2)\n",
        "        logs[\"update_norm\"] = total_u2 ** 0.5\n",
        "\n",
        "    return logs\n",
        "\n",
        "# ---------------------------\n",
        "# Experiment runner\n",
        "# ---------------------------\n",
        "def run_experiment(norm_cfg: str, base_model_path: str):\n",
        "    \"\"\"\n",
        "    norm_cfg in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\", \"groupnorm\"}\n",
        "    \"\"\"\n",
        "    assert norm_cfg in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\", \"groupnorm\"}\n",
        "    rows = []\n",
        "    print(f\"\\n===== Running Norm variant: {norm_cfg} =====\")\n",
        "\n",
        "    for r in ranks:\n",
        "        for kind in subspaces:\n",
        "            for seed in seeds:\n",
        "                set_seed(seed)\n",
        "\n",
        "                # fresh baseline each run\n",
        "                model = load_baseline_model(base_model_path).to(device)\n",
        "\n",
        "                # Apply normalization config\n",
        "                model = apply_norm_config(model, norm_cfg).to(device)\n",
        "\n",
        "                # Apply subspace constraints\n",
        "                apply_subspace_constraints(model, conv_layers, kind, r, seed=seed)\n",
        "\n",
        "                # Train + logs\n",
        "                logs = train_with_logging(\n",
        "                    model,\n",
        "                    train_loaders=train_loaders,\n",
        "                    norm_cfg=norm_cfg,\n",
        "                    epochs=EPOCHS,\n",
        "                    lr=LR,\n",
        "                    weight_decay=WEIGHT_DECAY\n",
        "                )\n",
        "\n",
        "                acc = eval_accuracy(model, test_loader)\n",
        "\n",
        "                row = {\n",
        "                    \"norm_cfg\": norm_cfg,\n",
        "                    \"rank\": r,\n",
        "                    \"subspace\": kind,\n",
        "                    \"seed\": seed,\n",
        "                    \"target_acc\": float(acc),\n",
        "                    \"gradnorm_mean\": float(np.mean(logs[\"grad_norm\"])),\n",
        "                    \"update_norm\": float(logs[\"update_norm\"]),\n",
        "                    \"epoch_loss\": [float(x) for x in logs[\"epoch_loss\"]],\n",
        "                    \"epoch_grad_norm\": [float(x) for x in logs[\"grad_norm\"]],\n",
        "                }\n",
        "                rows.append(row)\n",
        "\n",
        "                print(\n",
        "                    f\"[{norm_cfg}] r={r:2d} {kind:>6} seed={seed} \"\n",
        "                    f\"acc={row['target_acc']:.3f} \"\n",
        "                    f\"gn={row['gradnorm_mean']:.3f} upd={row['update_norm']:.3f}\"\n",
        "                )\n",
        "\n",
        "    return rows\n",
        "\n",
        "# ---------------------------\n",
        "# Run all BN/GN configs and save\n",
        "# ---------------------------\n",
        "all_rows = []\n",
        "for norm_cfg in [\"bn_default\", \"bn_frozen\", \"bn_affine_only\", \"groupnorm\"]:\n",
        "    all_rows.extend(run_experiment(norm_cfg, base_model_path))\n",
        "\n",
        "# Save to drive/project folder\n",
        "os.makedirs(PROJECT_ROOT, exist_ok=True)\n",
        "out_json = os.path.join(PROJECT_ROOT, \"bn_confound_controls_results.json\")\n",
        "with open(out_json, \"w\") as f:\n",
        "    json.dump(all_rows, f, indent=2)\n",
        "print(\"\\nSaved:\", out_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zOaDYRUKTnE",
        "outputId": "f0a1c283-6cfd-40cc-8857-710fa31263db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "\n",
            "===== Running Norm variant: bn_default =====\n",
            "[bn_default] r= 8  major seed=0 acc=0.716 gn=0.891 upd=0.003\n",
            "[bn_default] r= 8  major seed=1 acc=0.721 gn=0.907 upd=0.003\n",
            "[bn_default] r= 8  minor seed=0 acc=0.716 gn=0.874 upd=0.003\n",
            "[bn_default] r= 8  minor seed=1 acc=0.721 gn=0.890 upd=0.003\n",
            "[bn_default] r= 8 random seed=0 acc=0.716 gn=0.878 upd=0.003\n",
            "[bn_default] r= 8 random seed=1 acc=0.721 gn=0.894 upd=0.003\n",
            "[bn_default] r=16  major seed=0 acc=0.716 gn=0.905 upd=0.003\n",
            "[bn_default] r=16  major seed=1 acc=0.721 gn=0.921 upd=0.003\n",
            "[bn_default] r=16  minor seed=0 acc=0.716 gn=0.877 upd=0.003\n",
            "[bn_default] r=16  minor seed=1 acc=0.721 gn=0.894 upd=0.003\n",
            "[bn_default] r=16 random seed=0 acc=0.716 gn=0.884 upd=0.003\n",
            "[bn_default] r=16 random seed=1 acc=0.721 gn=0.900 upd=0.003\n",
            "\n",
            "===== Running Norm variant: bn_frozen =====\n",
            "[bn_frozen] r= 8  major seed=0 acc=0.740 gn=4.191 upd=0.045\n",
            "[bn_frozen] r= 8  major seed=1 acc=0.740 gn=4.011 upd=0.044\n",
            "[bn_frozen] r= 8  minor seed=0 acc=0.740 gn=4.153 upd=0.045\n",
            "[bn_frozen] r= 8  minor seed=1 acc=0.740 gn=3.976 upd=0.044\n",
            "[bn_frozen] r= 8 random seed=0 acc=0.740 gn=4.161 upd=0.045\n",
            "[bn_frozen] r= 8 random seed=1 acc=0.741 gn=3.983 upd=0.044\n",
            "[bn_frozen] r=16  major seed=0 acc=0.740 gn=4.220 upd=0.046\n",
            "[bn_frozen] r=16  major seed=1 acc=0.741 gn=4.039 upd=0.044\n",
            "[bn_frozen] r=16  minor seed=0 acc=0.740 gn=4.161 upd=0.045\n",
            "[bn_frozen] r=16  minor seed=1 acc=0.740 gn=3.983 upd=0.044\n",
            "[bn_frozen] r=16 random seed=0 acc=0.740 gn=4.175 upd=0.045\n",
            "[bn_frozen] r=16 random seed=1 acc=0.741 gn=3.998 upd=0.044\n",
            "\n",
            "===== Running Norm variant: bn_affine_only =====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================\n",
        "# GROUPNORM ONLY (FAST/SAFE)\n",
        "# ============================\n",
        "\n",
        "# --- speed knobs ---\n",
        "GN_EPOCHS = 2          # reduce from 3 if needed\n",
        "GN_MAX_STEPS = 80     # cap steps per epoch (increase if you want more fidelity)\n",
        "GN_SEEDS = [0]      # reduce to [0] if still slow\n",
        "GN_RANKS = [8, 16]\n",
        "GN_SUBSPACES = [\"major\", \"minor\", \"random\"]\n",
        "\n",
        "def train_with_logging_groupnorm_fast(model, train_loaders, epochs=GN_EPOCHS, lr=1e-4, max_steps=GN_MAX_STEPS):\n",
        "    # keep the same \"projected-gradient => projected-update\" purity\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.0, weight_decay=0.0)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    logs = {\"epoch_loss\": [], \"grad_norm\": [], \"update_norm\": []}\n",
        "\n",
        "    # snapshot params for update norm\n",
        "    with torch.no_grad():\n",
        "        init_params = {n: p.detach().clone() for n, p in model.named_parameters() if p.requires_grad}\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        model.train()  # GN has no running stats, so this is fine\n",
        "\n",
        "        iters = [iter(ld) for ld in train_loaders]\n",
        "        steps = min(len(ld) for ld in train_loaders)\n",
        "        steps = min(steps, max_steps)  # <-- SPEED CAP\n",
        "\n",
        "        ep_loss_sum, ep_ex = 0.0, 0\n",
        "        grad_norm_sum, grad_n = 0.0, 0\n",
        "\n",
        "        for _ in range(steps):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # balanced multi-domain accumulation (same as original)\n",
        "            for it_ in iters:\n",
        "                x, y = next(it_)\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y) / len(train_loaders)\n",
        "                loss.backward()\n",
        "                ep_loss_sum += loss.item() * x.size(0)\n",
        "                ep_ex += x.size(0)\n",
        "\n",
        "            # grad norm after projection hooks\n",
        "            with torch.no_grad():\n",
        "                total_g2 = 0.0\n",
        "                for p in model.parameters():\n",
        "                    if p.grad is not None:\n",
        "                        total_g2 += float(p.grad.detach().float().norm().item() ** 2)\n",
        "                grad_norm_sum += total_g2 ** 0.5\n",
        "                grad_n += 1\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "        logs[\"epoch_loss\"].append(ep_loss_sum / max(ep_ex, 1))\n",
        "        logs[\"grad_norm\"].append(grad_norm_sum / max(grad_n, 1))\n",
        "\n",
        "    # update norm\n",
        "    with torch.no_grad():\n",
        "        total_u2 = 0.0\n",
        "        for n, p in model.named_parameters():\n",
        "            if n in init_params:\n",
        "                total_u2 += float((p.detach() - init_params[n]).float().norm().item() ** 2)\n",
        "        logs[\"update_norm\"].append(total_u2 ** 0.5)\n",
        "\n",
        "    return logs\n",
        "\n",
        "\n",
        "def run_groupnorm_only_fast(base_model_path):\n",
        "    rows = []\n",
        "    norm_cfg = \"groupnorm\"\n",
        "    print(f\"\\n===== Running Norm variant: {norm_cfg} (FAST) =====\")\n",
        "    print(f\"epochs={GN_EPOCHS}, max_steps/epoch={GN_MAX_STEPS}, seeds={GN_SEEDS}\")\n",
        "\n",
        "    for r in GN_RANKS:\n",
        "        for kind in GN_SUBSPACES:\n",
        "            for seed in GN_SEEDS:\n",
        "                set_seed(seed)\n",
        "\n",
        "                model = load_baseline_model(base_model_path)\n",
        "                model = apply_norm_config(model, norm_cfg)\n",
        "\n",
        "                apply_subspace_constraints(model, conv_layers, kind, r, seed=seed)\n",
        "\n",
        "                logs = train_with_logging_groupnorm_fast(\n",
        "                    model, train_loaders, epochs=GN_EPOCHS, lr=LR, max_steps=GN_MAX_STEPS\n",
        "                )\n",
        "\n",
        "                acc = eval_accuracy(model, test_loader)\n",
        "\n",
        "                row = {\n",
        "                    \"norm_cfg\": norm_cfg,\n",
        "                    \"rank\": r,\n",
        "                    \"subspace\": kind,\n",
        "                    \"seed\": seed,\n",
        "                    \"target_acc\": float(acc),\n",
        "                    \"gradnorm_mean\": float(np.mean(logs[\"grad_norm\"])),\n",
        "                    \"update_norm\": float(logs[\"update_norm\"][0]),\n",
        "                    \"epoch_loss\": [float(x) for x in logs[\"epoch_loss\"]],\n",
        "                    \"epoch_grad_norm\": [float(x) for x in logs[\"grad_norm\"]],\n",
        "                    \"max_steps\": GN_MAX_STEPS,\n",
        "                    \"epochs\": GN_EPOCHS,\n",
        "                }\n",
        "                rows.append(row)\n",
        "\n",
        "                print(f\"[{norm_cfg}] r={r:2d} {kind:>6} seed={seed} \"\n",
        "                      f\"acc={acc:.3f} gn={row['gradnorm_mean']:.3f} upd={row['update_norm']:.3f}\")\n",
        "\n",
        "    return rows\n",
        "\n",
        "\n",
        "# ---- RUN ONLY GROUPNORM (FAST) ----\n",
        "gn_rows = run_groupnorm_only_fast(base_model_path)\n",
        "\n",
        "# optional: save separately so you can merge later\n",
        "import json, os\n",
        "gn_out = os.path.join(PROJECT_ROOT, \"bn_confound_controls_groupnorm_only_fast.json\")\n",
        "with open(gn_out, \"w\") as f:\n",
        "    json.dump(gn_rows, f, indent=2)\n",
        "print(\"\\nSaved:\", gn_out)\n"
      ],
      "metadata": {
        "id": "sH6wnHLWex8S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "outputId": "54e69a4f-ed4e-4366-aac4-bfef10ddbd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Running Norm variant: groupnorm (FAST) =====\n",
            "epochs=2, max_steps/epoch=80, seeds=[0]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3981718062.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;31m# ---- RUN ONLY GROUPNORM (FAST) ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0mgn_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_groupnorm_only_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# optional: save separately so you can merge later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3981718062.py\u001b[0m in \u001b[0;36mrun_groupnorm_only_fast\u001b[0;34m(base_model_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 )\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 row = {\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-306425771.py\u001b[0m in \u001b[0;36meval_accuracy\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}