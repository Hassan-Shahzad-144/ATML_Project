{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 0 — Baseline Training + Spectral Introspection (PACS, ResNet-18)"
      ],
      "metadata": {
        "id": "vDrAutzzqkBJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIljK3tIqWV9",
        "outputId": "53e12588-0c84-4431-c2a0-3712726d8d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ===== Colab / Drive setup =====\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/SoMA_PACS\"\n",
        "import os\n",
        "os.makedirs(PROJECT_ROOT, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install datasets huggingface_hub pillow\n"
      ],
      "metadata": {
        "id": "rDyYBQY4voPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "VYUqDWR9vvuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "\n",
        "PACS_ROOT = \"/content/drive/MyDrive/DG_PACS/PACS\"\n",
        "assert \"PACS\" in PACS_ROOT\n",
        "if not os.path.exists(PACS_ROOT):\n",
        "    os.makedirs(PACS_ROOT, exist_ok=True)\n",
        "    print(\"Created PACS folder.\")\n",
        "else:\n",
        "    print(\"PACS folder exists. Skipping deletion.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTAgGoZI9NQK",
        "outputId": "7863566d-d73b-45f7-8cd2-06fddcc0ef6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PACS folder exists. Skipping deletion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import os\n",
        "\n",
        "for d in [\"photo\",\"art_painting\",\"cartoon\",\"sketch\"]:\n",
        "    ds = datasets.ImageFolder(os.path.join(PACS_ROOT, d))\n",
        "    print(d, ds.class_to_idx)\n",
        "    assert len(ds.class_to_idx) == 7, f\"{d} does not have 7 classes!\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APKKzaX9v7PE",
        "outputId": "27aedf4a-dd59-49cb-fa62-3a608fcdb5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "photo {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "art_painting {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "cartoon {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "sketch {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import os\n",
        "\n",
        "def get_class_to_idx(domain):\n",
        "    ds = datasets.ImageFolder(root=os.path.join(PACS_ROOT, domain))\n",
        "    return ds.class_to_idx\n",
        "\n",
        "mappings = {d: get_class_to_idx(d) for d in [\"photo\",\"art_painting\",\"cartoon\",\"sketch\"]}\n",
        "for d, m in mappings.items():\n",
        "    print(d, m)\n",
        "\n",
        "# Compare\n",
        "base = mappings[\"photo\"]\n",
        "for d in mappings:\n",
        "    print(d, \"matches photo:\", mappings[d] == base)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLeEk0W78h3U",
        "outputId": "8ad589d0-44cf-4cab-e004-b078af3f92ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "photo {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "art_painting {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "cartoon {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "sketch {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "photo matches photo: True\n",
            "art_painting matches photo: True\n",
            "cartoon matches photo: True\n",
            "sketch matches photo: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Reproducibility =====\n",
        "import random, numpy as np, torch\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ===== Imports =====\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "B1BKeNMtqweA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== PACS paths (edit if needed) =====\n",
        "# PACS_ROOT = \"/content/drive/MyDrive/datasets/PACS\"\n",
        "\n",
        "SOURCE_DOMAINS = [\"photo\", \"art_painting\", \"cartoon\"]\n",
        "TARGET_DOMAIN = \"sketch\"\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n"
      ],
      "metadata": {
        "id": "nyuH-0aNqy94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "vxXugoPcq68T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_loader(domain, tf, shuffle):\n",
        "    ds = datasets.ImageFolder(\n",
        "        root=os.path.join(PACS_ROOT, domain),\n",
        "        transform=tf\n",
        "    )\n",
        "    return DataLoader(ds, batch_size=BATCH_SIZE,\n",
        "                      shuffle=shuffle, num_workers=NUM_WORKERS)\n",
        "\n",
        "train_loaders = [make_loader(d, train_tf, True) for d in SOURCE_DOMAINS]\n",
        "test_loader = make_loader(TARGET_DOMAIN, test_tf, False)\n"
      ],
      "metadata": {
        "id": "ttQEGt7Wq77l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18_FeatureHook(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "        self.backbone.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "        self._features = {}\n",
        "\n",
        "        def make_hook(name):\n",
        "            def hook(module, inp, out):\n",
        "                self._features[name] = out\n",
        "            return hook\n",
        "\n",
        "        # register hooks: BN output before ReLU\n",
        "        for lname in [\"layer2\", \"layer3\", \"layer4\"]:\n",
        "            layer = getattr(self.backbone, lname)\n",
        "            for i, block in enumerate(layer):\n",
        "                block.bn2.register_forward_hook(\n",
        "                    make_hook(f\"{lname}.{i}.bn2\")\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self._features = {}\n",
        "        return self.backbone(x)\n"
      ],
      "metadata": {
        "id": "l99DjWkirYoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop (Tier-0 backbone)"
      ],
      "metadata": {
        "id": "7Pi4sspmrclb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "DlRWTqesrZmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb399b87-573e-4328-90d1-3004248d7ecf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 192MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(loaders):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total = 0, 0, 0\n",
        "\n",
        "    for loader in loaders:\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            total_correct += (logits.argmax(1) == y).sum().item()\n",
        "            total += x.size(0)\n",
        "\n",
        "    return total_loss / total, total_correct / total\n"
      ],
      "metadata": {
        "id": "CLlKwixlri-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_epoch(loader):\n",
        "    model.eval()\n",
        "    total_correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        total_correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += x.size(0)\n",
        "    return total_correct / total\n"
      ],
      "metadata": {
        "id": "2IX_rRa1rmDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
      ],
      "metadata": {
        "id": "hRN6Rvde_EXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "for ep in range(EPOCHS):\n",
        "    tr_loss, tr_acc = train_epoch(train_loaders)\n",
        "    te_acc = eval_epoch(test_loader)\n",
        "\n",
        "    print(f\"[{ep:02d}] loss={tr_loss:.3f} | src_acc={tr_acc:.3f} | tgt_acc={te_acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p88rTDJTrpo1",
        "outputId": "f40de4a0-4b56-409f-f794-e35982f4c7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00] loss=0.386 | src_acc=0.874 | tgt_acc=0.661\n",
            "[01] loss=0.213 | src_acc=0.929 | tgt_acc=0.632\n",
            "[02] loss=0.144 | src_acc=0.953 | tgt_acc=0.680\n",
            "[03] loss=0.123 | src_acc=0.958 | tgt_acc=0.652\n",
            "[04] loss=0.085 | src_acc=0.972 | tgt_acc=0.725\n",
            "[05] loss=0.058 | src_acc=0.981 | tgt_acc=0.718\n",
            "[06] loss=0.105 | src_acc=0.967 | tgt_acc=0.733\n",
            "[07] loss=0.063 | src_acc=0.982 | tgt_acc=0.708\n",
            "[08] loss=0.061 | src_acc=0.981 | tgt_acc=0.688\n",
            "[09] loss=0.074 | src_acc=0.976 | tgt_acc=0.754\n",
            "[10] loss=0.031 | src_acc=0.990 | tgt_acc=0.722\n",
            "[11] loss=0.028 | src_acc=0.991 | tgt_acc=0.732\n",
            "[12] loss=0.063 | src_acc=0.979 | tgt_acc=0.699\n",
            "[13] loss=0.044 | src_acc=0.986 | tgt_acc=0.708\n",
            "[14] loss=0.038 | src_acc=0.987 | tgt_acc=0.736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save trained backbone"
      ],
      "metadata": {
        "id": "rhPHDh_2k18U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE_PATH = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "\n",
        "torch.save(model.state_dict(), BACKBONE_PATH)\n",
        "print(\"Saved PACS-trained backbone.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEjSvSJ4kQNh",
        "outputId": "2ce6a611-c9e2-45c0-a00e-28b5740a3cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PACS-trained backbone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TIER 0 — SPECTRAL INTROSPECTION"
      ],
      "metadata": {
        "id": "wzZQ1Auvrz-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy.linalg as LA\n",
        "\n",
        "def conv_svd(conv):\n",
        "    # conv.weight: [C_out, C_in, k, k]\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    Cout = W.shape[0]\n",
        "    Wmat = W.reshape(Cout, -1)\n",
        "    U, S, Vt = LA.svd(Wmat, full_matrices=False)\n",
        "    return U, S\n"
      ],
      "metadata": {
        "id": "Yi-RCY5grvg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectra = {}\n",
        "\n",
        "for lname in [\"layer2\", \"layer3\", \"layer4\"]:\n",
        "    for i, block in enumerate(getattr(model.backbone, lname)):\n",
        "        conv = block.conv2\n",
        "        U, S = conv_svd(conv)\n",
        "        spectra[f\"{lname}.{i}\"] = S\n"
      ],
      "metadata": {
        "id": "qjj5dqeur4O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(f\"{PROJECT_ROOT}/tier0_spectra.pkl\", \"wb\") as f:\n",
        "    pickle.dump(spectra, f)\n"
      ],
      "metadata": {
        "id": "pAuAenK-r5Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-0 Feature Statistics (Energy by Spectral Rank)"
      ],
      "metadata": {
        "id": "LFyi2onlsIIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def collect_feature_energy(loader):\n",
        "    model.eval()\n",
        "    energy = {}\n",
        "\n",
        "    for x, _ in loader:\n",
        "        x = x.to(device)\n",
        "        _ = model(x)\n",
        "\n",
        "        for k, feat in model._features.items():\n",
        "            # GAP → channel vector\n",
        "            h = feat.mean(dim=[2,3])  # [B, C]\n",
        "            e = (h**2).mean(0).cpu().numpy()\n",
        "            energy.setdefault(k, []).append(e)\n",
        "\n",
        "    for k in energy:\n",
        "        energy[k] = np.mean(energy[k], axis=0)\n",
        "\n",
        "    return energy\n"
      ],
      "metadata": {
        "id": "_d_MnlDssABX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_energy = collect_feature_energy(train_loaders[0])\n",
        "tgt_energy = collect_feature_energy(test_loader)\n",
        "\n",
        "with open(f\"{PROJECT_ROOT}/tier0_feature_energy.pkl\", \"wb\") as f:\n",
        "    pickle.dump({\"src\": src_energy, \"tgt\": tgt_energy}, f)\n"
      ],
      "metadata": {
        "id": "vEZ4uVIbsMA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saved to Drive\n",
        "\n",
        "- tier0_spectra.pkl → singular values per conv layer\n",
        "\n",
        "- tier0_feature_energy.pkl → channel-wise activation energy (src vs tgt)\n",
        "\n",
        "- trained baseline checkpoint (implicitly in model state)\n",
        "\n",
        "\n",
        "\n",
        "Scientific baseline\n",
        "\n",
        "- no spectral intervention\n",
        "\n",
        "- no leakage\n",
        "\n",
        "- fixed feature definition\n",
        "\n",
        "- BN explicitly visible"
      ],
      "metadata": {
        "id": "4Luz-YI4scu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# =============================================================================\n",
        "# TIER 1 - SCENARIO 1: Probing the PRETRAINED ImageNet Model\n",
        "\n",
        "This tests whether the pretrained model (before any PACS finetuning) already has spectral structure that separates domain from class information.\n"
      ],
      "metadata": {
        "id": "UtXng4HEckLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 0: Re-define the Model Class with ALL Layer Hooks (Run this first!)\n",
        "# -----------------------------------------------------------------------------\n",
        "# This ensures hooks are registered for ALL layers including layer1\n",
        "\n",
        "class ResNet18_FeatureHook(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "        self.backbone.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "        self._features = {}\n",
        "\n",
        "        def make_hook(name):\n",
        "            def hook(module, inp, out):\n",
        "                self._features[name] = out\n",
        "            return hook\n",
        "\n",
        "        # Register hooks for ALL layers (layer1, layer2, layer3, layer4)\n",
        "        for lname in [\"layer1\", \"layer2\", \"layer3\", \"layer4\"]:\n",
        "            layer = getattr(self.backbone, lname)\n",
        "            for i, block in enumerate(layer):\n",
        "                block.bn2.register_forward_hook(\n",
        "                    make_hook(f\"{lname}.{i}.bn2\")\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self._features = {}  # Clear before each forward pass\n",
        "        return self.backbone(x)\n",
        "\n",
        "print(\"ResNet18_FeatureHook class defined with hooks for layer1, layer2, layer3, layer4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHVgYLzMlWYN",
        "outputId": "9100b5e9-5750-4653-f59c-98968060df8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet18_FeatureHook class defined with hooks for layer1, layer2, layer3, layer4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 1: Load Fresh Pretrained Model and Verify Hooks\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "print(\"Loading fresh pretrained ResNet-18 (ImageNet weights only)...\")\n",
        "\n",
        "pretrained_model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "\n",
        "# Reset fc layer (doesn't affect feature extraction)\n",
        "nn.init.xavier_uniform_(pretrained_model.backbone.fc.weight)\n",
        "nn.init.zeros_(pretrained_model.backbone.fc.bias)\n",
        "\n",
        "pretrained_model.eval()\n",
        "\n",
        "# VERIFY: Run a test forward pass and check that hooks are working\n",
        "print(\"\\nVerifying hooks are registered correctly...\")\n",
        "test_input = torch.randn(1, 3, 224, 224).to(device)\n",
        "with torch.no_grad():\n",
        "    _ = pretrained_model(test_input)\n",
        "\n",
        "print(f\"Keys in _features after forward pass: {sorted(pretrained_model._features.keys())}\")\n",
        "\n",
        "# Check we have all expected keys\n",
        "expected_keys = [f\"{l}.{i}.bn2\" for l in [\"layer1\", \"layer2\", \"layer3\", \"layer4\"] for i in [0, 1]]\n",
        "missing_keys = [k for k in expected_keys if k not in pretrained_model._features]\n",
        "\n",
        "if missing_keys:\n",
        "    print(f\"\\n⚠️  WARNING: Missing hooks for: {missing_keys}\")\n",
        "    print(\"Please re-run the cell that defines ResNet18_FeatureHook class!\")\n",
        "else:\n",
        "    print(\"\\n✓ All hooks registered correctly!\")\n",
        "    print(\"Pretrained model ready. This model has NEVER seen PACS data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOt5APyxcj9_",
        "outputId": "204c2e95-0980-4376-afeb-2b191d2c8e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading fresh pretrained ResNet-18 (ImageNet weights only)...\n",
            "\n",
            "Verifying hooks are registered correctly...\n",
            "Keys in _features after forward pass: ['layer1.0.bn2', 'layer1.1.bn2', 'layer2.0.bn2', 'layer2.1.bn2', 'layer3.0.bn2', 'layer3.1.bn2', 'layer4.0.bn2', 'layer4.1.bn2']\n",
            "\n",
            "✓ All hooks registered correctly!\n",
            "Pretrained model ready. This model has NEVER seen PACS data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 2: Feature Extraction with Per-Domain Tracking (with error handling)\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "@torch.no_grad()\n",
        "def extract_gap_features_v2(model, domains, layer_name):\n",
        "    \"\"\"\n",
        "    Extract globally-averaged-pooled features with domain tracking.\n",
        "\n",
        "    Args:\n",
        "        model: The model to extract features from\n",
        "        domains: List of domain names to process\n",
        "        layer_name: Which layer to extract from (e.g., \"layer4.1\")\n",
        "\n",
        "    Returns:\n",
        "        X: (N, C) feature matrix\n",
        "        y_class: (N,) class labels\n",
        "        y_domain: (N,) domain labels (0-indexed)\n",
        "        domain_names: List mapping domain index to name\n",
        "    \"\"\"\n",
        "    DOMAIN_TO_ID = {\n",
        "        \"photo\": 0,\n",
        "        \"art_painting\": 1,\n",
        "        \"cartoon\": 2,\n",
        "        \"sketch\": 3,\n",
        "    }\n",
        "\n",
        "    # The key format in _features\n",
        "    feature_key = f\"{layer_name}.bn2\"\n",
        "\n",
        "    X, y_class, y_domain = [], [], []\n",
        "    model.eval()\n",
        "\n",
        "    for domain in domains:\n",
        "        loader = make_loader(domain, test_tf, shuffle=False)\n",
        "        d_id = DOMAIN_TO_ID[domain]\n",
        "\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            _ = model(x)\n",
        "\n",
        "            # Check if the key exists\n",
        "            if feature_key not in model._features:\n",
        "                available_keys = list(model._features.keys())\n",
        "                raise KeyError(\n",
        "                    f\"Key '{feature_key}' not found in model._features.\\n\"\n",
        "                    f\"Available keys: {sorted(available_keys)}\\n\"\n",
        "                    f\"Please re-run the cell that defines ResNet18_FeatureHook class.\"\n",
        "                )\n",
        "\n",
        "            feat = model._features[feature_key]\n",
        "            h = feat.mean(dim=[2, 3]).cpu().numpy()  # Global Average Pooling\n",
        "\n",
        "            X.append(h)\n",
        "            y_class.append(y.numpy())\n",
        "            y_domain.append(np.full(h.shape[0], d_id))\n",
        "\n",
        "    return (\n",
        "        np.concatenate(X),\n",
        "        np.concatenate(y_class),\n",
        "        np.concatenate(y_domain),\n",
        "        domains,\n",
        "    )"
      ],
      "metadata": {
        "id": "MpG8o4OQc28E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 3: Probe Training with Per-Domain Accuracy Breakdown\n",
        "# -----------------------------------------------------------------------------\n",
        "# This function trains a linear probe and computes accuracy both overall\n",
        "# and broken down by domain.\n",
        "\n",
        "def train_probe_with_breakdown(dataset, num_classes, y_domain_full, domain_names,\n",
        "                                seed=0, epochs=50, train_frac=0.7):\n",
        "    \"\"\"\n",
        "    Train a linear probe and return both overall and per-domain accuracy.\n",
        "\n",
        "    The per-domain breakdown shows how well the probe classifies samples\n",
        "    FROM each domain. For a domain probe, this tells us which domains are\n",
        "    easiest/hardest to identify.\n",
        "\n",
        "    Args:\n",
        "        dataset: ProjectedDataset with X and y\n",
        "        num_classes: Number of output classes\n",
        "        y_domain_full: Full array of domain labels (before train/val split)\n",
        "        domain_names: List of domain name strings\n",
        "        seed: Random seed\n",
        "        epochs: Training epochs\n",
        "        train_frac: Fraction for training (rest is validation)\n",
        "\n",
        "    Returns:\n",
        "        overall_acc: Float, overall validation accuracy\n",
        "        per_domain_acc: Dict mapping domain name -> accuracy for that domain's samples\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    n = len(dataset)\n",
        "    n_train = int(train_frac * n)\n",
        "\n",
        "    # Create shuffled indices\n",
        "    indices = np.random.permutation(n)\n",
        "    train_indices = indices[:n_train]\n",
        "    val_indices = indices[n_train:]\n",
        "\n",
        "    train_ds = torch.utils.data.Subset(dataset, train_indices.tolist())\n",
        "    val_ds = torch.utils.data.Subset(dataset, val_indices.tolist())\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "    # Initialize and train probe\n",
        "    probe = LinearProbe(dataset.X.shape[1], num_classes).to(device)\n",
        "    opt = torch.optim.Adam(probe.parameters(), lr=1e-2)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    probe.train()\n",
        "    for _ in range(epochs):\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss_fn(probe(x), y).backward()\n",
        "            opt.step()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    probe.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x = x.to(device)\n",
        "            pred = probe(x).argmax(1).cpu().numpy()\n",
        "            all_preds.append(pred)\n",
        "            all_labels.append(y.numpy())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    # Get domain labels for validation samples\n",
        "    val_domain_labels = y_domain_full[val_indices]\n",
        "\n",
        "    # Overall accuracy\n",
        "    overall_acc = (all_preds == all_labels).mean()\n",
        "\n",
        "    # Per-domain accuracy\n",
        "    # For each domain, how accurate is the probe on samples FROM that domain?\n",
        "    per_domain_acc = {}\n",
        "    for d_idx, d_name in enumerate(domain_names):\n",
        "        mask = val_domain_labels == d_idx\n",
        "        if mask.sum() > 0:\n",
        "            per_domain_acc[d_name] = (all_preds[mask] == all_labels[mask]).mean()\n",
        "        else:\n",
        "            per_domain_acc[d_name] = np.nan\n",
        "\n",
        "    return overall_acc, per_domain_acc"
      ],
      "metadata": {
        "id": "sLTuUSUac4v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 4: Main Probing Function with Full Reporting\n",
        "# -----------------------------------------------------------------------------\n",
        "# This runs the complete probe analysis for a given model, reporting both\n",
        "# combined accuracy and per-domain breakdown.\n",
        "\n",
        "def run_full_probe_analysis(model, layer_name, conv, domains, ranks, seeds,\n",
        "                            probe_type=\"domain\", exclude_photo=False):\n",
        "    \"\"\"\n",
        "    Run complete probe analysis with per-domain breakdown.\n",
        "\n",
        "    Args:\n",
        "        model: Model to analyze\n",
        "        layer_name: Layer name (e.g., \"layer4.1\")\n",
        "        conv: The conv layer to get SVD from\n",
        "        domains: List of domains to include\n",
        "        ranks: List of ranks to test\n",
        "        seeds: List of random seeds for averaging\n",
        "        probe_type: \"domain\" or \"class\"\n",
        "        exclude_photo: If True, exclude photo from analysis\n",
        "\n",
        "    Returns:\n",
        "        results: Nested dict with all results\n",
        "    \"\"\"\n",
        "    # Optionally exclude photo\n",
        "    if exclude_photo:\n",
        "        domains = [d for d in domains if d != \"photo\"]\n",
        "\n",
        "    num_classes = len(domains) if probe_type == \"domain\" else 7\n",
        "\n",
        "    # Get SVD of conv layer\n",
        "    U, S = get_conv_svd(conv)\n",
        "\n",
        "    # Extract features\n",
        "    X, y_class, y_domain, domain_names = extract_gap_features_v2(model, domains, layer_name)\n",
        "\n",
        "    # Choose labels based on probe type\n",
        "    y_labels = y_domain if probe_type == \"domain\" else y_class\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for r in ranks:\n",
        "        results[r] = {}\n",
        "\n",
        "        for kind in [\"major\", \"minor\", \"random\"]:\n",
        "            overall_accs = []\n",
        "            per_domain_accs = {d: [] for d in domains}\n",
        "\n",
        "            for seed in seeds:\n",
        "                # Get subspace basis\n",
        "                Usub = get_subspace(U, kind, r, seed)\n",
        "\n",
        "                # Create projected dataset\n",
        "                ds = ProjectedDataset(X, y_labels, Usub)\n",
        "\n",
        "                # Train probe with breakdown\n",
        "                overall_acc, per_domain = train_probe_with_breakdown(\n",
        "                    ds, num_classes=num_classes,\n",
        "                    y_domain_full=y_domain,\n",
        "                    domain_names=domains,\n",
        "                    seed=seed\n",
        "                )\n",
        "\n",
        "                overall_accs.append(overall_acc)\n",
        "                for d in domains:\n",
        "                    if d in per_domain and not np.isnan(per_domain[d]):\n",
        "                        per_domain_accs[d].append(per_domain[d])\n",
        "\n",
        "            # Store results\n",
        "            results[r][kind] = {\n",
        "                'overall_mean': np.mean(overall_accs),\n",
        "                'overall_std': np.std(overall_accs),\n",
        "                'per_domain': {\n",
        "                    d: {\n",
        "                        'mean': np.mean(per_domain_accs[d]) if per_domain_accs[d] else np.nan,\n",
        "                        'std': np.std(per_domain_accs[d]) if per_domain_accs[d] else np.nan\n",
        "                    }\n",
        "                    for d in domains\n",
        "                }\n",
        "            }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def print_probe_results(results, layer_name, probe_type, domains):\n",
        "    \"\"\"Pretty-print probe results with per-domain breakdown.\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"{probe_type.upper()} PROBE @ {layer_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    for r, r_results in results.items():\n",
        "        print(f\"\\n--- Rank {r} ---\")\n",
        "        print(f\"{'Subspace':<10} {'Overall':<18} | Per-Domain Accuracy\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        for kind in [\"major\", \"minor\", \"random\"]:\n",
        "            data = r_results[kind]\n",
        "            overall_str = f\"{data['overall_mean']:.3f} ± {data['overall_std']:.3f}\"\n",
        "\n",
        "            # Per-domain string\n",
        "            per_domain_parts = []\n",
        "            for d in domains:\n",
        "                d_short = d[:4]  # Abbreviate domain names\n",
        "                d_acc = data['per_domain'][d]['mean']\n",
        "                if not np.isnan(d_acc):\n",
        "                    per_domain_parts.append(f\"{d_short}:{d_acc:.2f}\")\n",
        "            per_domain_str = \", \".join(per_domain_parts)\n",
        "\n",
        "            print(f\"{kind:<10} {overall_str:<18} | {per_domain_str}\")\n",
        "\n",
        "        # Print gap analysis\n",
        "        major_overall = r_results['major']['overall_mean']\n",
        "        minor_overall = r_results['minor']['overall_mean']\n",
        "        gap = minor_overall - major_overall\n",
        "        gap_sign = \"+\" if gap > 0 else \"\"\n",
        "        print(f\"\\n  Gap (minor - major): {gap_sign}{gap:.3f}\")\n",
        "        if probe_type == \"domain\":\n",
        "            if gap > 0.02:\n",
        "                print(\"  → Minor has MORE domain info (supports SoMA hypothesis)\")\n",
        "            elif gap < -0.02:\n",
        "                print(\"  → Major has MORE domain info (contradicts SoMA hypothesis)\")\n",
        "            else:\n",
        "                print(\"  → No clear difference\")"
      ],
      "metadata": {
        "id": "pGDNvJm8c8Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# DIAGNOSTIC: Check what's in pretrained_model._features\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "print(\"Testing pretrained_model hooks...\")\n",
        "pretrained_model.eval()\n",
        "\n",
        "# Run a single forward pass\n",
        "test_batch = torch.randn(2, 3, 224, 224).to(device)\n",
        "with torch.no_grad():\n",
        "    _ = pretrained_model(test_batch)\n",
        "\n",
        "print(f\"\\nNumber of keys: {len(pretrained_model._features)}\")\n",
        "print(f\"Keys: {sorted(pretrained_model._features.keys())}\")\n",
        "\n",
        "# Check shapes\n",
        "for key, feat in pretrained_model._features.items():\n",
        "    print(f\"  {key}: {feat.shape}\")\n",
        "# ```\n",
        "\n",
        "# **Expected output:**\n",
        "# ```\n",
        "# Testing pretrained_model hooks...\n",
        "\n",
        "# Number of keys: 8\n",
        "# Keys: ['layer1.0.bn2', 'layer1.1.bn2', 'layer2.0.bn2', 'layer2.1.bn2', 'layer3.0.bn2', 'layer3.1.bn2', 'layer4.0.bn2', 'layer4.1.bn2']\n",
        "#   layer1.0.bn2: torch.Size([2, 64, 56, 56])\n",
        "#   layer1.1.bn2: torch.Size([2, 64, 56, 56])\n",
        "#   layer2.0.bn2: torch.Size([2, 128, 28, 28])\n",
        "  # ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLdKkxrWlrDo",
        "outputId": "326e6dfc-e438-454d-9ecd-bfad4b2fcac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing pretrained_model hooks...\n",
            "\n",
            "Number of keys: 8\n",
            "Keys: ['layer1.0.bn2', 'layer1.1.bn2', 'layer2.0.bn2', 'layer2.1.bn2', 'layer3.0.bn2', 'layer3.1.bn2', 'layer4.0.bn2', 'layer4.1.bn2']\n",
            "  layer1.0.bn2: torch.Size([2, 64, 56, 56])\n",
            "  layer1.1.bn2: torch.Size([2, 64, 56, 56])\n",
            "  layer2.0.bn2: torch.Size([2, 128, 28, 28])\n",
            "  layer2.1.bn2: torch.Size([2, 128, 28, 28])\n",
            "  layer3.0.bn2: torch.Size([2, 256, 14, 14])\n",
            "  layer3.1.bn2: torch.Size([2, 256, 14, 14])\n",
            "  layer4.0.bn2: torch.Size([2, 512, 7, 7])\n",
            "  layer4.1.bn2: torch.Size([2, 512, 7, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 5: Run Scenario 1 - Domain Probe on PRETRAINED Model (All 4 Domains)\n",
        "# -----------------------------------------------------------------------------\n",
        "# This probes the pretrained model on ALL conv blocks to see if domain info\n",
        "# is naturally concentrated in the minor subspace BEFORE any finetuning.\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"SCENARIO 1: Probing PRETRAINED ImageNet Model\")\n",
        "print(\"Testing if pretrained spectral structure already separates domain info\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Configuration\n",
        "domains_all = [\"photo\", \"art_painting\", \"cartoon\", \"sketch\"]\n",
        "ranks = [4, 8, 16]\n",
        "seeds = [0, 1, 2]\n",
        "\n",
        "# Get conv blocks from pretrained model (ALL layers)\n",
        "pretrained_conv_blocks = {}\n",
        "for lname in [\"layer1\", \"layer2\", \"layer3\", \"layer4\"]:\n",
        "    layer = getattr(pretrained_model.backbone, lname)\n",
        "    for i, block in enumerate(layer):\n",
        "        key = f\"{lname}.{i}\"\n",
        "        pretrained_conv_blocks[key] = block.conv2\n",
        "\n",
        "# Store all results\n",
        "scenario1_domain_results = {}\n",
        "\n",
        "print(\"\\n===== DOMAIN PROBES (ALL CONV BLOCKS) - PRETRAINED MODEL =====\")\n",
        "\n",
        "# Loop over ALL conv blocks\n",
        "for layer_name, conv in pretrained_conv_blocks.items():\n",
        "\n",
        "    results = run_full_probe_analysis(\n",
        "        model=pretrained_model,\n",
        "        layer_name=layer_name,\n",
        "        conv=conv,\n",
        "        domains=domains_all,\n",
        "        ranks=ranks,\n",
        "        seeds=seeds,\n",
        "        probe_type=\"domain\",\n",
        "        exclude_photo=False\n",
        "    )\n",
        "\n",
        "    scenario1_domain_results[layer_name] = results\n",
        "    print_probe_results(results, layer_name, \"domain\", domains_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uMtZ8WOc_Js",
        "outputId": "952c249b-336e-4083-df0b-214c446e6315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SCENARIO 1: Probing PRETRAINED ImageNet Model\n",
            "Testing if pretrained spectral structure already separates domain info\n",
            "======================================================================\n",
            "\n",
            "===== DOMAIN PROBES (ALL CONV BLOCKS) - PRETRAINED MODEL =====\n",
            "\n",
            "======================================================================\n",
            "DOMAIN PROBE @ layer1.0\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.746 ± 0.009      | phot:0.33, art_:0.70, cart:0.66, sket:1.00\n",
            "minor      0.696 ± 0.012      | phot:0.41, art_:0.73, cart:0.34, sket:1.00\n",
            "random     0.655 ± 0.023      | phot:0.23, art_:0.62, cart:0.41, sket:1.00\n",
            "\n",
            "  Gap (minor - major): -0.051\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.790 ± 0.002      | phot:0.49, art_:0.67, cart:0.76, sket:0.99\n",
            "minor      0.777 ± 0.013      | phot:0.65, art_:0.69, cart:0.56, sket:1.00\n",
            "random     0.777 ± 0.002      | phot:0.63, art_:0.62, cart:0.65, sket:1.00\n",
            "\n",
            "  Gap (minor - major): -0.013\n",
            "  → No clear difference\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.858 ± 0.001      | phot:0.77, art_:0.68, cart:0.84, sket:1.00\n",
            "minor      0.835 ± 0.004      | phot:0.74, art_:0.66, cart:0.78, sket:1.00\n",
            "random     0.833 ± 0.025      | phot:0.71, art_:0.68, cart:0.78, sket:1.00\n",
            "\n",
            "  Gap (minor - major): -0.024\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "======================================================================\n",
            "DOMAIN PROBE @ layer1.1\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.764 ± 0.002      | phot:0.02, art_:0.89, cart:0.78, sket:1.00\n",
            "minor      0.674 ± 0.008      | phot:0.38, art_:0.70, cart:0.31, sket:1.00\n",
            "random     0.679 ± 0.053      | phot:0.25, art_:0.68, cart:0.44, sket:1.00\n",
            "\n",
            "  Gap (minor - major): -0.090\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.779 ± 0.003      | phot:0.29, art_:0.75, cart:0.79, sket:1.00\n",
            "minor      0.770 ± 0.004      | phot:0.59, art_:0.64, cart:0.63, sket:1.00\n",
            "random     0.768 ± 0.035      | phot:0.51, art_:0.66, cart:0.66, sket:1.00\n",
            "\n",
            "  Gap (minor - major): -0.010\n",
            "  → No clear difference\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.866 ± 0.005      | phot:0.67, art_:0.73, cart:0.90, sket:1.00\n",
            "minor      0.837 ± 0.002      | phot:0.74, art_:0.68, cart:0.77, sket:1.00\n",
            "random     0.859 ± 0.008      | phot:0.71, art_:0.72, cart:0.85, sket:1.00\n",
            "\n",
            "  Gap (minor - major): -0.029\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "======================================================================\n",
            "DOMAIN PROBE @ layer2.0\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.652 ± 0.010      | phot:0.07, art_:0.64, cart:0.52, sket:0.98\n",
            "minor      0.705 ± 0.012      | phot:0.13, art_:0.64, cart:0.67, sket:1.00\n",
            "random     0.703 ± 0.033      | phot:0.17, art_:0.76, cart:0.53, sket:1.00\n",
            "\n",
            "  Gap (minor - major): +0.053\n",
            "  → Minor has MORE domain info (supports SoMA hypothesis)\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.797 ± 0.006      | phot:0.41, art_:0.76, cart:0.77, sket:0.99\n",
            "minor      0.801 ± 0.004      | phot:0.57, art_:0.67, cart:0.74, sket:1.00\n",
            "random     0.824 ± 0.012      | phot:0.55, art_:0.74, cart:0.79, sket:1.00\n",
            "\n",
            "  Gap (minor - major): +0.005\n",
            "  → No clear difference\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.853 ± 0.004      | phot:0.68, art_:0.71, cart:0.86, sket:1.00\n",
            "minor      0.860 ± 0.002      | phot:0.72, art_:0.74, cart:0.82, sket:1.00\n",
            "random     0.862 ± 0.008      | phot:0.71, art_:0.72, cart:0.86, sket:1.00\n",
            "\n",
            "  Gap (minor - major): +0.006\n",
            "  → No clear difference\n",
            "\n",
            "======================================================================\n",
            "DOMAIN PROBE @ layer2.1\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.800 ± 0.009      | phot:0.26, art_:0.81, cart:0.84, sket:1.00\n",
            "minor      0.741 ± 0.013      | phot:0.40, art_:0.66, cart:0.61, sket:1.00\n",
            "random     0.672 ± 0.079      | phot:0.24, art_:0.62, cart:0.49, sket:0.99\n",
            "\n",
            "  Gap (minor - major): -0.059\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.844 ± 0.002      | phot:0.56, art_:0.77, cart:0.85, sket:1.00\n",
            "minor      0.791 ± 0.008      | phot:0.54, art_:0.67, cart:0.72, sket:1.00\n",
            "random     0.819 ± 0.015      | phot:0.54, art_:0.72, cart:0.79, sket:1.00\n",
            "\n",
            "  Gap (minor - major): -0.053\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.890 ± 0.005      | phot:0.77, art_:0.79, cart:0.87, sket:1.00\n",
            "minor      0.844 ± 0.005      | phot:0.68, art_:0.72, cart:0.81, sket:1.00\n",
            "random     0.874 ± 0.010      | phot:0.72, art_:0.76, cart:0.87, sket:1.00\n",
            "\n",
            "  Gap (minor - major): -0.046\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "======================================================================\n",
            "DOMAIN PROBE @ layer3.0\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.773 ± 0.007      | phot:0.23, art_:0.70, cart:0.84, sket:1.00\n",
            "minor      0.693 ± 0.009      | phot:0.22, art_:0.54, cart:0.64, sket:1.00\n",
            "random     0.694 ± 0.057      | phot:0.22, art_:0.69, cart:0.53, sket:0.99\n",
            "\n",
            "  Gap (minor - major): -0.080\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.827 ± 0.005      | phot:0.46, art_:0.70, cart:0.91, sket:1.00\n",
            "minor      0.816 ± 0.004      | phot:0.49, art_:0.73, cart:0.81, sket:1.00\n",
            "random     0.795 ± 0.015      | phot:0.54, art_:0.61, cart:0.79, sket:1.00\n",
            "\n",
            "  Gap (minor - major): -0.011\n",
            "  → No clear difference\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.880 ± 0.000      | phot:0.70, art_:0.73, cart:0.94, sket:1.00\n",
            "minor      0.881 ± 0.004      | phot:0.73, art_:0.78, cart:0.88, sket:1.00\n",
            "random     0.857 ± 0.019      | phot:0.67, art_:0.72, cart:0.86, sket:1.00\n",
            "\n",
            "  Gap (minor - major): +0.001\n",
            "  → No clear difference\n",
            "\n",
            "======================================================================\n",
            "DOMAIN PROBE @ layer3.1\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.694 ± 0.013      | phot:0.75, art_:0.36, cart:0.43, sket:1.00\n",
            "minor      0.757 ± 0.001      | phot:0.57, art_:0.55, cart:0.66, sket:1.00\n",
            "random     0.687 ± 0.030      | phot:0.19, art_:0.68, cart:0.53, sket:0.99\n",
            "\n",
            "  Gap (minor - major): +0.063\n",
            "  → Minor has MORE domain info (supports SoMA hypothesis)\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.768 ± 0.007      | phot:0.73, art_:0.60, cart:0.56, sket:0.99\n",
            "minor      0.808 ± 0.004      | phot:0.66, art_:0.63, cart:0.74, sket:1.00\n",
            "random     0.816 ± 0.023      | phot:0.60, art_:0.66, cart:0.80, sket:1.00\n",
            "\n",
            "  Gap (minor - major): +0.039\n",
            "  → Minor has MORE domain info (supports SoMA hypothesis)\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.883 ± 0.001      | phot:0.75, art_:0.81, cart:0.87, sket:0.99\n",
            "minor      0.870 ± 0.005      | phot:0.77, art_:0.73, cart:0.84, sket:1.00\n",
            "random     0.866 ± 0.024      | phot:0.73, art_:0.77, cart:0.82, sket:1.00\n",
            "\n",
            "  Gap (minor - major): -0.013\n",
            "  → No clear difference\n",
            "\n",
            "======================================================================\n",
            "DOMAIN PROBE @ layer4.0\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.750 ± 0.006      | phot:0.47, art_:0.53, cart:0.74, sket:0.99\n",
            "minor      0.731 ± 0.004      | phot:0.43, art_:0.63, cart:0.58, sket:1.00\n",
            "random     0.702 ± 0.018      | phot:0.46, art_:0.61, cart:0.51, sket:0.96\n",
            "\n",
            "  Gap (minor - major): -0.019\n",
            "  → No clear difference\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.813 ± 0.002      | phot:0.67, art_:0.66, cart:0.75, sket:0.99\n",
            "minor      0.770 ± 0.005      | phot:0.53, art_:0.63, cart:0.68, sket:1.00\n",
            "random     0.733 ± 0.017      | phot:0.49, art_:0.59, cart:0.64, sket:0.96\n",
            "\n",
            "  Gap (minor - major): -0.044\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.870 ± 0.005      | phot:0.73, art_:0.70, cart:0.90, sket:1.00\n",
            "minor      0.858 ± 0.005      | phot:0.65, art_:0.75, cart:0.86, sket:1.00\n",
            "random     0.872 ± 0.008      | phot:0.72, art_:0.78, cart:0.85, sket:0.99\n",
            "\n",
            "  Gap (minor - major): -0.011\n",
            "  → No clear difference\n",
            "\n",
            "======================================================================\n",
            "DOMAIN PROBE @ layer4.1\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.748 ± 0.007      | phot:0.55, art_:0.47, cart:0.78, sket:0.96\n",
            "minor      0.582 ± 0.009      | phot:0.14, art_:0.49, cart:0.43, sket:0.90\n",
            "random     0.664 ± 0.039      | phot:0.35, art_:0.50, cart:0.59, sket:0.92\n",
            "\n",
            "  Gap (minor - major): -0.166\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.797 ± 0.004      | phot:0.63, art_:0.61, cart:0.78, sket:0.97\n",
            "minor      0.634 ± 0.005      | phot:0.29, art_:0.49, cart:0.53, sket:0.92\n",
            "random     0.695 ± 0.021      | phot:0.40, art_:0.54, cart:0.66, sket:0.92\n",
            "\n",
            "  Gap (minor - major): -0.163\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.844 ± 0.005      | phot:0.74, art_:0.66, cart:0.84, sket:0.98\n",
            "minor      0.670 ± 0.007      | phot:0.41, art_:0.50, cart:0.57, sket:0.93\n",
            "random     0.822 ± 0.008      | phot:0.69, art_:0.65, cart:0.79, sket:0.99\n",
            "\n",
            "  Gap (minor - major): -0.174\n",
            "  → Major has MORE domain info (contradicts SoMA hypothesis)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Cell 7: Run Scenario 1 - Class Probe on PRETRAINED Model (All Conv Blocks)\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"SCENARIO 1: Class Probe on PRETRAINED Model - ALL CONV BLOCKS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "scenario1_class_results = {}\n",
        "\n",
        "for layer_name, conv in pretrained_conv_blocks.items():\n",
        "\n",
        "    results = run_full_probe_analysis(\n",
        "        model=pretrained_model,\n",
        "        layer_name=layer_name,\n",
        "        conv=conv,\n",
        "        domains=domains_all,\n",
        "        ranks=ranks,\n",
        "        seeds=seeds,\n",
        "        probe_type=\"class\",\n",
        "        exclude_photo=False\n",
        "    )\n",
        "\n",
        "    scenario1_class_results[layer_name] = results\n",
        "    print_probe_results(results, layer_name, \"class\", domains_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKdtMBQWdJNX",
        "outputId": "85cf62cf-e8d2-4733-9d05-f0b71b76a091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SCENARIO 1: Class Probe on PRETRAINED Model - ALL CONV BLOCKS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "CLASS PROBE @ layer1.0\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.245 ± 0.007      | phot:0.30, art_:0.29, cart:0.27, sket:0.19\n",
            "minor      0.266 ± 0.007      | phot:0.25, art_:0.28, cart:0.28, sket:0.26\n",
            "random     0.256 ± 0.017      | phot:0.29, art_:0.27, cart:0.29, sket:0.22\n",
            "\n",
            "  Gap (minor - major): +0.021\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.294 ± 0.013      | phot:0.34, art_:0.31, cart:0.31, sket:0.26\n",
            "minor      0.299 ± 0.011      | phot:0.29, art_:0.29, cart:0.31, sket:0.30\n",
            "random     0.319 ± 0.021      | phot:0.36, art_:0.30, cart:0.37, sket:0.29\n",
            "\n",
            "  Gap (minor - major): +0.006\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.359 ± 0.009      | phot:0.44, art_:0.35, cart:0.44, sket:0.28\n",
            "minor      0.361 ± 0.009      | phot:0.34, art_:0.32, cart:0.41, sket:0.37\n",
            "random     0.368 ± 0.011      | phot:0.40, art_:0.33, cart:0.42, sket:0.34\n",
            "\n",
            "  Gap (minor - major): +0.002\n",
            "\n",
            "======================================================================\n",
            "CLASS PROBE @ layer1.1\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.223 ± 0.005      | phot:0.26, art_:0.25, cart:0.20, sket:0.21\n",
            "minor      0.250 ± 0.005      | phot:0.27, art_:0.26, cart:0.30, sket:0.21\n",
            "random     0.268 ± 0.016      | phot:0.32, art_:0.25, cart:0.25, sket:0.27\n",
            "\n",
            "  Gap (minor - major): +0.028\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.300 ± 0.010      | phot:0.35, art_:0.26, cart:0.38, sket:0.25\n",
            "minor      0.287 ± 0.007      | phot:0.30, art_:0.29, cart:0.32, sket:0.26\n",
            "random     0.321 ± 0.010      | phot:0.33, art_:0.30, cart:0.34, sket:0.31\n",
            "\n",
            "  Gap (minor - major): -0.013\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.372 ± 0.008      | phot:0.40, art_:0.31, cart:0.42, sket:0.36\n",
            "minor      0.356 ± 0.006      | phot:0.37, art_:0.31, cart:0.39, sket:0.36\n",
            "random     0.378 ± 0.014      | phot:0.40, art_:0.33, cart:0.40, sket:0.38\n",
            "\n",
            "  Gap (minor - major): -0.016\n",
            "\n",
            "======================================================================\n",
            "CLASS PROBE @ layer2.0\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.268 ± 0.007      | phot:0.19, art_:0.20, cart:0.29, sket:0.32\n",
            "minor      0.288 ± 0.006      | phot:0.30, art_:0.23, cart:0.29, sket:0.31\n",
            "random     0.331 ± 0.012      | phot:0.35, art_:0.28, cart:0.33, sket:0.35\n",
            "\n",
            "  Gap (minor - major): +0.020\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.357 ± 0.004      | phot:0.43, art_:0.31, cart:0.35, sket:0.35\n",
            "minor      0.329 ± 0.004      | phot:0.33, art_:0.27, cart:0.40, sket:0.31\n",
            "random     0.377 ± 0.004      | phot:0.46, art_:0.31, cart:0.36, sket:0.39\n",
            "\n",
            "  Gap (minor - major): -0.028\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.408 ± 0.007      | phot:0.46, art_:0.35, cart:0.44, sket:0.40\n",
            "minor      0.405 ± 0.008      | phot:0.42, art_:0.32, cart:0.47, sket:0.41\n",
            "random     0.408 ± 0.009      | phot:0.47, art_:0.33, cart:0.45, sket:0.40\n",
            "\n",
            "  Gap (minor - major): -0.003\n",
            "\n",
            "======================================================================\n",
            "CLASS PROBE @ layer2.1\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.285 ± 0.002      | phot:0.36, art_:0.25, cart:0.23, sket:0.30\n",
            "minor      0.288 ± 0.008      | phot:0.30, art_:0.23, cart:0.26, sket:0.33\n",
            "random     0.300 ± 0.028      | phot:0.35, art_:0.26, cart:0.26, sket:0.32\n",
            "\n",
            "  Gap (minor - major): +0.003\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.365 ± 0.005      | phot:0.44, art_:0.31, cart:0.34, sket:0.37\n",
            "minor      0.354 ± 0.003      | phot:0.34, art_:0.27, cart:0.34, sket:0.41\n",
            "random     0.379 ± 0.012      | phot:0.41, art_:0.30, cart:0.39, sket:0.40\n",
            "\n",
            "  Gap (minor - major): -0.011\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.442 ± 0.007      | phot:0.49, art_:0.34, cart:0.43, sket:0.48\n",
            "minor      0.417 ± 0.001      | phot:0.47, art_:0.32, cart:0.48, sket:0.41\n",
            "random     0.429 ± 0.005      | phot:0.51, art_:0.33, cart:0.44, sket:0.45\n",
            "\n",
            "  Gap (minor - major): -0.025\n",
            "\n",
            "======================================================================\n",
            "CLASS PROBE @ layer3.0\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.277 ± 0.004      | phot:0.38, art_:0.24, cart:0.28, sket:0.25\n",
            "minor      0.244 ± 0.007      | phot:0.32, art_:0.22, cart:0.27, sket:0.21\n",
            "random     0.286 ± 0.018      | phot:0.34, art_:0.27, cart:0.27, sket:0.28\n",
            "\n",
            "  Gap (minor - major): -0.033\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.389 ± 0.006      | phot:0.55, art_:0.33, cart:0.39, sket:0.35\n",
            "minor      0.353 ± 0.007      | phot:0.36, art_:0.25, cart:0.40, sket:0.38\n",
            "random     0.369 ± 0.027      | phot:0.45, art_:0.30, cart:0.38, sket:0.37\n",
            "\n",
            "  Gap (minor - major): -0.035\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.502 ± 0.004      | phot:0.61, art_:0.40, cart:0.59, sket:0.46\n",
            "minor      0.419 ± 0.012      | phot:0.44, art_:0.29, cart:0.41, sket:0.48\n",
            "random     0.459 ± 0.028      | phot:0.55, art_:0.35, cart:0.46, sket:0.48\n",
            "\n",
            "  Gap (minor - major): -0.083\n",
            "\n",
            "======================================================================\n",
            "CLASS PROBE @ layer3.1\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.303 ± 0.006      | phot:0.46, art_:0.32, cart:0.25, sket:0.26\n",
            "minor      0.245 ± 0.013      | phot:0.23, art_:0.22, cart:0.28, sket:0.25\n",
            "random     0.274 ± 0.038      | phot:0.39, art_:0.25, cart:0.26, sket:0.25\n",
            "\n",
            "  Gap (minor - major): -0.058\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.363 ± 0.004      | phot:0.51, art_:0.39, cart:0.37, sket:0.28\n",
            "minor      0.319 ± 0.011      | phot:0.47, art_:0.25, cart:0.30, sket:0.30\n",
            "random     0.361 ± 0.032      | phot:0.43, art_:0.29, cart:0.37, sket:0.37\n",
            "\n",
            "  Gap (minor - major): -0.044\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.489 ± 0.004      | phot:0.62, art_:0.45, cart:0.48, sket:0.46\n",
            "minor      0.427 ± 0.017      | phot:0.56, art_:0.35, cart:0.42, sket:0.42\n",
            "random     0.456 ± 0.010      | phot:0.56, art_:0.36, cart:0.44, sket:0.47\n",
            "\n",
            "  Gap (minor - major): -0.062\n",
            "\n",
            "======================================================================\n",
            "CLASS PROBE @ layer4.0\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.333 ± 0.006      | phot:0.39, art_:0.34, cart:0.32, sket:0.31\n",
            "minor      0.291 ± 0.006      | phot:0.33, art_:0.23, cart:0.29, sket:0.30\n",
            "random     0.279 ± 0.019      | phot:0.34, art_:0.25, cart:0.28, sket:0.26\n",
            "\n",
            "  Gap (minor - major): -0.042\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.438 ± 0.004      | phot:0.59, art_:0.42, cart:0.46, sket:0.37\n",
            "minor      0.345 ± 0.008      | phot:0.46, art_:0.24, cart:0.33, sket:0.36\n",
            "random     0.409 ± 0.009      | phot:0.53, art_:0.30, cart:0.39, sket:0.43\n",
            "\n",
            "  Gap (minor - major): -0.094\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.561 ± 0.002      | phot:0.71, art_:0.52, cart:0.59, sket:0.50\n",
            "minor      0.447 ± 0.012      | phot:0.53, art_:0.27, cart:0.43, sket:0.51\n",
            "random     0.499 ± 0.027      | phot:0.67, art_:0.41, cart:0.45, sket:0.50\n",
            "\n",
            "  Gap (minor - major): -0.115\n",
            "\n",
            "======================================================================\n",
            "CLASS PROBE @ layer4.1\n",
            "======================================================================\n",
            "\n",
            "--- Rank 4 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.331 ± 0.001      | phot:0.43, art_:0.40, cart:0.27, sket:0.29\n",
            "minor      0.240 ± 0.005      | phot:0.32, art_:0.22, cart:0.21, sket:0.23\n",
            "random     0.276 ± 0.005      | phot:0.38, art_:0.27, cart:0.27, sket:0.25\n",
            "\n",
            "  Gap (minor - major): -0.091\n",
            "\n",
            "--- Rank 8 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.479 ± 0.007      | phot:0.70, art_:0.51, cart:0.43, sket:0.40\n",
            "minor      0.299 ± 0.003      | phot:0.37, art_:0.28, cart:0.28, sket:0.29\n",
            "random     0.402 ± 0.015      | phot:0.51, art_:0.30, cart:0.43, sket:0.40\n",
            "\n",
            "  Gap (minor - major): -0.179\n",
            "\n",
            "--- Rank 16 ---\n",
            "Subspace   Overall            | Per-Domain Accuracy\n",
            "----------------------------------------------------------------------\n",
            "major      0.592 ± 0.010      | phot:0.86, art_:0.61, cart:0.54, sket:0.50\n",
            "minor      0.376 ± 0.006      | phot:0.52, art_:0.32, cart:0.29, sket:0.40\n",
            "random     0.502 ± 0.031      | phot:0.73, art_:0.44, cart:0.44, sket:0.48\n",
            "\n",
            "  Gap (minor - major): -0.216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-2: ΔW-Based Domain-Sensitive Subspace Discovery\n",
        "Working with pretrained base, and just finetuning that in one direction only"
      ],
      "metadata": {
        "id": "Ywa9lmNS0G0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# =============================================================================\n",
        "# Load PRETRAINED model (ImageNet only, never seen PACS)\n",
        "# =============================================================================\n",
        "\n",
        "def load_pretrained_model():\n",
        "    \"\"\"Load fresh ImageNet-pretrained ResNet-18 (NOT finetuned on PACS)\"\"\"\n",
        "    model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "    # The ResNet18_FeatureHook already loads ImageNet weights in __init__\n",
        "    # We just need to ensure fc is properly initialized (it doesn't matter for ΔW)\n",
        "    nn.init.xavier_uniform_(model.backbone.fc.weight)\n",
        "    nn.init.zeros_(model.backbone.fc.bias)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_finetuned_model():\n",
        "    \"\"\"Load the model finetuned on 3 source domains\"\"\"\n",
        "    model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "    state = torch.load(BACKBONE_PATH, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "8U2DMlgYai0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Train single domain starting from PRETRAINED (not finetuned)\n",
        "# =============================================================================\n",
        "\n",
        "def freeze_bn_stats(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            m.eval()                  # freeze running mean/var\n",
        "            m.weight.requires_grad = True\n",
        "            m.bias.requires_grad = True\n",
        "\n",
        "from collections import defaultdict\n",
        "def make_balanced_loader(domain, tf, batch_size):\n",
        "    ds = datasets.ImageFolder(\n",
        "        root=os.path.join(PACS_ROOT, domain),\n",
        "        transform=tf\n",
        "    )\n",
        "\n",
        "    # group indices by class\n",
        "    class_to_indices = defaultdict(list)\n",
        "    for idx, (_, y) in enumerate(ds.samples):\n",
        "        class_to_indices[y].append(idx)\n",
        "\n",
        "    # sample equal counts per class\n",
        "    min_count = min(len(v) for v in class_to_indices.values())\n",
        "    balanced_indices = []\n",
        "    for v in class_to_indices.values():\n",
        "        balanced_indices.extend(v[:min_count])\n",
        "\n",
        "    sampler = torch.utils.data.SubsetRandomSampler(balanced_indices)\n",
        "\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        sampler=sampler,\n",
        "        num_workers=NUM_WORKERS\n",
        "    )\n",
        "\n",
        "def train_single_domain_from_pretrained(domain, epochs=3, lr=1e-4):\n",
        "    \"\"\"\n",
        "    Start from pretrained ImageNet model and train on single domain.\n",
        "    This captures: \"How does pretrained → domain d adaptation occur?\"\n",
        "    \"\"\"\n",
        "    model = load_pretrained_model()  # PRETRAINED, not finetuned!\n",
        "    freeze_bn_stats(model)\n",
        "\n",
        "    loader = make_balanced_loader(domain, train_tf, BATCH_SIZE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "lykJHAkKau6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_deltaW_channel_subspace(dW_list):\n",
        "    \"\"\"\n",
        "    dW_list: list of ΔW matrices for one layer\n",
        "             each ΔW has shape [C_out, D]\n",
        "\n",
        "    Returns:\n",
        "        U_domain: [C_out, C_out] eigenvectors (descending order)\n",
        "        S_domain: eigenvalues\n",
        "    \"\"\"\n",
        "    C_out = dW_list[0].shape[0]\n",
        "    C = np.zeros((C_out, C_out))\n",
        "\n",
        "    for dW in dW_list:\n",
        "        C += dW @ dW.T   # channel-channel covariance\n",
        "\n",
        "    # Eigen-decomposition (symmetric PSD matrix)\n",
        "    eigvals, eigvecs = np.linalg.eigh(C)\n",
        "\n",
        "    # Sort descending\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "    eigvals = eigvals[idx]\n",
        "    eigvecs = eigvecs[:, idx]\n",
        "\n",
        "    return eigvecs, eigvals\n",
        "\n",
        "\n",
        "def compute_alignment_metrics(U, V):\n",
        "    \"\"\"\n",
        "    U, V: [C_out, r] orthonormal basis matrices\n",
        "\n",
        "    Returns:\n",
        "        mean_angle_deg\n",
        "        overlap (mean cos^2)\n",
        "        projection_energy\n",
        "    \"\"\"\n",
        "    # Cross-subspace matrix\n",
        "    M = U.T @ V   # [r, r]\n",
        "\n",
        "    # Singular values = cos(theta_i)\n",
        "    sv = np.linalg.svd(M, compute_uv=False)\n",
        "    sv = np.clip(sv, -1.0, 1.0)\n",
        "\n",
        "    # Principal angles (degrees)\n",
        "    angles = np.degrees(np.arccos(sv))\n",
        "    mean_angle = angles.mean()\n",
        "\n",
        "    # Overlap (mean squared cosine)\n",
        "    overlap = np.mean(sv ** 2)\n",
        "\n",
        "    # Projection energy (equivalent to overlap)\n",
        "    proj_energy = np.linalg.norm(M, ord=\"fro\") ** 2 / V.shape[1]\n",
        "\n",
        "    return mean_angle, overlap, proj_energy\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Compute ΔW from pretrained model\n",
        "# =============================================================================\n",
        "\n",
        "def extract_delta_W_from_pretrained(pretrained_model, adapted_model, conv_path):\n",
        "    \"\"\"\n",
        "    Compute ΔW = W_adapted - W_pretrained\n",
        "    \"\"\"\n",
        "    base_conv = getattr(\n",
        "        getattr(pretrained_model.backbone, conv_path[0])[conv_path[1]],\n",
        "        conv_path[2]\n",
        "    )\n",
        "\n",
        "    adapt_conv = getattr(\n",
        "        getattr(adapted_model.backbone, conv_path[0])[conv_path[1]],\n",
        "        conv_path[2]\n",
        "    )\n",
        "\n",
        "    W0 = base_conv.weight.detach().cpu().numpy()\n",
        "    W1 = adapt_conv.weight.detach().cpu().numpy()\n",
        "\n",
        "    dW = W1 - W0\n",
        "    C_out = dW.shape[0]\n",
        "    return dW.reshape(C_out, -1)\n",
        "\n"
      ],
      "metadata": {
        "id": "t_PiTjBWazn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# =============================================================================\n",
        "# Run the corrected Tier 2 analysis\n",
        "# =============================================================================\n",
        "\n",
        "conv_layers = {\n",
        "    \"layer2.1\": (\"layer2\", 1, \"conv2\"),\n",
        "    \"layer3.1\": (\"layer3\", 1, \"conv2\"),\n",
        "    \"layer4.1\": (\"layer4\", 1, \"conv2\"),\n",
        "}\n",
        "\n",
        "# Load pretrained model as the BASE for ΔW computation\n",
        "pretrained_model = load_pretrained_model()\n",
        "\n",
        "# Store ΔW for each domain\n",
        "deltaWs_from_pretrained = {k: [] for k in conv_layers}\n",
        "\n",
        "print(\"Computing ΔW from PRETRAINED model to each domain...\")\n",
        "for domain in SOURCE_DOMAINS:\n",
        "    print(f\"  Training on domain: {domain}\")\n",
        "    adapted = train_single_domain_from_pretrained(domain, epochs=3)\n",
        "\n",
        "    for lname, path in conv_layers.items():\n",
        "        dW = extract_delta_W_from_pretrained(pretrained_model, adapted, path)\n",
        "        deltaWs_from_pretrained[lname].append(dW)\n",
        "\n",
        "# Build domain-sensitive subspace from these ΔWs\n",
        "delta_subspaces_pretrained = {}\n",
        "for lname, dW_list in deltaWs_from_pretrained.items():\n",
        "    U_domain, S_domain = build_deltaW_channel_subspace(dW_list)\n",
        "    delta_subspaces_pretrained[lname] = (U_domain, S_domain)\n",
        "\n",
        "print(\"Constructed ΔW subspaces from pretrained base.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKowiCUla-wm",
        "outputId": "3203c350-b71f-4e39-a993-3e664fdb2969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing ΔW from PRETRAINED model to each domain...\n",
            "  Training on domain: photo\n",
            "  Training on domain: art_painting\n",
            "  Training on domain: cartoon\n",
            "Constructed ΔW subspaces from pretrained base.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Get SVD subspaces from PRETRAINED model (what SoMA would actually use)\n",
        "# =============================================================================\n",
        "\n",
        "def get_soma_subspace_from_model(model, layer_path, kind, r):\n",
        "    \"\"\"\n",
        "    Get major/minor/random subspace from a specific model's weights.\n",
        "    \"\"\"\n",
        "    conv = getattr(\n",
        "        getattr(model.backbone, layer_path[0])[layer_path[1]],\n",
        "        layer_path[2]\n",
        "    )\n",
        "\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    C_out = W.shape[0]\n",
        "    Wmat = W.reshape(C_out, -1)\n",
        "\n",
        "    U, S, _ = np.linalg.svd(Wmat, full_matrices=False)\n",
        "\n",
        "    if kind == \"minor\":\n",
        "        return U[:, -r:]\n",
        "    if kind == \"major\":\n",
        "        return U[:, :r]\n",
        "    if kind == \"random\":\n",
        "        Q, _ = np.linalg.qr(np.random.randn(C_out, r))\n",
        "        return Q\n",
        "\n",
        "    raise ValueError(f\"Unknown kind: {kind}\")"
      ],
      "metadata": {
        "id": "9XaqMIkjbKZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Compute alignment between ΔW subspace and SVD subspaces of PRETRAINED model\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"APPROACH A: ΔW from Pretrained, SVD from Pretrained\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "ranks = [4, 8, 16]\n",
        "n_random = 10\n",
        "\n",
        "alignment_results_pretrained = {}\n",
        "\n",
        "for lname, (U_domain, S_domain) in delta_subspaces_pretrained.items():\n",
        "    print(f\"\\n=== Alignment @ {lname} ===\")\n",
        "    alignment_results_pretrained[lname] = {}\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"\\nRank {r}\")\n",
        "        V = U_domain[:, :r]  # Top-r ΔW directions\n",
        "\n",
        "        alignment_results_pretrained[lname][r] = {}\n",
        "\n",
        "        for kind in [\"minor\", \"major\", \"random\"]:\n",
        "            angles, overlaps = [], []\n",
        "\n",
        "            for seed in range(n_random):\n",
        "                np.random.seed(seed)\n",
        "                # SVD from PRETRAINED model (what SoMA actually uses)\n",
        "                U = get_soma_subspace_from_model(pretrained_model, conv_layers[lname], kind, r)\n",
        "\n",
        "                mean_angle, overlap, _ = compute_alignment_metrics(U, V)\n",
        "                angles.append(mean_angle)\n",
        "                overlaps.append(overlap)\n",
        "\n",
        "            alignment_results_pretrained[lname][r][kind] = {\n",
        "                \"angle\": (np.mean(angles), np.std(angles)),\n",
        "                \"overlap\": (np.mean(overlaps), np.std(overlaps)),\n",
        "            }\n",
        "\n",
        "            print(f\"  {kind:>6} | angle={np.mean(angles):.1f}° | overlap={np.mean(overlaps):.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwxkMKa4YwIs",
        "outputId": "87fc567a-b600-4957-ad68-37029a423570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "APPROACH A: ΔW from Pretrained, SVD from Pretrained\n",
            "======================================================================\n",
            "\n",
            "=== Alignment @ layer2.1 ===\n",
            "\n",
            "Rank 4\n",
            "   minor | angle=83.4° | overlap=0.018\n",
            "   major | angle=81.7° | overlap=0.036\n",
            "  random | angle=81.8° | overlap=0.030\n",
            "\n",
            "Rank 8\n",
            "   minor | angle=81.0° | overlap=0.032\n",
            "   major | angle=78.3° | overlap=0.062\n",
            "  random | angle=77.4° | overlap=0.066\n",
            "\n",
            "Rank 16\n",
            "   minor | angle=76.9° | overlap=0.070\n",
            "   major | angle=69.4° | overlap=0.157\n",
            "  random | angle=71.9° | overlap=0.128\n",
            "\n",
            "=== Alignment @ layer3.1 ===\n",
            "\n",
            "Rank 4\n",
            "   minor | angle=85.8° | overlap=0.007\n",
            "   major | angle=81.0° | overlap=0.037\n",
            "  random | angle=84.1° | overlap=0.016\n",
            "\n",
            "Rank 8\n",
            "   minor | angle=83.9° | overlap=0.016\n",
            "   major | angle=76.0° | overlap=0.086\n",
            "  random | angle=81.1° | overlap=0.033\n",
            "\n",
            "Rank 16\n",
            "   minor | angle=80.8° | overlap=0.037\n",
            "   major | angle=72.3° | overlap=0.125\n",
            "  random | angle=77.6° | overlap=0.062\n",
            "\n",
            "=== Alignment @ layer4.1 ===\n",
            "\n",
            "Rank 4\n",
            "   minor | angle=85.8° | overlap=0.008\n",
            "   major | angle=86.5° | overlap=0.005\n",
            "  random | angle=85.7° | overlap=0.008\n",
            "\n",
            "Rank 8\n",
            "   minor | angle=84.5° | overlap=0.013\n",
            "   major | angle=85.0° | overlap=0.011\n",
            "  random | angle=84.0° | overlap=0.015\n",
            "\n",
            "Rank 16\n",
            "   minor | angle=81.6° | overlap=0.029\n",
            "   major | angle=81.9° | overlap=0.026\n",
            "  random | angle=81.3° | overlap=0.031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# VALIDATION: Does held-out domain (Sketch) align with ΔW subspace from 3 sources?\n",
        "# =============================================================================\n",
        "\n",
        "HELD_OUT_DOMAIN = \"sketch\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VALIDATION: Does Sketch's ΔW align with subspace from Photo/Art/Cartoon?\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Train on Sketch starting from pretrained\n",
        "print(f\"\\nTraining on held-out domain: {HELD_OUT_DOMAIN}\")\n",
        "adapted_sketch = train_single_domain_from_pretrained(HELD_OUT_DOMAIN, epochs=3)\n",
        "\n",
        "# Compute ΔW for Sketch\n",
        "deltaW_sketch = {}\n",
        "for lname, path in conv_layers.items():\n",
        "    dW = extract_delta_W_from_pretrained(pretrained_model, adapted_sketch, path)\n",
        "    deltaW_sketch[lname] = dW\n",
        "\n",
        "# For each layer, check if Sketch's ΔW aligns with the subspace derived from 3 domains\n",
        "print(\"\\nAlignment of Sketch's ΔW with 3-domain derived subspace:\")\n",
        "\n",
        "for lname in conv_layers.keys():\n",
        "    print(f\"\\n=== {lname} ===\")\n",
        "\n",
        "    # Get the ΔW subspace from 3 source domains\n",
        "    U_3domain, S_3domain = delta_subspaces_pretrained[lname]\n",
        "\n",
        "    # Get Sketch's ΔW\n",
        "    dW_sketch = deltaW_sketch[lname]\n",
        "\n",
        "    # Compute how much of Sketch's ΔW variance is captured by 3-domain subspace\n",
        "    for r in [4, 8, 16]:\n",
        "        U_sub = U_3domain[:, :r]  # Top-r directions from 3 domains\n",
        "\n",
        "        # Project Sketch's ΔW onto this subspace\n",
        "        dW_projected = U_sub @ (U_sub.T @ dW_sketch)\n",
        "\n",
        "        # Compute fraction of variance captured\n",
        "        total_variance = np.linalg.norm(dW_sketch, 'fro')**2\n",
        "        projected_variance = np.linalg.norm(dW_projected, 'fro')**2\n",
        "        fraction_captured = projected_variance / total_variance\n",
        "\n",
        "        print(f\"  Rank {r}: {fraction_captured:.1%} of Sketch's ΔW variance captured\")\n",
        "\n",
        "# Also compute principal angles between Sketch's ΔW and 3-domain subspace\n",
        "print(\"\\nPrincipal angles between Sketch's ΔW direction and 3-domain subspace:\")\n",
        "\n",
        "for lname in conv_layers.keys():\n",
        "    print(f\"\\n=== {lname} ===\")\n",
        "\n",
        "    U_3domain, _ = delta_subspaces_pretrained[lname]\n",
        "    dW_sketch = deltaW_sketch[lname]\n",
        "\n",
        "    # Get top direction of Sketch's ΔW\n",
        "    U_sketch, S_sketch, _ = np.linalg.svd(dW_sketch, full_matrices=False)\n",
        "\n",
        "    for r in [4, 8, 16]:\n",
        "        V_3domain = U_3domain[:, :r]\n",
        "        V_sketch = U_sketch[:, :r]\n",
        "\n",
        "        mean_angle, overlap, _ = compute_alignment_metrics(V_sketch, V_3domain)\n",
        "        print(f\"  Rank {r}: angle={mean_angle:.1f}°, overlap={overlap:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWDm5GeVfzJI",
        "outputId": "fc1d6dc8-9cd5-4fec-f831-2bcb7dcaeca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "VALIDATION: Does Sketch's ΔW align with subspace from Photo/Art/Cartoon?\n",
            "======================================================================\n",
            "\n",
            "Training on held-out domain: sketch\n",
            "\n",
            "Alignment of Sketch's ΔW with 3-domain derived subspace:\n",
            "\n",
            "=== layer2.1 ===\n",
            "  Rank 4: 7.2% of Sketch's ΔW variance captured\n",
            "  Rank 8: 12.7% of Sketch's ΔW variance captured\n",
            "  Rank 16: 23.3% of Sketch's ΔW variance captured\n",
            "\n",
            "=== layer3.1 ===\n",
            "  Rank 4: 2.9% of Sketch's ΔW variance captured\n",
            "  Rank 8: 6.3% of Sketch's ΔW variance captured\n",
            "  Rank 16: 11.7% of Sketch's ΔW variance captured\n",
            "\n",
            "=== layer4.1 ===\n",
            "  Rank 4: 0.5% of Sketch's ΔW variance captured\n",
            "  Rank 8: 1.2% of Sketch's ΔW variance captured\n",
            "  Rank 16: 2.3% of Sketch's ΔW variance captured\n",
            "\n",
            "Principal angles between Sketch's ΔW direction and 3-domain subspace:\n",
            "\n",
            "=== layer2.1 ===\n",
            "  Rank 4: angle=68.4°, overlap=0.158\n",
            "  Rank 8: angle=67.6°, overlap=0.183\n",
            "  Rank 16: angle=60.2°, overlap=0.295\n",
            "\n",
            "=== layer3.1 ===\n",
            "  Rank 4: angle=80.8°, overlap=0.034\n",
            "  Rank 8: angle=75.1°, overlap=0.089\n",
            "  Rank 16: angle=69.0°, overlap=0.167\n",
            "\n",
            "=== layer4.1 ===\n",
            "  Rank 4: angle=87.0°, overlap=0.004\n",
            "  Rank 8: angle=84.6°, overlap=0.012\n",
            "  Rank 16: angle=81.9°, overlap=0.028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Get Major/Minor subspaces from pretrained model\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def get_svd_subspaces(model, conv_path):\n",
        "    \"\"\"Get SVD of pretrained weights\"\"\"\n",
        "    conv = getattr(\n",
        "        getattr(model.backbone, conv_path[0])[conv_path[1]],\n",
        "        conv_path[2]\n",
        "    )\n",
        "\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    C_out = W.shape[0]\n",
        "    Wmat = W.reshape(C_out, -1)\n",
        "\n",
        "    U, S, Vh = np.linalg.svd(Wmat, full_matrices=False)\n",
        "    return U, S, Vh\n",
        "\n",
        "pretrained_svd = {}\n",
        "for lname, path in conv_layers.items():\n",
        "    U, S, Vh = get_svd_subspaces(pretrained_model, path)\n",
        "    pretrained_svd[lname] = {'U': U, 'S': S, 'Vh': Vh}\n",
        "    print(f\"  {lname}: U shape = {U.shape}, rank = {len(S)}\")\n",
        "\n",
        "\n",
        "def compute_alignment_metrics(U, V):\n",
        "    \"\"\"\n",
        "    Compute alignment between two subspaces.\n",
        "    U, V: [d, r] orthonormal bases\n",
        "    Returns: mean_angle (degrees), overlap (mean cos²θ)\n",
        "    \"\"\"\n",
        "    M = U.T @ V\n",
        "    sv = np.linalg.svd(M, compute_uv=False)\n",
        "    sv = np.clip(sv, -1.0, 1.0)\n",
        "\n",
        "    angles = np.degrees(np.arccos(sv))\n",
        "    mean_angle = angles.mean()\n",
        "    overlap = np.mean(sv ** 2)\n",
        "\n",
        "    return mean_angle, overlap\n",
        "\n",
        "def get_deltaW_principal_directions(dW, r):\n",
        "    \"\"\"Get top-r principal directions of ΔW\"\"\"\n",
        "    U_dw, S_dw, _ = np.linalg.svd(dW, full_matrices=False)\n",
        "    return U_dw[:, :r]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SANITY CHECK: Sketch's ΔW Alignment with Pretrained SVD Subspaces\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "ranks = [4, 8, 16]\n",
        "\n",
        "for lname in conv_layers.keys():\n",
        "    print(f\"\\n=== {lname} ===\")\n",
        "\n",
        "    U_pretrained = pretrained_svd[lname]['U']\n",
        "    dW_sketch = deltaW_sketch[lname]\n",
        "    d = U_pretrained.shape[0]  # Output dimension\n",
        "\n",
        "    for r in ranks:\n",
        "        # Get Sketch's ΔW principal directions\n",
        "        V_sketch = get_deltaW_principal_directions(dW_sketch, r)\n",
        "\n",
        "        # Major: top-r of pretrained\n",
        "        U_major = U_pretrained[:, :r]\n",
        "\n",
        "        # Minor: bottom-r of pretrained\n",
        "        U_minor = U_pretrained[:, -r:]\n",
        "\n",
        "        # Middle: middle-r of pretrained\n",
        "        mid_start = d // 2 - r // 2\n",
        "        U_middle = U_pretrained[:, mid_start:mid_start + r]\n",
        "\n",
        "        # Random\n",
        "        np.random.seed(42)\n",
        "        Q_random, _ = np.linalg.qr(np.random.randn(d, r))\n",
        "\n",
        "        # Compute alignments\n",
        "        angle_major, overlap_major = compute_alignment_metrics(U_major, V_sketch)\n",
        "        angle_minor, overlap_minor = compute_alignment_metrics(U_minor, V_sketch)\n",
        "        angle_middle, overlap_middle = compute_alignment_metrics(U_middle, V_sketch)\n",
        "        angle_random, overlap_random = compute_alignment_metrics(Q_random, V_sketch)\n",
        "\n",
        "        print(f\"\\n  Rank {r}:\")\n",
        "        print(f\"    Major:  angle={angle_major:.1f}°, overlap={overlap_major:.4f}\")\n",
        "        print(f\"    Minor:  angle={angle_minor:.1f}°, overlap={overlap_minor:.4f}\")\n",
        "        print(f\"    Middle: angle={angle_middle:.1f}°, overlap={overlap_middle:.4f}\")\n",
        "        print(f\"    Random: angle={angle_random:.1f}°, overlap={overlap_random:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On-f1Xfbupb4",
        "outputId": "05b7e4ff-1754-4d49-a7ad-aa1c743c5359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  layer2.1: U shape = (128, 128), rank = 128\n",
            "  layer3.1: U shape = (256, 256), rank = 256\n",
            "  layer4.1: U shape = (512, 512), rank = 512\n",
            "\n",
            "======================================================================\n",
            "SANITY CHECK: Sketch's ΔW Alignment with Pretrained SVD Subspaces\n",
            "======================================================================\n",
            "\n",
            "=== layer2.1 ===\n",
            "\n",
            "  Rank 4:\n",
            "    Major:  angle=78.6°, overlap=0.0509\n",
            "    Minor:  angle=83.2°, overlap=0.0190\n",
            "    Middle: angle=81.1°, overlap=0.0348\n",
            "    Random: angle=82.1°, overlap=0.0273\n",
            "\n",
            "  Rank 8:\n",
            "    Major:  angle=77.1°, overlap=0.0703\n",
            "    Minor:  angle=79.4°, overlap=0.0452\n",
            "    Middle: angle=78.3°, overlap=0.0546\n",
            "    Random: angle=78.1°, overlap=0.0647\n",
            "\n",
            "  Rank 16:\n",
            "    Major:  angle=70.0°, overlap=0.1474\n",
            "    Minor:  angle=75.4°, overlap=0.0879\n",
            "    Middle: angle=72.5°, overlap=0.1214\n",
            "    Random: angle=71.9°, overlap=0.1309\n",
            "\n",
            "=== layer3.1 ===\n",
            "\n",
            "  Rank 4:\n",
            "    Major:  angle=84.3°, overlap=0.0152\n",
            "    Minor:  angle=84.7°, overlap=0.0174\n",
            "    Middle: angle=85.3°, overlap=0.0102\n",
            "    Random: angle=83.5°, overlap=0.0157\n",
            "\n",
            "  Rank 8:\n",
            "    Major:  angle=79.1°, overlap=0.0494\n",
            "    Minor:  angle=82.0°, overlap=0.0267\n",
            "    Middle: angle=82.7°, overlap=0.0229\n",
            "    Random: angle=82.2°, overlap=0.0272\n",
            "\n",
            "  Rank 16:\n",
            "    Major:  angle=74.5°, overlap=0.0963\n",
            "    Minor:  angle=79.7°, overlap=0.0491\n",
            "    Middle: angle=78.0°, overlap=0.0578\n",
            "    Random: angle=77.2°, overlap=0.0672\n",
            "\n",
            "=== layer4.1 ===\n",
            "\n",
            "  Rank 4:\n",
            "    Major:  angle=86.8°, overlap=0.0039\n",
            "    Minor:  angle=85.8°, overlap=0.0075\n",
            "    Middle: angle=85.9°, overlap=0.0073\n",
            "    Random: angle=86.5°, overlap=0.0048\n",
            "\n",
            "  Rank 8:\n",
            "    Major:  angle=84.7°, overlap=0.0122\n",
            "    Minor:  angle=83.9°, overlap=0.0161\n",
            "    Middle: angle=83.9°, overlap=0.0162\n",
            "    Random: angle=85.0°, overlap=0.0122\n",
            "\n",
            "  Rank 16:\n",
            "    Major:  angle=81.1°, overlap=0.0332\n",
            "    Minor:  angle=80.4°, overlap=0.0359\n",
            "    Middle: angle=81.0°, overlap=0.0337\n",
            "    Random: angle=82.0°, overlap=0.0280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXPERIMENT 3: Subspace Comparison for Domain Generalization\n"
      ],
      "metadata": {
        "id": "OmCkxjdrvFMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EXPERIMENT 3: Subspace Comparison for Domain Generalization\n",
        "# =============================================================================\n",
        "#\n",
        "# This experiment definitively tests whether the MINOR subspace is special,\n",
        "# or whether ANY low-rank constraint provides similar benefits.\n",
        "#\n",
        "# Variants:\n",
        "#   - SoMA-Minor:  Constrain updates to bottom-r singular vectors\n",
        "#   - SoMA-Major:  Constrain updates to top-r singular vectors\n",
        "#   - SoMA-Middle: Constrain updates to middle-r singular vectors\n",
        "#   - SoMA-Random: Constrain updates to random orthonormal basis\n",
        "#   - Full-FT:     No constraint (baseline)\n",
        "#\n",
        "# Protocol:\n",
        "#   - Train on 3 source domains (Photo, Art, Cartoon)\n",
        "#   - Evaluate on held-out target domain (Sketch)\n",
        "#   - Use rank=8 for all constrained variants\n",
        "#\n",
        "# =============================================================================\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Configuration\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "RANK = 8  # Adapter rank for all constrained variants\n",
        "EPOCHS = 10\n",
        "LR = 1e-4\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "SOURCE_DOMAINS = [\"photo\", \"art_painting\", \"cartoon\"]\n",
        "TARGET_DOMAIN = \"sketch\"\n",
        "\n",
        "# Layers to apply adapters (following SoMA paper - typically mid-to-late layers)\n",
        "ADAPTER_LAYERS = [\n",
        "    (\"layer2\", 0, \"conv2\"),\n",
        "    (\"layer2\", 1, \"conv2\"),\n",
        "    (\"layer3\", 0, \"conv2\"),\n",
        "    (\"layer3\", 1, \"conv2\"),\n",
        "    (\"layer4\", 0, \"conv2\"),\n",
        "    (\"layer4\", 1, \"conv2\"),\n",
        "]\n",
        "\n",
        "# Random seeds for reproducibility\n",
        "SEEDS = [42, 123, 456]\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Data Loading\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "IMG_SIZE = 224\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "def get_domain_dataset(domain, transform):\n",
        "    return datasets.ImageFolder(\n",
        "        root=os.path.join(PACS_ROOT, domain),\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "\n",
        "def get_source_loader(batch_size=BATCH_SIZE):\n",
        "    \"\"\"Combined loader for all source domains\"\"\"\n",
        "    source_datasets = [get_domain_dataset(d, train_tf) for d in SOURCE_DOMAINS]\n",
        "    combined = ConcatDataset(source_datasets)\n",
        "    return DataLoader(combined, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS)\n",
        "\n",
        "\n",
        "def get_target_loader(batch_size=BATCH_SIZE):\n",
        "    \"\"\"Loader for target domain (evaluation only)\"\"\"\n",
        "    target_dataset = get_domain_dataset(TARGET_DOMAIN, test_tf)\n",
        "    return DataLoader(target_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Subspace-Constrained Adapter (LoRA-style)\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class SubspaceAdapter(nn.Module):\n",
        "    def __init__(self, conv_layer, subspace_basis, scale=1.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = conv_layer\n",
        "        self.scale = scale\n",
        "\n",
        "        C_out, C_in, k1, k2 = conv_layer.weight.shape\n",
        "        r = subspace_basis.shape[1]\n",
        "\n",
        "        self.C_out = C_out\n",
        "        self.C_in = C_in\n",
        "        self.k = k1\n",
        "        self.r = r\n",
        "        self.stride = conv_layer.stride\n",
        "        self.padding = conv_layer.padding\n",
        "\n",
        "        # A is trainable (down-projection)\n",
        "        self.A = nn.Parameter(torch.randn(r, C_in * k1 * k2) * 0.01)\n",
        "\n",
        "        # B is FROZEN (enforces subspace constraint)\n",
        "        self.register_buffer('B', torch.from_numpy(subspace_basis.astype(np.float32)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Original convolution output\n",
        "        out = self.conv(x)\n",
        "\n",
        "        # Adapter path: unfold input, apply low-rank transform\n",
        "        # This is equivalent to a rank-r convolution\n",
        "\n",
        "        # Unfold input to patches: (N, C_in*k*k, H_out*W_out)\n",
        "        x_unf = F.unfold(x, kernel_size=self.k, stride=self.stride, padding=self.padding)\n",
        "\n",
        "        # Apply A: (N, r, H_out*W_out)\n",
        "        adapter_out = self.A @ x_unf\n",
        "\n",
        "        # Apply B: (N, C_out, H_out*W_out)\n",
        "        adapter_out = self.B @ adapter_out\n",
        "\n",
        "        # Reshape to match conv output: (N, C_out, H_out, W_out)\n",
        "        adapter_out = adapter_out.view(out.shape)\n",
        "\n",
        "        return out + self.scale * adapter_out\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Model with Subspace Adapters\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class ResNet18WithAdapters(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet-18 with subspace-constrained adapters on specified layers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_classes, adapter_layers, subspace_type, rank, random_seed=42):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_classes: Number of output classes\n",
        "            adapter_layers: List of (layer_name, block_idx, conv_name) tuples\n",
        "            subspace_type: 'minor', 'major', 'middle', 'random', or 'none'\n",
        "            rank: Rank of adapters\n",
        "            random_seed: Seed for random subspace generation\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        from torchvision import models\n",
        "\n",
        "        # Load pretrained backbone\n",
        "        self.backbone = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "        self.backbone.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "        self.subspace_type = subspace_type\n",
        "        self.rank = rank\n",
        "        self.random_seed = random_seed\n",
        "        self.adapter_layers = adapter_layers\n",
        "        self.adapters = nn.ModuleDict()\n",
        "\n",
        "        # Store the random bases used (for reporting)\n",
        "        self.random_bases = {}\n",
        "\n",
        "        if subspace_type != 'none':\n",
        "            self._add_adapters()\n",
        "\n",
        "    def _get_conv_layer(self, layer_name, block_idx, conv_name):\n",
        "        \"\"\"Get reference to a specific conv layer\"\"\"\n",
        "        layer = getattr(self.backbone, layer_name)\n",
        "        block = layer[block_idx]\n",
        "        return getattr(block, conv_name)\n",
        "\n",
        "    def _set_conv_layer(self, layer_name, block_idx, conv_name, new_module):\n",
        "        \"\"\"Replace a specific conv layer with adapter\"\"\"\n",
        "        layer = getattr(self.backbone, layer_name)\n",
        "        block = layer[block_idx]\n",
        "        setattr(block, conv_name, new_module)\n",
        "\n",
        "    def _compute_subspace_basis(self, conv_layer, layer_key):\n",
        "        \"\"\"Compute the subspace basis for a given conv layer\"\"\"\n",
        "        W = conv_layer.weight.detach().cpu().numpy()\n",
        "        C_out = W.shape[0]\n",
        "        W_mat = W.reshape(C_out, -1)\n",
        "\n",
        "        # Compute SVD\n",
        "        U, S, Vh = np.linalg.svd(W_mat, full_matrices=False)\n",
        "\n",
        "        r = self.rank\n",
        "        d = C_out\n",
        "\n",
        "        if self.subspace_type == 'minor':\n",
        "            # Bottom-r singular vectors\n",
        "            basis = U[:, -r:]\n",
        "        elif self.subspace_type == 'major':\n",
        "            # Top-r singular vectors\n",
        "            basis = U[:, :r]\n",
        "        elif self.subspace_type == 'middle':\n",
        "            # Middle-r singular vectors\n",
        "            mid_start = d // 2 - r // 2\n",
        "            basis = U[:, mid_start:mid_start + r]\n",
        "        elif self.subspace_type == 'random':\n",
        "            # Random orthonormal basis (consistent across runs with same seed)\n",
        "            np.random.seed(self.random_seed + hash(layer_key) % 10000)\n",
        "            random_matrix = np.random.randn(d, r)\n",
        "            basis, _ = np.linalg.qr(random_matrix)\n",
        "            # Store for reporting\n",
        "            self.random_bases[layer_key] = basis.copy()\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown subspace type: {self.subspace_type}\")\n",
        "\n",
        "        return basis\n",
        "\n",
        "    def _add_adapters(self):\n",
        "        \"\"\"Add adapters to specified layers\"\"\"\n",
        "        for layer_name, block_idx, conv_name in self.adapter_layers:\n",
        "            # layer_key = f\"{layer_name}.{block_idx}.{conv_name}\"\n",
        "            layer_key = f\"{layer_name}_{block_idx}_{conv_name}\"\n",
        "\n",
        "            # Get original conv layer\n",
        "            conv = self._get_conv_layer(layer_name, block_idx, conv_name)\n",
        "\n",
        "            # Compute subspace basis\n",
        "            basis = self._compute_subspace_basis(conv, layer_key)\n",
        "\n",
        "            # Create adapter\n",
        "            adapter = SubspaceAdapter(conv, basis, scale=1.0)\n",
        "\n",
        "            # Replace conv with adapter\n",
        "            self._set_conv_layer(layer_name, block_idx, conv_name, adapter)\n",
        "\n",
        "            # Store reference\n",
        "            self.adapters[layer_key] = adapter\n",
        "\n",
        "    def freeze_backbone(self):\n",
        "      for param in self.backbone.parameters():\n",
        "          param.requires_grad = False\n",
        "\n",
        "      # Only unfreeze A (B is a buffer, not a parameter)\n",
        "      for adapter in self.adapters.values():\n",
        "          adapter.A.requires_grad = True\n",
        "\n",
        "      # Unfreeze classifier\n",
        "      for param in self.backbone.fc.parameters():\n",
        "          param.requires_grad = True\n",
        "\n",
        "      # BatchNorm affine params\n",
        "      for m in self.backbone.modules():\n",
        "          if isinstance(m, nn.BatchNorm2d):\n",
        "              m.eval()\n",
        "              m.weight.requires_grad = True\n",
        "              m.bias.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "    def get_trainable_params(self):\n",
        "        \"\"\"Return number of trainable parameters\"\"\"\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Training and Evaluation Functions\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    # Keep BatchNorm in eval mode\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            m.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += x.size(0)\n",
        "\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    \"\"\"Evaluate on a dataset\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += x.size(0)\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Full Finetuning Baseline\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class ResNet18FullFinetune(nn.Module):\n",
        "    \"\"\"Standard ResNet-18 for full finetuning baseline\"\"\"\n",
        "\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        from torchvision import models\n",
        "        self.backbone = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "        self.backbone.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "    def freeze_backbone(self):\n",
        "        \"\"\"For full finetuning, we don't freeze anything except BN stats\"\"\"\n",
        "        for m in self.backbone.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.eval()\n",
        "                m.weight.requires_grad = True\n",
        "                m.bias.requires_grad = True\n",
        "\n",
        "    def get_trainable_params(self):\n",
        "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Run Single Experiment\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def run_single_experiment(subspace_type, seed):\n",
        "    \"\"\"\n",
        "    Run a single experiment with given subspace type and seed.\n",
        "\n",
        "    Args:\n",
        "        subspace_type: 'minor', 'major', 'middle', 'random', or 'full'\n",
        "        seed: Random seed\n",
        "\n",
        "    Returns:\n",
        "        dict with results\n",
        "    \"\"\"\n",
        "    # Set seeds\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Create model\n",
        "    if subspace_type == 'full':\n",
        "        model = ResNet18FullFinetune(num_classes=7).to(device)\n",
        "    else:\n",
        "        model = ResNet18WithAdapters(\n",
        "            num_classes=7,\n",
        "            adapter_layers=ADAPTER_LAYERS,\n",
        "            subspace_type=subspace_type,\n",
        "            rank=RANK,\n",
        "            random_seed=seed\n",
        "        ).to(device)\n",
        "\n",
        "    # Freeze backbone (except adapters and classifier)\n",
        "    model.freeze_backbone()\n",
        "\n",
        "    # Get trainable params count\n",
        "    trainable_params = model.get_trainable_params()\n",
        "\n",
        "    # Create data loaders\n",
        "    source_loader = get_source_loader()\n",
        "    target_loader = get_target_loader()\n",
        "\n",
        "    # Optimizer and loss\n",
        "    optimizer = torch.optim.Adam(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=LR\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    best_target_acc = 0\n",
        "    history = {'train_loss': [], 'train_acc': [], 'target_acc': []}\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss, train_acc = train_epoch(model, source_loader, optimizer, criterion)\n",
        "        target_acc = evaluate(model, target_loader)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['target_acc'].append(target_acc)\n",
        "\n",
        "        if target_acc > best_target_acc:\n",
        "            best_target_acc = target_acc\n",
        "\n",
        "    # Final evaluation\n",
        "    final_target_acc = evaluate(model, target_loader)\n",
        "\n",
        "    # Also evaluate on source domains individually\n",
        "    source_accs = {}\n",
        "    for domain in SOURCE_DOMAINS:\n",
        "        loader = DataLoader(\n",
        "            get_domain_dataset(domain, test_tf),\n",
        "            batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS\n",
        "        )\n",
        "        source_accs[domain] = evaluate(model, loader)\n",
        "\n",
        "    return {\n",
        "        'subspace_type': subspace_type,\n",
        "        'seed': seed,\n",
        "        'trainable_params': trainable_params,\n",
        "        'final_target_acc': final_target_acc,\n",
        "        'best_target_acc': best_target_acc,\n",
        "        'source_accs': source_accs,\n",
        "        'history': history,\n",
        "    }\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Main Experiment Runner\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def run_experiment_3():\n",
        "    \"\"\"Run the complete Experiment 3\"\"\"\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"EXPERIMENT 3: Subspace Comparison for Domain Generalization\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nConfiguration:\")\n",
        "    print(f\"  Rank: {RANK}\")\n",
        "    print(f\"  Epochs: {EPOCHS}\")\n",
        "    print(f\"  Learning rate: {LR}\")\n",
        "    print(f\"  Source domains: {SOURCE_DOMAINS}\")\n",
        "    print(f\"  Target domain: {TARGET_DOMAIN}\")\n",
        "    print(f\"  Seeds: {SEEDS}\")\n",
        "    print(f\"  Adapter layers: {len(ADAPTER_LAYERS)} layers\")\n",
        "\n",
        "    # Variants to test\n",
        "    variants = ['minor', 'major', 'middle', 'random', 'full']\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for variant in variants:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Running variant: {variant.upper()}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        variant_results = []\n",
        "\n",
        "        for seed in SEEDS:\n",
        "            print(f\"\\n  Seed {seed}...\")\n",
        "            result = run_single_experiment(variant, seed)\n",
        "            variant_results.append(result)\n",
        "\n",
        "            print(f\"    Trainable params: {result['trainable_params']:,}\")\n",
        "            print(f\"    Final target acc: {result['final_target_acc']:.4f}\")\n",
        "            print(f\"    Best target acc:  {result['best_target_acc']:.4f}\")\n",
        "            print(f\"    Source accs: {', '.join([f'{d[:4]}={v:.3f}' for d,v in result['source_accs'].items()])}\")\n",
        "\n",
        "        all_results.extend(variant_results)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Results Analysis and Reporting\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def analyze_results(results):\n",
        "    \"\"\"Analyze and print summary of results\"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    rows = []\n",
        "    for r in results:\n",
        "        rows.append({\n",
        "            'variant': r['subspace_type'],\n",
        "            'seed': r['seed'],\n",
        "            'trainable_params': r['trainable_params'],\n",
        "            'target_acc': r['final_target_acc'],\n",
        "            'best_target_acc': r['best_target_acc'],\n",
        "            'source_photo': r['source_accs'].get('photo', 0),\n",
        "            'source_art': r['source_accs'].get('art_painting', 0),\n",
        "            'source_cartoon': r['source_accs'].get('cartoon', 0),\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # Summary statistics\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"EXPERIMENT 3 RESULTS SUMMARY\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    print(\"\\n--- Target Domain Accuracy (Sketch) ---\")\n",
        "    summary = df.groupby('variant')['target_acc'].agg(['mean', 'std']).round(4)\n",
        "    summary = summary.sort_values('mean', ascending=False)\n",
        "    print(summary)\n",
        "\n",
        "    print(\"\\n--- Best Target Accuracy (over training) ---\")\n",
        "    summary_best = df.groupby('variant')['best_target_acc'].agg(['mean', 'std']).round(4)\n",
        "    summary_best = summary_best.sort_values('mean', ascending=False)\n",
        "    print(summary_best)\n",
        "\n",
        "    print(\"\\n--- Source Domain Accuracies ---\")\n",
        "    for variant in df['variant'].unique():\n",
        "        v_df = df[df['variant'] == variant]\n",
        "        print(f\"\\n{variant.upper()}:\")\n",
        "        print(f\"  Photo:   {v_df['source_photo'].mean():.4f} ± {v_df['source_photo'].std():.4f}\")\n",
        "        print(f\"  Art:     {v_df['source_art'].mean():.4f} ± {v_df['source_art'].std():.4f}\")\n",
        "        print(f\"  Cartoon: {v_df['source_cartoon'].mean():.4f} ± {v_df['source_cartoon'].std():.4f}\")\n",
        "\n",
        "    print(\"\\n--- Trainable Parameters ---\")\n",
        "    params = df.groupby('variant')['trainable_params'].first()\n",
        "    print(params)\n",
        "\n",
        "    # Statistical comparison\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"KEY COMPARISONS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    minor_acc = df[df['variant'] == 'minor']['target_acc'].values\n",
        "    major_acc = df[df['variant'] == 'major']['target_acc'].values\n",
        "    middle_acc = df[df['variant'] == 'middle']['target_acc'].values\n",
        "    random_acc = df[df['variant'] == 'random']['target_acc'].values\n",
        "    full_acc = df[df['variant'] == 'full']['target_acc'].values\n",
        "\n",
        "    print(f\"\\nMinor vs Major: {minor_acc.mean():.4f} vs {major_acc.mean():.4f} (diff: {minor_acc.mean() - major_acc.mean():+.4f})\")\n",
        "    print(f\"Minor vs Middle: {minor_acc.mean():.4f} vs {middle_acc.mean():.4f} (diff: {minor_acc.mean() - middle_acc.mean():+.4f})\")\n",
        "    print(f\"Minor vs Random: {minor_acc.mean():.4f} vs {random_acc.mean():.4f} (diff: {minor_acc.mean() - random_acc.mean():+.4f})\")\n",
        "    print(f\"Minor vs Full: {minor_acc.mean():.4f} vs {full_acc.mean():.4f} (diff: {minor_acc.mean() - full_acc.mean():+.4f})\")\n",
        "\n",
        "    # Interpretation\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"INTERPRETATION\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    constrained_accs = np.concatenate([minor_acc, major_acc, middle_acc, random_acc])\n",
        "    constrained_mean = constrained_accs.mean()\n",
        "    constrained_std = constrained_accs.std()\n",
        "\n",
        "    print(f\"\\nAll constrained methods: {constrained_mean:.4f} ± {constrained_std:.4f}\")\n",
        "    print(f\"Full finetuning:         {full_acc.mean():.4f} ± {full_acc.std():.4f}\")\n",
        "\n",
        "    # Check if minor is special\n",
        "    minor_vs_others = minor_acc.mean() - np.mean([major_acc.mean(), middle_acc.mean(), random_acc.mean()])\n",
        "    print(f\"\\nMinor vs average of other constrained: {minor_vs_others:+.4f}\")\n",
        "\n",
        "    if abs(minor_vs_others) < 0.02:\n",
        "        print(\"\\n→ Minor is NOT special. All subspace constraints perform similarly.\")\n",
        "        print(\"→ SoMA's benefit likely comes from regularization, not subspace selection.\")\n",
        "    elif minor_vs_others > 0.02:\n",
        "        print(\"\\n→ Minor outperforms other subspaces. SoMA's hypothesis may have merit.\")\n",
        "    else:\n",
        "        print(\"\\n→ Minor underperforms other subspaces. SoMA's hypothesis is contradicted.\")\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Run Everything\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run experiments\n",
        "    results = run_experiment_3()\n",
        "\n",
        "    # Analyze results\n",
        "    df = analyze_results(results)\n",
        "\n",
        "    # Save results\n",
        "    df.to_csv(f\"{PROJECT_ROOT}/experiment3_results.csv\", index=False)\n",
        "    print(f\"\\nResults saved to {PROJECT_ROOT}/experiment3_results.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NcYRkrtH0j3q",
        "outputId": "349c7251-527f-44e5-c648-294cdfc8ddbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "======================================================================\n",
            "EXPERIMENT 3: Subspace Comparison for Domain Generalization\n",
            "======================================================================\n",
            "\n",
            "Configuration:\n",
            "  Rank: 8\n",
            "  Epochs: 10\n",
            "  Learning rate: 0.0001\n",
            "  Source domains: ['photo', 'art_painting', 'cartoon']\n",
            "  Target domain: sketch\n",
            "  Seeds: [42, 123, 456]\n",
            "  Adapter layers: 6 layers\n",
            "\n",
            "======================================================================\n",
            "Running variant: MINOR\n",
            "======================================================================\n",
            "\n",
            "  Seed 42...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.5500\n",
            "    Best target acc:  0.5862\n",
            "    Source accs: phot=0.990, art_=0.965, cart=0.956\n",
            "\n",
            "  Seed 123...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.5330\n",
            "    Best target acc:  0.5948\n",
            "    Source accs: phot=0.995, art_=0.965, cart=0.958\n",
            "\n",
            "  Seed 456...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.3691\n",
            "    Best target acc:  0.4910\n",
            "    Source accs: phot=0.993, art_=0.962, cart=0.954\n",
            "\n",
            "======================================================================\n",
            "Running variant: MAJOR\n",
            "======================================================================\n",
            "\n",
            "  Seed 42...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-884700661.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;31m# Run experiments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;31m# Analyze results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-884700661.py\u001b[0m in \u001b[0;36mrun_experiment_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSEEDS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n  Seed {seed}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_single_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0mvariant_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-884700661.py\u001b[0m in \u001b[0;36mrun_single_experiment\u001b[0;34m(subspace_type, seed)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mtarget_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-884700661.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Main Experiment Runner\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def run_experiment_3():\n",
        "    \"\"\"Run the complete Experiment 3\"\"\"\n",
        "    SEEDS = [42]\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"EXPERIMENT 3: Subspace Comparison for Domain Generalization\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nConfiguration:\")\n",
        "    print(f\"  Rank: {RANK}\")\n",
        "    print(f\"  Epochs: {EPOCHS}\")\n",
        "    print(f\"  Learning rate: {LR}\")\n",
        "    print(f\"  Source domains: {SOURCE_DOMAINS}\")\n",
        "    print(f\"  Target domain: {TARGET_DOMAIN}\")\n",
        "    print(f\"  Seeds: {SEEDS}\")\n",
        "    print(f\"  Adapter layers: {len(ADAPTER_LAYERS)} layers\")\n",
        "\n",
        "    # Variants to test\n",
        "    variants = ['major', 'middle', 'random', 'full']\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for variant in variants:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Running variant: {variant.upper()}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        variant_results = []\n",
        "\n",
        "        for seed in SEEDS:\n",
        "            print(f\"\\n  Seed {seed}...\")\n",
        "            result = run_single_experiment(variant, seed)\n",
        "            variant_results.append(result)\n",
        "\n",
        "            print(f\"    Trainable params: {result['trainable_params']:,}\")\n",
        "            print(f\"    Final target acc: {result['final_target_acc']:.4f}\")\n",
        "            print(f\"    Best target acc:  {result['best_target_acc']:.4f}\")\n",
        "            print(f\"    Source accs: {', '.join([f'{d[:4]}={v:.3f}' for d,v in result['source_accs'].items()])}\")\n",
        "\n",
        "        all_results.extend(variant_results)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Run Everything\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run experiments\n",
        "    results = run_experiment_3()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s4t8KveA4jJ",
        "outputId": "995daf00-ab9b-4358-c4d5-404a37019959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EXPERIMENT 3: Subspace Comparison for Domain Generalization\n",
            "======================================================================\n",
            "\n",
            "Configuration:\n",
            "  Rank: 8\n",
            "  Epochs: 10\n",
            "  Learning rate: 0.0001\n",
            "  Source domains: ['photo', 'art_painting', 'cartoon']\n",
            "  Target domain: sketch\n",
            "  Seeds: [42]\n",
            "  Adapter layers: 6 layers\n",
            "\n",
            "======================================================================\n",
            "Running variant: MAJOR\n",
            "======================================================================\n",
            "\n",
            "  Seed 42...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.5668\n",
            "    Best target acc:  0.5750\n",
            "    Source accs: phot=0.991, art_=0.966, cart=0.971\n",
            "\n",
            "======================================================================\n",
            "Running variant: MIDDLE\n",
            "======================================================================\n",
            "\n",
            "  Seed 42...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.6139\n",
            "    Best target acc:  0.6139\n",
            "    Source accs: phot=0.992, art_=0.970, cart=0.962\n",
            "\n",
            "======================================================================\n",
            "Running variant: RANDOM\n",
            "======================================================================\n",
            "\n",
            "  Seed 42...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.6124\n",
            "    Best target acc:  0.6124\n",
            "    Source accs: phot=0.990, art_=0.967, cart=0.965\n",
            "\n",
            "======================================================================\n",
            "Running variant: FULL\n",
            "======================================================================\n",
            "\n",
            "  Seed 42...\n",
            "    Trainable params: 11,180,103\n",
            "    Final target acc: 0.6760\n",
            "    Best target acc:  0.7597\n",
            "    Source accs: phot=0.984, art_=0.968, cart=0.997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Main Experiment Runner\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def run_experiment_3():\n",
        "    \"\"\"Run the complete Experiment 3\"\"\"\n",
        "    SEEDS = [456]\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"EXPERIMENT 3: Subspace Comparison for Domain Generalization\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nConfiguration:\")\n",
        "    print(f\"  Rank: {RANK}\")\n",
        "    print(f\"  Epochs: {EPOCHS}\")\n",
        "    print(f\"  Learning rate: {LR}\")\n",
        "    print(f\"  Source domains: {SOURCE_DOMAINS}\")\n",
        "    print(f\"  Target domain: {TARGET_DOMAIN}\")\n",
        "    print(f\"  Seeds: {SEEDS}\")\n",
        "    print(f\"  Adapter layers: {len(ADAPTER_LAYERS)} layers\")\n",
        "\n",
        "    # Variants to test\n",
        "    variants = ['major', 'middle', 'random', 'full']\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for variant in variants:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Running variant: {variant.upper()}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        variant_results = []\n",
        "\n",
        "        for seed in SEEDS:\n",
        "            print(f\"\\n  Seed {seed}...\")\n",
        "            result = run_single_experiment(variant, seed)\n",
        "            variant_results.append(result)\n",
        "\n",
        "            print(f\"    Trainable params: {result['trainable_params']:,}\")\n",
        "            print(f\"    Final target acc: {result['final_target_acc']:.4f}\")\n",
        "            print(f\"    Best target acc:  {result['best_target_acc']:.4f}\")\n",
        "            print(f\"    Source accs: {', '.join([f'{d[:4]}={v:.3f}' for d,v in result['source_accs'].items()])}\")\n",
        "\n",
        "        all_results.extend(variant_results)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Run Everything\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run experiments\n",
        "    results = run_experiment_3()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_mTSgfQEmsa",
        "outputId": "560b3573-fa1e-498b-cc24-d407024fea09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EXPERIMENT 3: Subspace Comparison for Domain Generalization\n",
            "======================================================================\n",
            "\n",
            "Configuration:\n",
            "  Rank: 8\n",
            "  Epochs: 10\n",
            "  Learning rate: 0.0001\n",
            "  Source domains: ['photo', 'art_painting', 'cartoon']\n",
            "  Target domain: sketch\n",
            "  Seeds: [456]\n",
            "  Adapter layers: 6 layers\n",
            "\n",
            "======================================================================\n",
            "Running variant: MAJOR\n",
            "======================================================================\n",
            "\n",
            "  Seed 456...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.5574\n",
            "    Best target acc:  0.6363\n",
            "    Source accs: phot=0.994, art_=0.974, cart=0.971\n",
            "\n",
            "======================================================================\n",
            "Running variant: MIDDLE\n",
            "======================================================================\n",
            "\n",
            "  Seed 456...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.4248\n",
            "    Best target acc:  0.5383\n",
            "    Source accs: phot=0.994, art_=0.966, cart=0.960\n",
            "\n",
            "======================================================================\n",
            "Running variant: RANDOM\n",
            "======================================================================\n",
            "\n",
            "  Seed 456...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.4782\n",
            "    Best target acc:  0.5566\n",
            "    Source accs: phot=0.989, art_=0.964, cart=0.962\n",
            "\n",
            "======================================================================\n",
            "Running variant: FULL\n",
            "======================================================================\n",
            "\n",
            "  Seed 456...\n",
            "    Trainable params: 11,180,103\n",
            "    Final target acc: 0.7333\n",
            "    Best target acc:  0.7585\n",
            "    Source accs: phot=0.982, art_=0.970, cart=0.982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Main Experiment Runner\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def run_experiment_3():\n",
        "    \"\"\"Run the complete Experiment 3\"\"\"\n",
        "    SEEDS = [123]\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"EXPERIMENT 3: Subspace Comparison for Domain Generalization\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"\\nConfiguration:\")\n",
        "    print(f\"  Rank: {RANK}\")\n",
        "    print(f\"  Epochs: {EPOCHS}\")\n",
        "    print(f\"  Learning rate: {LR}\")\n",
        "    print(f\"  Source domains: {SOURCE_DOMAINS}\")\n",
        "    print(f\"  Target domain: {TARGET_DOMAIN}\")\n",
        "    print(f\"  Seeds: {SEEDS}\")\n",
        "    print(f\"  Adapter layers: {len(ADAPTER_LAYERS)} layers\")\n",
        "\n",
        "    # Variants to test\n",
        "    variants = ['major', 'middle', 'random', 'full']\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for variant in variants:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Running variant: {variant.upper()}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        variant_results = []\n",
        "\n",
        "        for seed in SEEDS:\n",
        "            print(f\"\\n  Seed {seed}...\")\n",
        "            result = run_single_experiment(variant, seed)\n",
        "            variant_results.append(result)\n",
        "\n",
        "            print(f\"    Trainable params: {result['trainable_params']:,}\")\n",
        "            print(f\"    Final target acc: {result['final_target_acc']:.4f}\")\n",
        "            print(f\"    Best target acc:  {result['best_target_acc']:.4f}\")\n",
        "            print(f\"    Source accs: {', '.join([f'{d[:4]}={v:.3f}' for d,v in result['source_accs'].items()])}\")\n",
        "\n",
        "        all_results.extend(variant_results)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Run Everything\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Run experiments\n",
        "    results = run_experiment_3()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQTmXwvPHLKX",
        "outputId": "e98b694b-2e7d-4e18-b342-c4957f88b2d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EXPERIMENT 3: Subspace Comparison for Domain Generalization\n",
            "======================================================================\n",
            "\n",
            "Configuration:\n",
            "  Rank: 8\n",
            "  Epochs: 10\n",
            "  Learning rate: 0.0001\n",
            "  Source domains: ['photo', 'art_painting', 'cartoon']\n",
            "  Target domain: sketch\n",
            "  Seeds: [123]\n",
            "  Adapter layers: 6 layers\n",
            "\n",
            "======================================================================\n",
            "Running variant: MAJOR\n",
            "======================================================================\n",
            "\n",
            "  Seed 123...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.6266\n",
            "    Best target acc:  0.6266\n",
            "    Source accs: phot=0.993, art_=0.969, cart=0.968\n",
            "\n",
            "======================================================================\n",
            "Running variant: MIDDLE\n",
            "======================================================================\n",
            "\n",
            "  Seed 123...\n",
            "    Trainable params: 142,215\n",
            "    Final target acc: 0.5052\n",
            "    Best target acc:  0.5169\n",
            "    Source accs: phot=0.992, art_=0.969, cart=0.958\n",
            "\n",
            "======================================================================\n",
            "Running variant: RANDOM\n",
            "======================================================================\n",
            "\n",
            "  Seed 123...\n"
          ]
        }
      ]
    }
  ]
}