{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eprJLeJVbH2X",
        "outputId": "89f7d894-7c11-4d70-bfd6-f2d23f80be22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "PACS_ROOT: /content/drive/MyDrive/datasets/PACS\n",
            "PROJECT_ROOT: /content/drive/MyDrive/SoMA_PACS_E3\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 0) MOUNT DRIVE + PATHS\n",
        "# ============================================================\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import os, json, math, copy, time, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# >>> Set these two paths <<<\n",
        "PACS_ROOT = \"/content/drive/MyDrive/datasets/PACS\"      # your ImageFolder PACS\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/SoMA_PACS_E3\"    # outputs\n",
        "\n",
        "os.makedirs(PROJECT_ROOT, exist_ok=True)\n",
        "print(\"PACS_ROOT:\", PACS_ROOT)\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 1) REPRODUCIBILITY + DEVICE\n",
        "# ============================================================\n",
        "def set_seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7heYcC9brDM",
        "outputId": "f931c6c8-739c-4f93-b49c-c30c8ff2f293"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DATALOADER WORKER SEEDING (DETERMINISTIC)\n",
        "# ============================================================\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n"
      ],
      "metadata": {
        "id": "sKo7XX34ks-z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 2) CONFIG (Scope 1 default)\n",
        "# ============================================================\n",
        "CFG = {\n",
        "    # Data\n",
        "    \"source_domains\": [\"photo\", \"art_painting\", \"cartoon\"],\n",
        "    \"target_domain\": \"sketch\",\n",
        "    \"img_size\": 224,\n",
        "    \"batch_size_per_domain\": 16,   # per-domain batch; total batch = 3x this\n",
        "    \"num_workers\": 2,\n",
        "\n",
        "    # Training\n",
        "    \"epochs\": 20,\n",
        "    \"lr_full\": 3e-4,    # Adam\n",
        "    \"lr_adapter\": 1e-3, # Adam\n",
        "    \"weight_decay\": 0.0,\n",
        "\n",
        "    # Adapters\n",
        "    \"rank\": 8,\n",
        "    \"adapter_scale\": 1.0,\n",
        "\n",
        "    # Scope\n",
        "    \"scope\": \"layer4_only\",   # <-- run this now\n",
        "    # \"scope\": \"layer3_layer4\",  # <-- later\n",
        "\n",
        "    # ΔW subspace computation\n",
        "    \"deltaW_small_adapt_epochs\": 1,   # small adaptation\n",
        "    \"deltaW_lr\": 1e-3,\n",
        "    \"deltaW_examples_per_class\": 20,  # per-domain, per-class (class-balanced)\n",
        "    \"freeze_bn_stats\": True,\n",
        "\n",
        "    # Seeds\n",
        "    \"seeds\": [42, 123],\n",
        "}\n",
        "\n",
        "# Adapter layer specs per scope\n",
        "SCOPE_LAYERS = {\n",
        "    \"layer4_only\": [\n",
        "        (\"layer4\", 0, \"conv2\"),\n",
        "        (\"layer4\", 1, \"conv2\"),\n",
        "    ],\n",
        "    \"layer3_layer4\": [\n",
        "        (\"layer3\", 0, \"conv2\"),\n",
        "        (\"layer3\", 1, \"conv2\"),\n",
        "        (\"layer4\", 0, \"conv2\"),\n",
        "        (\"layer4\", 1, \"conv2\"),\n",
        "    ],\n",
        "}\n",
        "\n",
        "# ADAPTER_LAYERS = SCOPE_LAYERS[CFG[\"scope\"]]\n",
        "CFG[\"scope\"] = \"layer3_layer4\"\n",
        "ADAPTER_LAYERS = SCOPE_LAYERS[CFG[\"scope\"]]\n",
        "print(\"Scope:\", CFG[\"scope\"])\n",
        "print(\"Adapter layers:\", ADAPTER_LAYERS)\n",
        "\n",
        "# Variants to compare\n",
        "VARIANTS = [\"soma_minor\", \"soma_major\", \"random\", \"full_finetune\",\"deltaW_subspace\"]\n",
        "\n",
        "# Save config\n",
        "with open(os.path.join(PROJECT_ROOT, f\"config_{CFG['scope']}.json\"), \"w\") as f:\n",
        "    json.dump(CFG, f, indent=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPHAranPbt8a",
        "outputId": "492c7d7d-062c-4c7f-acf8-50b8c9dfd552"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scope: layer3_layer4\n",
            "Adapter layers: [('layer3', 0, 'conv2'), ('layer3', 1, 'conv2'), ('layer4', 0, 'conv2'), ('layer4', 1, 'conv2')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 3) TRANSFORMS + DATASET HELPERS\n",
        "# ============================================================\n",
        "IMG_SIZE = CFG[\"img_size\"]\n",
        "\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "def get_domain_dataset(domain, tfm):\n",
        "    return datasets.ImageFolder(root=os.path.join(PACS_ROOT, domain), transform=tfm)\n",
        "\n",
        "def make_class_balanced_loader(domain, tfm, batch_size, num_workers, seed=0, limit_per_class=None):\n",
        "    \"\"\"\n",
        "    Returns a DataLoader with WeightedRandomSampler to balance classes within this domain.\n",
        "    Optional limit_per_class creates a small balanced subset (used for ΔW small adapt).\n",
        "    \"\"\"\n",
        "    ds = get_domain_dataset(domain, tfm)\n",
        "\n",
        "    # Optional: create a small class-balanced subset\n",
        "    if limit_per_class is not None:\n",
        "        # indices per class\n",
        "        cls_to_idx = ds.class_to_idx\n",
        "        targets = np.array([y for _, y in ds.samples])\n",
        "        idxs = []\n",
        "        rng = np.random.default_rng(seed)\n",
        "        for c in range(len(cls_to_idx)):\n",
        "            cls_idxs = np.where(targets == c)[0]\n",
        "            if len(cls_idxs) == 0:\n",
        "                continue\n",
        "            take = min(limit_per_class, len(cls_idxs))\n",
        "            chosen = rng.choice(cls_idxs, size=take, replace=False)\n",
        "            idxs.extend(chosen.tolist())\n",
        "        idxs = np.array(sorted(idxs))\n",
        "        # wrap subset\n",
        "        ds = torch.utils.data.Subset(ds, idxs)\n",
        "        # need subset targets for sampler\n",
        "        subset_targets = targets[idxs]\n",
        "        targets_for_weights = subset_targets\n",
        "    else:\n",
        "        targets_for_weights = np.array([y for _, y in ds.samples])\n",
        "\n",
        "    # weights inverse frequency\n",
        "    class_counts = np.bincount(targets_for_weights, minlength=7).astype(np.float64)\n",
        "    class_counts[class_counts == 0] = 1.0\n",
        "    class_weights = 1.0 / class_counts\n",
        "    sample_weights = class_weights[targets_for_weights]\n",
        "\n",
        "    g = torch.Generator()\n",
        "    g.manual_seed(seed)\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=torch.tensor(sample_weights, dtype=torch.double),\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True,\n",
        "        generator=g\n",
        "    )\n",
        "\n",
        "    loader = DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        sampler=sampler,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return loader\n",
        "\n",
        "def make_plain_loader(domain, tfm, batch_size, num_workers, shuffle=False):\n",
        "    ds = get_domain_dataset(domain, tfm)\n",
        "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "class MultiDomainBatcher:\n",
        "    \"\"\"\n",
        "    Iterates over multiple loaders and yields a domain-balanced batch by concatenation:\n",
        "    one batch from each domain -> concat along batch dimension.\n",
        "    \"\"\"\n",
        "    def __init__(self, loaders):\n",
        "        self.loaders = loaders\n",
        "\n",
        "    def __iter__(self):\n",
        "        iters = [iter(l) for l in self.loaders]\n",
        "        while True:\n",
        "            xs, ys = [], []\n",
        "            for i, it in enumerate(iters):\n",
        "                try:\n",
        "                    x, y = next(it)\n",
        "                except StopIteration:\n",
        "                    return\n",
        "                xs.append(x)\n",
        "                ys.append(y)\n",
        "            yield torch.cat(xs, dim=0), torch.cat(ys, dim=0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(l) for l in self.loaders)\n"
      ],
      "metadata": {
        "id": "fqly1EyNbwd_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SOURCE TRAIN/VAL SPLITS (NO TARGET PEEKING)\n",
        "# ============================================================\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "def split_indices_stratified(ds, val_frac=0.2, seed=0):\n",
        "    # ds is ImageFolder; ds.samples = [(path, y), ...]\n",
        "    rng = np.random.default_rng(seed)\n",
        "    targets = np.array([y for _, y in ds.samples])\n",
        "    n_classes = targets.max() + 1\n",
        "\n",
        "    train_idx, val_idx = [], []\n",
        "    for c in range(n_classes):\n",
        "        idx_c = np.where(targets == c)[0]\n",
        "        rng.shuffle(idx_c)\n",
        "        n_val = int(math.ceil(val_frac * len(idx_c)))\n",
        "        val_idx.extend(idx_c[:n_val].tolist())\n",
        "        train_idx.extend(idx_c[n_val:].tolist())\n",
        "\n",
        "    rng.shuffle(train_idx)\n",
        "    rng.shuffle(val_idx)\n",
        "    return train_idx, val_idx\n",
        "\n",
        "def make_subset_loader(ds_full, indices, batch_size, num_workers, shuffle, seed=0, class_balance=False, augment=False):\n",
        "    ds = Subset(ds_full, indices)\n",
        "\n",
        "    # Build sampler if class_balance\n",
        "    if class_balance:\n",
        "        # Need targets for subset\n",
        "        targets = np.array([ds_full.samples[i][1] for i in indices])\n",
        "        class_counts = np.bincount(targets, minlength=7).astype(np.float64)\n",
        "        class_counts[class_counts == 0] = 1.0\n",
        "        class_weights = 1.0 / class_counts\n",
        "        sample_weights = class_weights[targets]\n",
        "\n",
        "        g = torch.Generator().manual_seed(seed)\n",
        "        sampler = WeightedRandomSampler(\n",
        "            weights=torch.tensor(sample_weights, dtype=torch.double),\n",
        "            num_samples=len(sample_weights),\n",
        "            replacement=True,\n",
        "            generator=g\n",
        "        )\n",
        "        return DataLoader(ds, batch_size=batch_size, sampler=sampler,\n",
        "                          num_workers=num_workers, pin_memory=True,\n",
        "                          worker_init_fn=seed_worker, generator=g)\n",
        "    else:\n",
        "        g = torch.Generator().manual_seed(seed)\n",
        "        return DataLoader(ds, batch_size=batch_size, shuffle=shuffle,\n",
        "                          num_workers=num_workers, pin_memory=True,\n",
        "                          worker_init_fn=seed_worker, generator=g)\n",
        "\n",
        "def build_source_train_val_loaders(seed, val_frac=0.2):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      train_loaders: list over source domains (class-balanced, augmented)\n",
        "      val_loaders:   list over source domains (plain, no augmentation)\n",
        "    \"\"\"\n",
        "    train_loaders, val_loaders = [], []\n",
        "    for dom in CFG[\"source_domains\"]:\n",
        "        ds_train_aug = get_domain_dataset(dom, train_tf)  # aug tf\n",
        "        ds_val_plain = get_domain_dataset(dom, test_tf)   # no aug tf\n",
        "\n",
        "        train_idx, val_idx = split_indices_stratified(ds_train_aug, val_frac=val_frac, seed=seed)\n",
        "\n",
        "        tr_loader = make_subset_loader(ds_train_aug, train_idx,\n",
        "                                       batch_size=CFG[\"batch_size_per_domain\"],\n",
        "                                       num_workers=CFG[\"num_workers\"],\n",
        "                                       shuffle=False, seed=seed,\n",
        "                                       class_balance=True)\n",
        "\n",
        "        va_loader = make_subset_loader(ds_val_plain, val_idx,\n",
        "                                       batch_size=CFG[\"batch_size_per_domain\"] * len(CFG[\"source_domains\"]),\n",
        "                                       num_workers=CFG[\"num_workers\"],\n",
        "                                       shuffle=False, seed=seed,\n",
        "                                       class_balance=False)\n",
        "        train_loaders.append(tr_loader)\n",
        "        val_loaders.append(va_loader)\n",
        "\n",
        "    return train_loaders, val_loaders\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_acc_multi(model, loaders):\n",
        "    accs = [evaluate_acc(model, l) for l in loaders]\n",
        "    return float(np.mean(accs)), [float(a) for a in accs]\n"
      ],
      "metadata": {
        "id": "5ufgMrDCiM-Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 4) MODEL: ADAPTER MODULE + RESNET18 WRAPPER\n",
        "# ============================================================\n",
        "class FrozenSubspaceAdapter(nn.Module):\n",
        "    \"\"\"\n",
        "    Adapter for a Conv2d layer:\n",
        "      y = conv(x) + scale * B( A(x) )\n",
        "    where:\n",
        "      A is a trainable kxk conv:  C_in -> r\n",
        "      B is a frozen 1x1 conv:     r -> C_out  (weights set to subspace basis)\n",
        "    \"\"\"\n",
        "    def __init__(self, conv: nn.Conv2d, basis_U: np.ndarray, scale=1.0):\n",
        "        super().__init__()\n",
        "        assert isinstance(conv, nn.Conv2d)\n",
        "        C_out, C_in, k1, k2 = conv.weight.shape\n",
        "        r = basis_U.shape[1]\n",
        "        assert basis_U.shape == (C_out, r)\n",
        "\n",
        "        self.conv = conv\n",
        "        self.scale = scale\n",
        "\n",
        "        # Trainable A: kxk conv mapping into rank-r space\n",
        "        self.A = nn.Conv2d(\n",
        "            in_channels=C_in, out_channels=r,\n",
        "            kernel_size=(k1, k2),\n",
        "            stride=conv.stride, padding=conv.padding,\n",
        "            bias=False\n",
        "        )\n",
        "        nn.init.normal_(self.A.weight, mean=0.0, std=0.01)\n",
        "\n",
        "        # Frozen B: 1x1 conv mapping back to C_out\n",
        "        self.B = nn.Conv2d(in_channels=r, out_channels=C_out, kernel_size=1, bias=False)\n",
        "        with torch.no_grad():\n",
        "            Wb = torch.from_numpy(basis_U.astype(np.float32))  # [C_out, r]\n",
        "            self.B.weight.copy_(Wb[:, :, None, None])          # [C_out, r, 1, 1]\n",
        "        for p in self.B.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        adapt = self.B(self.A(x))\n",
        "        return out + self.scale * adapt\n",
        "\n",
        "class ResNet18WithAdapters(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "        self.backbone.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "        # store adapters (purely for bookkeeping)\n",
        "        self.adapters = nn.ModuleDict()\n",
        "\n",
        "    def _get_conv(self, layer_name, block_idx, conv_name):\n",
        "        layer = getattr(self.backbone, layer_name)\n",
        "        block = layer[block_idx]\n",
        "        return getattr(block, conv_name)\n",
        "\n",
        "    def _set_conv(self, layer_name, block_idx, conv_name, new_module):\n",
        "        layer = getattr(self.backbone, layer_name)\n",
        "        block = layer[block_idx]\n",
        "        setattr(block, conv_name, new_module)\n",
        "\n",
        "    def install_adapters(self, adapter_layers, bases_by_layer, scale=1.0):\n",
        "        \"\"\"\n",
        "        bases_by_layer: dict key -> np.ndarray [C_out, r]\n",
        "        key is f\"{layer_name}_{block_idx}_{conv_name}\"\n",
        "        \"\"\"\n",
        "        for (layer_name, block_idx, conv_name) in adapter_layers:\n",
        "            key = f\"{layer_name}_{block_idx}_{conv_name}\"\n",
        "            conv = self._get_conv(layer_name, block_idx, conv_name)\n",
        "            adapter = FrozenSubspaceAdapter(conv, bases_by_layer[key], scale=scale)\n",
        "            self._set_conv(layer_name, block_idx, conv_name, adapter)\n",
        "            self.adapters[key] = adapter\n",
        "\n",
        "    def freeze_bn_running_stats(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.eval()\n",
        "\n",
        "    def set_bn_affine_trainable(self, trainable=True):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                if m.weight is not None: m.weight.requires_grad = trainable\n",
        "                if m.bias is not None:   m.bias.requires_grad = trainable\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "def freeze_all_params(model: nn.Module):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "def count_trainable(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ],
      "metadata": {
        "id": "WzGoLJN3by9g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 5) SUBSPACE BASES: SoMA major/minor/random AND ΔW-subspace\n",
        "# ============================================================\n",
        "def conv_weight_matrix(conv: nn.Conv2d) -> np.ndarray:\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    return W.reshape(W.shape[0], -1)  # [C_out, D]\n",
        "\n",
        "def svd_U(Wmat: np.ndarray):\n",
        "    U, S, Vt = np.linalg.svd(Wmat, full_matrices=False)\n",
        "    return U, S\n",
        "\n",
        "def make_random_basis(C_out, r, seed):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    Q, _ = np.linalg.qr(rng.standard_normal((C_out, r)))\n",
        "    return Q\n",
        "\n",
        "def compute_bases_from_imagenet(model: ResNet18WithAdapters, adapter_layers, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    kind: soma_major / soma_minor / random\n",
        "    computed from ImageNet weights of the model (before any PACS training)\n",
        "    \"\"\"\n",
        "    bases = {}\n",
        "    for (layer_name, block_idx, conv_name) in adapter_layers:\n",
        "        key = f\"{layer_name}_{block_idx}_{conv_name}\"\n",
        "        conv = getattr(getattr(model.backbone, layer_name)[block_idx], conv_name)\n",
        "        Wmat = conv_weight_matrix(conv)\n",
        "        U, _ = svd_U(Wmat)\n",
        "        C_out = U.shape[0]\n",
        "\n",
        "        if kind == \"soma_major\":\n",
        "            bases[key] = U[:, :r]\n",
        "        elif kind == \"soma_minor\":\n",
        "            bases[key] = U[:, -r:]\n",
        "        elif kind == \"random\":\n",
        "            # seed per-layer for stability\n",
        "            bases[key] = make_random_basis(C_out, r, seed=seed + abs(hash(key)) % 10000)\n",
        "        else:\n",
        "            raise ValueError(kind)\n",
        "    return bases\n"
      ],
      "metadata": {
        "id": "dqA5dJ5Kb2Dd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 6) ΔW-SUBSPACE COMPUTATION (from ImageNet model via small per-domain adaptations)\n",
        "# ============================================================\n",
        "def set_train_mode_bn_frozen(model: nn.Module):\n",
        "    model.train()\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            m.eval()\n",
        "\n",
        "def build_deltaW_channel_subspace(dW_list):\n",
        "    \"\"\"\n",
        "    dW_list: list of ΔW matrices for one layer, each [C_out, D]\n",
        "    returns eigvecs [C_out, C_out] sorted desc\n",
        "    \"\"\"\n",
        "    C_out = dW_list[0].shape[0]\n",
        "    C = np.zeros((C_out, C_out), dtype=np.float64)\n",
        "    for dW in dW_list:\n",
        "        C += dW @ dW.T\n",
        "    eigvals, eigvecs = np.linalg.eigh(C)\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "    eigvecs = eigvecs[:, idx]\n",
        "    eigvals = eigvals[idx]\n",
        "    return eigvecs, eigvals\n",
        "\n",
        "def tiny_adapt_and_get_deltaW_bases(\n",
        "    base_imagenet_model: ResNet18WithAdapters,\n",
        "    adapter_layers,\n",
        "    r,\n",
        "    source_domains,\n",
        "    examples_per_class,\n",
        "    epochs,\n",
        "    lr,\n",
        "    seed\n",
        "):\n",
        "    \"\"\"\n",
        "    Match your prior logic:\n",
        "      - for each domain: train small class-balanced subset from ImageNet base\n",
        "      - extract ΔW per layer\n",
        "      - aggregate using C = sum_d ΔWΔW^T\n",
        "      - basis = eigvecs(C)[:, :r]\n",
        "    \"\"\"\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Snapshot W0 for each conv as matrix [C_out, D]\n",
        "    W0 = {}\n",
        "    for (layer_name, block_idx, conv_name) in adapter_layers:\n",
        "        key = f\"{layer_name}_{block_idx}_{conv_name}\"\n",
        "        conv0 = getattr(getattr(base_imagenet_model.backbone, layer_name)[block_idx], conv_name)\n",
        "        W0[key] = conv_weight_matrix(conv0).copy()\n",
        "\n",
        "    # Collect ΔWs per layer\n",
        "    dW_lists = {k: [] for k in W0.keys()}\n",
        "\n",
        "    for dom in source_domains:\n",
        "        m = copy.deepcopy(base_imagenet_model).to(device)\n",
        "\n",
        "        # freeze BN running stats\n",
        "        set_train_mode_bn_frozen(m)\n",
        "        m.set_bn_affine_trainable(True)\n",
        "\n",
        "        # train small subset: allow updating backbone (like your previous code)\n",
        "        # If you want it closer to your prior snippet, keep all params trainable.\n",
        "        for p in m.parameters():\n",
        "            p.requires_grad = True\n",
        "        if CFG[\"freeze_bn_stats\"]:\n",
        "            m.freeze_bn_running_stats()\n",
        "            m.set_bn_affine_trainable(True)\n",
        "\n",
        "        # small balanced loader (subset per class)\n",
        "        loader = make_class_balanced_loader(\n",
        "            dom, train_tf,\n",
        "            batch_size=CFG[\"batch_size_per_domain\"],\n",
        "            num_workers=CFG[\"num_workers\"],\n",
        "            seed=seed,\n",
        "            limit_per_class=examples_per_class\n",
        "        )\n",
        "\n",
        "        opt = torch.optim.Adam(m.parameters(), lr=lr)\n",
        "        crit = nn.CrossEntropyLoss()\n",
        "\n",
        "        for ep in range(epochs):\n",
        "            for x, y in loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                loss = crit(m(x), y)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "        # extract ΔW for each target layer\n",
        "        for (layer_name, block_idx, conv_name) in adapter_layers:\n",
        "            key = f\"{layer_name}_{block_idx}_{conv_name}\"\n",
        "            convd = getattr(getattr(m.backbone, layer_name)[block_idx], conv_name)\n",
        "            Wd = conv_weight_matrix(convd)\n",
        "            dW = Wd - W0[key]\n",
        "            dW_lists[key].append(dW)\n",
        "\n",
        "        del m\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Build bases from channel-covariance eigvecs\n",
        "    bases = {}\n",
        "    for key, dW_list in dW_lists.items():\n",
        "        Ueig, _ = build_deltaW_channel_subspace(dW_list)\n",
        "        bases[key] = Ueig[:, :r]\n",
        "    return bases\n"
      ],
      "metadata": {
        "id": "rB9b7UmYb7uw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 7) TRAIN / EVAL LOOPS (Adapter vs Full finetune)\n",
        "# ============================================================\n",
        "@torch.no_grad()\n",
        "def evaluate_acc(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = model(x).argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "def train_one_epoch_domain_balanced(model, md_batcher, optimizer, criterion, freeze_bn_stats=True):\n",
        "    model.train()\n",
        "    if freeze_bn_stats:\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.eval()\n",
        "\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    for x, y in md_batcher:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    return total_loss / max(1, total), correct / max(1, total)\n",
        "\n",
        "def build_source_loaders(seed):\n",
        "    loaders = []\n",
        "    for d in CFG[\"source_domains\"]:\n",
        "        loaders.append(make_class_balanced_loader(\n",
        "            d, train_tf,\n",
        "            batch_size=CFG[\"batch_size_per_domain\"],\n",
        "            num_workers=CFG[\"num_workers\"],\n",
        "            seed=seed\n",
        "        ))\n",
        "    return loaders\n",
        "\n",
        "def build_target_loader():\n",
        "    return make_plain_loader(\n",
        "        CFG[\"target_domain\"], test_tf,\n",
        "        batch_size=CFG[\"batch_size_per_domain\"] * len(CFG[\"source_domains\"]),\n",
        "        num_workers=CFG[\"num_workers\"],\n",
        "        shuffle=False\n",
        "    )\n"
      ],
      "metadata": {
        "id": "hYnca6UlcCnp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 8) BUILD MODELS PER VARIANT\n",
        "# ============================================================\n",
        "def make_model_for_variant(variant, seed):\n",
        "    \"\"\"\n",
        "    Returns (model, trainable_params_count)\n",
        "    All start from ImageNet pretrained ResNet18.\n",
        "    \"\"\"\n",
        "    set_seed(seed)\n",
        "    base = ResNet18WithAdapters(num_classes=7).to(device)\n",
        "\n",
        "    # BN handling (applies to both adapter and full finetune)\n",
        "    if CFG[\"freeze_bn_stats\"]:\n",
        "        base.freeze_bn_running_stats()\n",
        "        base.set_bn_affine_trainable(True)\n",
        "\n",
        "    if variant == \"full_finetune\":\n",
        "        # train everything except BN running stats (affine trainable)\n",
        "        for p in base.parameters():\n",
        "            p.requires_grad = True\n",
        "        if CFG[\"freeze_bn_stats\"]:\n",
        "            base.freeze_bn_running_stats()\n",
        "            base.set_bn_affine_trainable(True)\n",
        "        return base, count_trainable(base)\n",
        "\n",
        "    # adapter variants\n",
        "    r = CFG[\"rank\"]\n",
        "\n",
        "    if variant in [\"soma_major\", \"soma_minor\", \"random\"]:\n",
        "        bases = compute_bases_from_imagenet(base, ADAPTER_LAYERS, variant, r, seed=seed)\n",
        "\n",
        "    elif variant == \"deltaW_subspace\":\n",
        "        bases = tiny_adapt_and_get_deltaW_bases(\n",
        "            base_imagenet_model=base,\n",
        "            adapter_layers=ADAPTER_LAYERS,\n",
        "            r=r,\n",
        "            source_domains=CFG[\"source_domains\"],\n",
        "            examples_per_class=CFG[\"deltaW_examples_per_class\"],\n",
        "            epochs=CFG[\"deltaW_small_adapt_epochs\"],\n",
        "            lr=CFG[\"deltaW_lr\"],\n",
        "            seed=seed\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Unknown variant: \" + variant)\n",
        "\n",
        "    # install adapters\n",
        "    base.install_adapters(ADAPTER_LAYERS, bases_by_layer=bases, scale=CFG[\"adapter_scale\"])\n",
        "\n",
        "    # freeze all, unfreeze adapter A + fc + BN affine\n",
        "    freeze_all_params(base)\n",
        "    for adapter in base.adapters.values():\n",
        "        adapter.A.weight.requires_grad = True\n",
        "    for p in base.backbone.fc.parameters():\n",
        "        p.requires_grad = True\n",
        "    base.set_bn_affine_trainable(True)\n",
        "\n",
        "    if CFG[\"freeze_bn_stats\"]:\n",
        "        base.set_bn_affine_trainable(True)\n",
        "\n",
        "    if CFG[\"freeze_bn_stats\"]:\n",
        "        base.freeze_bn_running_stats()\n",
        "\n",
        "\n",
        "    return base, count_trainable(base)\n"
      ],
      "metadata": {
        "id": "5AFiWq18cF65"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def run_variant(variant, seed):\n",
        "    model, n_trainable = make_model_for_variant(variant, seed)\n",
        "    model.to(device) # Ensure all adapter layers are on the correct device\n",
        "\n",
        "    # source_loaders = build_source_loaders(seed)\n",
        "    # md_batcher = MultiDomainBatcher(source_loaders)\n",
        "    # target_loader = build_target_loader()\n",
        "\n",
        "    source_train_loaders, source_val_loaders = build_source_train_val_loaders(seed, val_frac=0.2)\n",
        "    md_batcher = MultiDomainBatcher(source_train_loaders)\n",
        "    target_loader = build_target_loader()\n",
        "\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    if variant == \"full_finetune\":\n",
        "        lr = CFG[\"lr_full\"]\n",
        "        # all params trainable already\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=CFG[\"weight_decay\"])\n",
        "    else:\n",
        "        lr = CFG[\"lr_adapter\"]\n",
        "        trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
        "        optimizer = torch.optim.Adam(trainable_params, lr=lr, weight_decay=CFG[\"weight_decay\"])\n",
        "\n",
        "    history = []\n",
        "    best_acc = -1.0\n",
        "    best_path = None\n",
        "\n",
        "    print(variant)\n",
        "\n",
        "    for ep in range(CFG[\"epochs\"]):\n",
        "        t0 = time.time()\n",
        "        print(ep)\n",
        "        tr_loss, tr_acc = train_one_epoch_domain_balanced(\n",
        "            model, md_batcher, optimizer, criterion, freeze_bn_stats=CFG[\"freeze_bn_stats\"]\n",
        "        )\n",
        "        tgt_acc = evaluate_acc(model, target_loader)\n",
        "        dt = time.time() - t0\n",
        "\n",
        "        row = {\n",
        "            \"variant\": variant,\n",
        "            \"seed\": seed,\n",
        "            \"epoch\": ep,\n",
        "            \"train_loss\": tr_loss,\n",
        "            \"train_acc\": tr_acc,\n",
        "            \"tgt_acc\": tgt_acc,\n",
        "            \"lr\": lr,\n",
        "            \"trainable_params\": n_trainable,\n",
        "            \"scope\": CFG[\"scope\"],\n",
        "        }\n",
        "        history.append(row)\n",
        "        print(f\"[{variant} | seed={seed} | ep={ep:02d}] \"\n",
        "              f\"loss={tr_loss:.3f} src_acc={tr_acc:.3f} tgt_acc={tgt_acc:.3f} time={dt:.1f}s\")\n",
        "\n",
        "        # if tgt_acc > best_acc:\n",
        "        #     best_acc = tgt_acc\n",
        "        #     best_path = os.path.join(PROJECT_ROOT, f\"best_{CFG['scope']}_{variant}_seed{seed}.pt\")\n",
        "        #     torch.save(model.state_dict(), best_path)\n",
        "\n",
        "        src_val_mean, src_val_list = evaluate_acc_multi(model, source_val_loaders)\n",
        "        tgt_acc = evaluate_acc(model, target_loader)  # log only\n",
        "\n",
        "        row.update({\n",
        "            \"src_val_mean\": src_val_mean,\n",
        "            \"src_val_photo\": src_val_list[0],\n",
        "            \"src_val_art\": src_val_list[1],\n",
        "            \"src_val_cartoon\": src_val_list[2],\n",
        "        })\n",
        "\n",
        "        # select by source validation ONLY\n",
        "        if src_val_mean > best_acc:\n",
        "            best_acc = src_val_mean\n",
        "            best_path = os.path.join(PROJECT_ROOT, f\"best_{CFG['scope']}_{variant}_seed{seed}.pt\")\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "\n",
        "\n",
        "    # final save\n",
        "    final_path = os.path.join(PROJECT_ROOT, f\"final_{CFG['scope']}_{variant}_seed{seed}.pt\")\n",
        "    torch.save(model.state_dict(), final_path)\n",
        "\n",
        "    return history, best_acc, best_path, final_path\n",
        "\n",
        "all_rows = []\n",
        "summary_rows = []\n",
        "\n",
        "for variant in VARIANTS:\n",
        "    for seed in CFG[\"seeds\"]:\n",
        "        hist, best_acc, best_path, final_path = run_variant(variant, seed)\n",
        "        print(\">>>\")\n",
        "        all_rows.extend(hist)\n",
        "        summary_rows.append({\n",
        "            \"variant\": variant,\n",
        "            \"seed\": seed,\n",
        "            \"best_source_Val_meanACC\": best_acc,\n",
        "            \"best_ckpt\": best_path,\n",
        "            \"final_ckpt\": final_path,\n",
        "            \"scope\": CFG[\"scope\"],\n",
        "        })\n",
        "\n",
        "\n",
        "print(\"yeahhh\")\n",
        "\n",
        "df_hist = pd.DataFrame(all_rows)\n",
        "df_sum = pd.DataFrame(summary_rows)\n",
        "\n",
        "hist_csv = os.path.join(PROJECT_ROOT, f\"e3_adapter_hist_{CFG['scope']}.csv\")\n",
        "sum_csv  = os.path.join(PROJECT_ROOT, f\"e3_adapter_summary_{CFG['scope']}.csv\")\n",
        "df_hist.to_csv(hist_csv, index=False)\n",
        "df_sum.to_csv(sum_csv, index=False)\n",
        "\n",
        "print(\"\\nSaved:\")\n",
        "print(hist_csv)\n",
        "print(sum_csv)\n",
        "df_sum.groupby(\"variant\")[\"best_tgt_acc\"].agg([\"mean\",\"std\"]).sort_values(\"mean\", ascending=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G_qHdJN1cIct",
        "outputId": "17b86cf1-705a-46a2-d5c3-2ea1e324f315"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 182MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "soma_minor\n",
            "0\n",
            "[soma_minor | seed=42 | ep=00] loss=0.620 src_acc=0.788 tgt_acc=0.503 time=1760.3s\n",
            "1\n",
            "[soma_minor | seed=42 | ep=01] loss=0.242 src_acc=0.916 tgt_acc=0.532 time=218.6s\n",
            "2\n",
            "[soma_minor | seed=42 | ep=02] loss=0.144 src_acc=0.953 tgt_acc=0.622 time=140.1s\n",
            "3\n",
            "[soma_minor | seed=42 | ep=03] loss=0.112 src_acc=0.962 tgt_acc=0.614 time=86.2s\n",
            "4\n",
            "[soma_minor | seed=42 | ep=04] loss=0.107 src_acc=0.964 tgt_acc=0.599 time=64.3s\n",
            "5\n",
            "[soma_minor | seed=42 | ep=05] loss=0.082 src_acc=0.971 tgt_acc=0.558 time=55.6s\n",
            "6\n",
            "[soma_minor | seed=42 | ep=06] loss=0.069 src_acc=0.975 tgt_acc=0.624 time=46.1s\n",
            "7\n",
            "[soma_minor | seed=42 | ep=07] loss=0.048 src_acc=0.986 tgt_acc=0.572 time=47.4s\n",
            "8\n",
            "[soma_minor | seed=42 | ep=08] loss=0.049 src_acc=0.986 tgt_acc=0.489 time=43.4s\n",
            "9\n",
            "[soma_minor | seed=42 | ep=09] loss=0.047 src_acc=0.983 tgt_acc=0.595 time=43.8s\n",
            "10\n",
            "[soma_minor | seed=42 | ep=10] loss=0.039 src_acc=0.988 tgt_acc=0.566 time=42.1s\n",
            "11\n",
            "[soma_minor | seed=42 | ep=11] loss=0.032 src_acc=0.991 tgt_acc=0.561 time=42.5s\n",
            "12\n",
            "[soma_minor | seed=42 | ep=12] loss=0.037 src_acc=0.988 tgt_acc=0.510 time=44.2s\n",
            "13\n",
            "[soma_minor | seed=42 | ep=13] loss=0.053 src_acc=0.983 tgt_acc=0.617 time=42.5s\n",
            "14\n",
            "[soma_minor | seed=42 | ep=14] loss=0.026 src_acc=0.992 tgt_acc=0.592 time=42.7s\n",
            "15\n",
            "[soma_minor | seed=42 | ep=15] loss=0.022 src_acc=0.993 tgt_acc=0.612 time=43.4s\n",
            "16\n",
            "[soma_minor | seed=42 | ep=16] loss=0.007 src_acc=0.999 tgt_acc=0.603 time=44.1s\n",
            "17\n",
            "[soma_minor | seed=42 | ep=17] loss=0.020 src_acc=0.993 tgt_acc=0.540 time=42.7s\n",
            "18\n",
            "[soma_minor | seed=42 | ep=18] loss=0.018 src_acc=0.995 tgt_acc=0.507 time=42.8s\n",
            "19\n",
            "[soma_minor | seed=42 | ep=19] loss=0.021 src_acc=0.993 tgt_acc=0.613 time=43.0s\n",
            ">>>\n",
            "soma_minor\n",
            "0\n",
            "[soma_minor | seed=123 | ep=00] loss=0.690 src_acc=0.764 tgt_acc=0.510 time=43.4s\n",
            "1\n",
            "[soma_minor | seed=123 | ep=01] loss=0.229 src_acc=0.923 tgt_acc=0.590 time=42.8s\n",
            "2\n",
            "[soma_minor | seed=123 | ep=02] loss=0.169 src_acc=0.942 tgt_acc=0.602 time=43.5s\n",
            "3\n",
            "[soma_minor | seed=123 | ep=03] loss=0.119 src_acc=0.958 tgt_acc=0.571 time=43.3s\n",
            "4\n",
            "[soma_minor | seed=123 | ep=04] loss=0.098 src_acc=0.969 tgt_acc=0.646 time=43.7s\n",
            "5\n",
            "[soma_minor | seed=123 | ep=05] loss=0.077 src_acc=0.975 tgt_acc=0.575 time=43.3s\n",
            "6\n",
            "[soma_minor | seed=123 | ep=06] loss=0.057 src_acc=0.982 tgt_acc=0.570 time=43.2s\n",
            "7\n",
            "[soma_minor | seed=123 | ep=07] loss=0.060 src_acc=0.980 tgt_acc=0.629 time=43.8s\n",
            "8\n",
            "[soma_minor | seed=123 | ep=08] loss=0.044 src_acc=0.986 tgt_acc=0.574 time=42.8s\n",
            "9\n",
            "[soma_minor | seed=123 | ep=09] loss=0.040 src_acc=0.987 tgt_acc=0.624 time=43.2s\n",
            "10\n",
            "[soma_minor | seed=123 | ep=10] loss=0.056 src_acc=0.979 tgt_acc=0.310 time=42.9s\n",
            "11\n",
            "[soma_minor | seed=123 | ep=11] loss=0.048 src_acc=0.986 tgt_acc=0.411 time=42.7s\n",
            "12\n",
            "[soma_minor | seed=123 | ep=12] loss=0.035 src_acc=0.988 tgt_acc=0.623 time=42.8s\n",
            "13\n",
            "[soma_minor | seed=123 | ep=13] loss=0.046 src_acc=0.987 tgt_acc=0.577 time=42.7s\n",
            "14\n",
            "[soma_minor | seed=123 | ep=14] loss=0.021 src_acc=0.993 tgt_acc=0.472 time=42.8s\n",
            "15\n",
            "[soma_minor | seed=123 | ep=15] loss=0.020 src_acc=0.993 tgt_acc=0.645 time=43.6s\n",
            "16\n",
            "[soma_minor | seed=123 | ep=16] loss=0.026 src_acc=0.992 tgt_acc=0.611 time=43.2s\n",
            "17\n",
            "[soma_minor | seed=123 | ep=17] loss=0.019 src_acc=0.994 tgt_acc=0.592 time=42.6s\n",
            "18\n",
            "[soma_minor | seed=123 | ep=18] loss=0.016 src_acc=0.995 tgt_acc=0.562 time=42.2s\n",
            "19\n",
            "[soma_minor | seed=123 | ep=19] loss=0.021 src_acc=0.993 tgt_acc=0.657 time=42.4s\n",
            ">>>\n",
            "soma_major\n",
            "0\n",
            "[soma_major | seed=42 | ep=00] loss=0.615 src_acc=0.780 tgt_acc=0.540 time=43.4s\n",
            "1\n",
            "[soma_major | seed=42 | ep=01] loss=0.217 src_acc=0.926 tgt_acc=0.567 time=42.3s\n",
            "2\n",
            "[soma_major | seed=42 | ep=02] loss=0.151 src_acc=0.950 tgt_acc=0.569 time=44.3s\n",
            "3\n",
            "[soma_major | seed=42 | ep=03] loss=0.105 src_acc=0.968 tgt_acc=0.609 time=42.7s\n",
            "4\n",
            "[soma_major | seed=42 | ep=04] loss=0.106 src_acc=0.963 tgt_acc=0.624 time=42.5s\n",
            "5\n",
            "[soma_major | seed=42 | ep=05] loss=0.078 src_acc=0.973 tgt_acc=0.586 time=42.4s\n",
            "6\n",
            "[soma_major | seed=42 | ep=06] loss=0.067 src_acc=0.980 tgt_acc=0.601 time=42.3s\n",
            "7\n",
            "[soma_major | seed=42 | ep=07] loss=0.064 src_acc=0.980 tgt_acc=0.570 time=43.0s\n",
            "8\n",
            "[soma_major | seed=42 | ep=08] loss=0.042 src_acc=0.987 tgt_acc=0.527 time=42.9s\n",
            "9\n",
            "[soma_major | seed=42 | ep=09] loss=0.077 src_acc=0.975 tgt_acc=0.566 time=42.5s\n",
            "10\n",
            "[soma_major | seed=42 | ep=10] loss=0.042 src_acc=0.986 tgt_acc=0.586 time=42.6s\n",
            "11\n",
            "[soma_major | seed=42 | ep=11] loss=0.029 src_acc=0.992 tgt_acc=0.650 time=42.7s\n",
            "12\n",
            "[soma_major | seed=42 | ep=12] loss=0.021 src_acc=0.994 tgt_acc=0.561 time=43.1s\n",
            "13\n",
            "[soma_major | seed=42 | ep=13] loss=0.026 src_acc=0.993 tgt_acc=0.637 time=42.6s\n",
            "14\n",
            "[soma_major | seed=42 | ep=14] loss=0.027 src_acc=0.991 tgt_acc=0.657 time=42.9s\n",
            "15\n",
            "[soma_major | seed=42 | ep=15] loss=0.025 src_acc=0.991 tgt_acc=0.537 time=42.7s\n",
            "16\n",
            "[soma_major | seed=42 | ep=16] loss=0.017 src_acc=0.995 tgt_acc=0.655 time=42.7s\n",
            "17\n",
            "[soma_major | seed=42 | ep=17] loss=0.028 src_acc=0.990 tgt_acc=0.700 time=42.6s\n",
            "18\n",
            "[soma_major | seed=42 | ep=18] loss=0.024 src_acc=0.993 tgt_acc=0.601 time=42.1s\n",
            "19\n",
            "[soma_major | seed=42 | ep=19] loss=0.024 src_acc=0.994 tgt_acc=0.667 time=41.9s\n",
            ">>>\n",
            "soma_major\n",
            "0\n",
            "[soma_major | seed=123 | ep=00] loss=0.700 src_acc=0.751 tgt_acc=0.571 time=43.0s\n",
            "1\n",
            "[soma_major | seed=123 | ep=01] loss=0.221 src_acc=0.922 tgt_acc=0.582 time=42.9s\n",
            "2\n",
            "[soma_major | seed=123 | ep=02] loss=0.171 src_acc=0.945 tgt_acc=0.617 time=43.2s\n",
            "3\n",
            "[soma_major | seed=123 | ep=03] loss=0.107 src_acc=0.966 tgt_acc=0.622 time=44.2s\n",
            "4\n",
            "[soma_major | seed=123 | ep=04] loss=0.105 src_acc=0.967 tgt_acc=0.674 time=42.6s\n",
            "5\n",
            "[soma_major | seed=123 | ep=05] loss=0.075 src_acc=0.974 tgt_acc=0.661 time=43.5s\n",
            "6\n",
            "[soma_major | seed=123 | ep=06] loss=0.060 src_acc=0.982 tgt_acc=0.624 time=43.4s\n",
            "7\n",
            "[soma_major | seed=123 | ep=07] loss=0.063 src_acc=0.980 tgt_acc=0.671 time=43.2s\n",
            "8\n",
            "[soma_major | seed=123 | ep=08] loss=0.046 src_acc=0.986 tgt_acc=0.661 time=43.6s\n",
            "9\n",
            "[soma_major | seed=123 | ep=09] loss=0.051 src_acc=0.983 tgt_acc=0.658 time=42.9s\n",
            "10\n",
            "[soma_major | seed=123 | ep=10] loss=0.045 src_acc=0.985 tgt_acc=0.643 time=44.4s\n",
            "11\n",
            "[soma_major | seed=123 | ep=11] loss=0.033 src_acc=0.990 tgt_acc=0.618 time=43.1s\n",
            "12\n",
            "[soma_major | seed=123 | ep=12] loss=0.018 src_acc=0.994 tgt_acc=0.732 time=42.5s\n",
            "13\n",
            "[soma_major | seed=123 | ep=13] loss=0.033 src_acc=0.990 tgt_acc=0.622 time=43.0s\n",
            "14\n",
            "[soma_major | seed=123 | ep=14] loss=0.033 src_acc=0.989 tgt_acc=0.575 time=42.5s\n",
            "15\n",
            "[soma_major | seed=123 | ep=15] loss=0.042 src_acc=0.986 tgt_acc=0.635 time=42.8s\n",
            "16\n",
            "[soma_major | seed=123 | ep=16] loss=0.014 src_acc=0.997 tgt_acc=0.684 time=43.4s\n",
            "17\n",
            "[soma_major | seed=123 | ep=17] loss=0.017 src_acc=0.994 tgt_acc=0.706 time=42.9s\n",
            "18\n",
            "[soma_major | seed=123 | ep=18] loss=0.013 src_acc=0.996 tgt_acc=0.688 time=43.5s\n",
            "19\n",
            "[soma_major | seed=123 | ep=19] loss=0.020 src_acc=0.994 tgt_acc=0.670 time=43.0s\n",
            ">>>\n",
            "random\n",
            "0\n",
            "[random | seed=42 | ep=00] loss=0.617 src_acc=0.791 tgt_acc=0.497 time=43.0s\n",
            "1\n",
            "[random | seed=42 | ep=01] loss=0.227 src_acc=0.923 tgt_acc=0.561 time=42.8s\n",
            "2\n",
            "[random | seed=42 | ep=02] loss=0.150 src_acc=0.950 tgt_acc=0.592 time=42.7s\n",
            "3\n",
            "[random | seed=42 | ep=03] loss=0.105 src_acc=0.966 tgt_acc=0.629 time=42.6s\n",
            "4\n",
            "[random | seed=42 | ep=04] loss=0.111 src_acc=0.962 tgt_acc=0.640 time=42.2s\n",
            "5\n",
            "[random | seed=42 | ep=05] loss=0.081 src_acc=0.969 tgt_acc=0.498 time=43.0s\n",
            "6\n",
            "[random | seed=42 | ep=06] loss=0.052 src_acc=0.986 tgt_acc=0.587 time=42.3s\n",
            "7\n",
            "[random | seed=42 | ep=07] loss=0.052 src_acc=0.982 tgt_acc=0.539 time=42.3s\n",
            "8\n",
            "[random | seed=42 | ep=08] loss=0.059 src_acc=0.981 tgt_acc=0.347 time=42.3s\n",
            "9\n",
            "[random | seed=42 | ep=09] loss=0.050 src_acc=0.984 tgt_acc=0.492 time=42.7s\n",
            "10\n",
            "[random | seed=42 | ep=10] loss=0.032 src_acc=0.990 tgt_acc=0.539 time=43.3s\n",
            "11\n",
            "[random | seed=42 | ep=11] loss=0.028 src_acc=0.991 tgt_acc=0.631 time=43.2s\n",
            "12\n",
            "[random | seed=42 | ep=12] loss=0.034 src_acc=0.989 tgt_acc=0.601 time=42.7s\n",
            "13\n",
            "[random | seed=42 | ep=13] loss=0.031 src_acc=0.990 tgt_acc=0.607 time=42.5s\n",
            "14\n",
            "[random | seed=42 | ep=14] loss=0.017 src_acc=0.994 tgt_acc=0.607 time=41.9s\n",
            "15\n",
            "[random | seed=42 | ep=15] loss=0.008 src_acc=0.998 tgt_acc=0.543 time=42.0s\n",
            "16\n",
            "[random | seed=42 | ep=16] loss=0.010 src_acc=0.997 tgt_acc=0.630 time=42.6s\n",
            "17\n",
            "[random | seed=42 | ep=17] loss=0.026 src_acc=0.993 tgt_acc=0.582 time=41.8s\n",
            "18\n",
            "[random | seed=42 | ep=18] loss=0.018 src_acc=0.994 tgt_acc=0.581 time=41.6s\n",
            "19\n",
            "[random | seed=42 | ep=19] loss=0.017 src_acc=0.995 tgt_acc=0.605 time=42.1s\n",
            ">>>\n",
            "random\n",
            "0\n",
            "[random | seed=123 | ep=00] loss=0.675 src_acc=0.768 tgt_acc=0.507 time=43.1s\n",
            "1\n",
            "[random | seed=123 | ep=01] loss=0.225 src_acc=0.924 tgt_acc=0.550 time=42.3s\n",
            "2\n",
            "[random | seed=123 | ep=02] loss=0.169 src_acc=0.942 tgt_acc=0.600 time=42.9s\n",
            "3\n",
            "[random | seed=123 | ep=03] loss=0.111 src_acc=0.964 tgt_acc=0.552 time=43.0s\n",
            "4\n",
            "[random | seed=123 | ep=04] loss=0.095 src_acc=0.970 tgt_acc=0.626 time=43.1s\n",
            "5\n",
            "[random | seed=123 | ep=05] loss=0.090 src_acc=0.968 tgt_acc=0.570 time=43.0s\n",
            "6\n",
            "[random | seed=123 | ep=06] loss=0.060 src_acc=0.978 tgt_acc=0.625 time=43.3s\n",
            "7\n",
            "[random | seed=123 | ep=07] loss=0.061 src_acc=0.982 tgt_acc=0.586 time=42.4s\n",
            "8\n",
            "[random | seed=123 | ep=08] loss=0.064 src_acc=0.978 tgt_acc=0.566 time=41.8s\n",
            "9\n",
            "[random | seed=123 | ep=09] loss=0.046 src_acc=0.984 tgt_acc=0.639 time=42.0s\n",
            "10\n",
            "[random | seed=123 | ep=10] loss=0.034 src_acc=0.990 tgt_acc=0.502 time=42.6s\n",
            "11\n",
            "[random | seed=123 | ep=11] loss=0.031 src_acc=0.990 tgt_acc=0.521 time=42.8s\n",
            "12\n",
            "[random | seed=123 | ep=12] loss=0.043 src_acc=0.983 tgt_acc=0.579 time=42.1s\n",
            "13\n",
            "[random | seed=123 | ep=13] loss=0.036 src_acc=0.989 tgt_acc=0.592 time=42.2s\n",
            "14\n",
            "[random | seed=123 | ep=14] loss=0.024 src_acc=0.994 tgt_acc=0.506 time=42.5s\n",
            "15\n",
            "[random | seed=123 | ep=15] loss=0.024 src_acc=0.992 tgt_acc=0.518 time=42.3s\n",
            "16\n",
            "[random | seed=123 | ep=16] loss=0.018 src_acc=0.994 tgt_acc=0.470 time=42.4s\n",
            "17\n",
            "[random | seed=123 | ep=17] loss=0.020 src_acc=0.994 tgt_acc=0.639 time=42.2s\n",
            "18\n",
            "[random | seed=123 | ep=18] loss=0.047 src_acc=0.984 tgt_acc=0.537 time=42.3s\n",
            "19\n",
            "[random | seed=123 | ep=19] loss=0.014 src_acc=0.995 tgt_acc=0.677 time=42.6s\n",
            ">>>\n",
            "full_finetune\n",
            "0\n",
            "[full_finetune | seed=42 | ep=00] loss=1.719 src_acc=0.328 tgt_acc=0.485 time=43.5s\n",
            "1\n",
            "[full_finetune | seed=42 | ep=01] loss=0.783 src_acc=0.719 tgt_acc=0.563 time=43.9s\n",
            "2\n",
            "[full_finetune | seed=42 | ep=02] loss=0.432 src_acc=0.854 tgt_acc=0.611 time=44.3s\n",
            "3\n",
            "[full_finetune | seed=42 | ep=03] loss=0.312 src_acc=0.891 tgt_acc=0.641 time=43.4s\n",
            "4\n",
            "[full_finetune | seed=42 | ep=04] loss=0.218 src_acc=0.929 tgt_acc=0.646 time=44.2s\n",
            "5\n",
            "[full_finetune | seed=42 | ep=05] loss=0.175 src_acc=0.940 tgt_acc=0.585 time=42.8s\n",
            "6\n",
            "[full_finetune | seed=42 | ep=06] loss=0.151 src_acc=0.953 tgt_acc=0.681 time=43.9s\n",
            "7\n",
            "[full_finetune | seed=42 | ep=07] loss=0.139 src_acc=0.954 tgt_acc=0.750 time=44.8s\n",
            "8\n",
            "[full_finetune | seed=42 | ep=08] loss=0.133 src_acc=0.956 tgt_acc=0.616 time=44.6s\n",
            "9\n",
            "[full_finetune | seed=42 | ep=09] loss=0.112 src_acc=0.963 tgt_acc=0.732 time=42.6s\n",
            "10\n",
            "[full_finetune | seed=42 | ep=10] loss=0.115 src_acc=0.965 tgt_acc=0.669 time=44.1s\n",
            "11\n",
            "[full_finetune | seed=42 | ep=11] loss=0.086 src_acc=0.972 tgt_acc=0.698 time=42.6s\n",
            "12\n",
            "[full_finetune | seed=42 | ep=12] loss=0.087 src_acc=0.971 tgt_acc=0.685 time=42.8s\n",
            "13\n",
            "[full_finetune | seed=42 | ep=13] loss=0.097 src_acc=0.967 tgt_acc=0.668 time=44.0s\n",
            "14\n",
            "[full_finetune | seed=42 | ep=14] loss=0.078 src_acc=0.975 tgt_acc=0.597 time=42.8s\n",
            "15\n",
            "[full_finetune | seed=42 | ep=15] loss=0.082 src_acc=0.975 tgt_acc=0.724 time=42.4s\n",
            "16\n",
            "[full_finetune | seed=42 | ep=16] loss=0.097 src_acc=0.970 tgt_acc=0.739 time=42.9s\n",
            "17\n",
            "[full_finetune | seed=42 | ep=17] loss=0.070 src_acc=0.978 tgt_acc=0.653 time=42.5s\n",
            "18\n",
            "[full_finetune | seed=42 | ep=18] loss=0.054 src_acc=0.980 tgt_acc=0.618 time=43.3s\n",
            "19\n",
            "[full_finetune | seed=42 | ep=19] loss=0.044 src_acc=0.986 tgt_acc=0.659 time=42.5s\n",
            ">>>\n",
            "full_finetune\n",
            "0\n",
            "[full_finetune | seed=123 | ep=00] loss=1.488 src_acc=0.413 tgt_acc=0.488 time=42.4s\n",
            "1\n",
            "[full_finetune | seed=123 | ep=01] loss=0.658 src_acc=0.759 tgt_acc=0.500 time=42.6s\n",
            "2\n",
            "[full_finetune | seed=123 | ep=02] loss=0.433 src_acc=0.858 tgt_acc=0.589 time=44.4s\n",
            "3\n",
            "[full_finetune | seed=123 | ep=03] loss=0.303 src_acc=0.897 tgt_acc=0.591 time=44.5s\n",
            "4\n",
            "[full_finetune | seed=123 | ep=04] loss=0.212 src_acc=0.926 tgt_acc=0.644 time=45.0s\n",
            "5\n",
            "[full_finetune | seed=123 | ep=05] loss=0.203 src_acc=0.931 tgt_acc=0.585 time=42.6s\n",
            "6\n",
            "[full_finetune | seed=123 | ep=06] loss=0.151 src_acc=0.952 tgt_acc=0.545 time=44.2s\n",
            "7\n",
            "[full_finetune | seed=123 | ep=07] loss=0.118 src_acc=0.960 tgt_acc=0.681 time=43.1s\n",
            "8\n",
            "[full_finetune | seed=123 | ep=08] loss=0.128 src_acc=0.959 tgt_acc=0.615 time=43.8s\n",
            "9\n",
            "[full_finetune | seed=123 | ep=09] loss=0.154 src_acc=0.952 tgt_acc=0.599 time=44.5s\n",
            "10\n",
            "[full_finetune | seed=123 | ep=10] loss=0.105 src_acc=0.967 tgt_acc=0.614 time=43.8s\n",
            "11\n",
            "[full_finetune | seed=123 | ep=11] loss=0.067 src_acc=0.978 tgt_acc=0.644 time=45.1s\n",
            "12\n",
            "[full_finetune | seed=123 | ep=12] loss=0.179 src_acc=0.947 tgt_acc=0.675 time=44.2s\n",
            "13\n",
            "[full_finetune | seed=123 | ep=13] loss=0.093 src_acc=0.967 tgt_acc=0.611 time=48.5s\n",
            "14\n",
            "[full_finetune | seed=123 | ep=14] loss=0.109 src_acc=0.966 tgt_acc=0.658 time=44.6s\n",
            "15\n",
            "[full_finetune | seed=123 | ep=15] loss=0.076 src_acc=0.976 tgt_acc=0.715 time=44.7s\n",
            "16\n",
            "[full_finetune | seed=123 | ep=16] loss=0.056 src_acc=0.981 tgt_acc=0.673 time=44.8s\n",
            "17\n",
            "[full_finetune | seed=123 | ep=17] loss=0.069 src_acc=0.978 tgt_acc=0.599 time=45.8s\n",
            "18\n",
            "[full_finetune | seed=123 | ep=18] loss=0.046 src_acc=0.988 tgt_acc=0.705 time=44.2s\n",
            "19\n",
            "[full_finetune | seed=123 | ep=19] loss=0.063 src_acc=0.979 tgt_acc=0.455 time=45.8s\n",
            ">>>\n",
            "deltaW_subspace\n",
            "0\n",
            "[deltaW_subspace | seed=42 | ep=00] loss=0.528 src_acc=0.815 tgt_acc=0.562 time=44.0s\n",
            "1\n",
            "[deltaW_subspace | seed=42 | ep=01] loss=0.216 src_acc=0.930 tgt_acc=0.593 time=43.6s\n",
            "2\n",
            "[deltaW_subspace | seed=42 | ep=02] loss=0.145 src_acc=0.955 tgt_acc=0.622 time=43.9s\n",
            "3\n",
            "[deltaW_subspace | seed=42 | ep=03] loss=0.105 src_acc=0.966 tgt_acc=0.660 time=44.1s\n",
            "4\n",
            "[deltaW_subspace | seed=42 | ep=04] loss=0.100 src_acc=0.964 tgt_acc=0.607 time=44.3s\n",
            "5\n",
            "[deltaW_subspace | seed=42 | ep=05] loss=0.081 src_acc=0.968 tgt_acc=0.615 time=43.1s\n",
            "6\n",
            "[deltaW_subspace | seed=42 | ep=06] loss=0.071 src_acc=0.978 tgt_acc=0.601 time=42.5s\n",
            "7\n",
            "[deltaW_subspace | seed=42 | ep=07] loss=0.048 src_acc=0.983 tgt_acc=0.673 time=43.2s\n",
            "8\n",
            "[deltaW_subspace | seed=42 | ep=08] loss=0.047 src_acc=0.986 tgt_acc=0.533 time=43.3s\n",
            "9\n",
            "[deltaW_subspace | seed=42 | ep=09] loss=0.035 src_acc=0.990 tgt_acc=0.603 time=43.4s\n",
            "10\n",
            "[deltaW_subspace | seed=42 | ep=10] loss=0.050 src_acc=0.985 tgt_acc=0.628 time=43.4s\n",
            "11\n",
            "[deltaW_subspace | seed=42 | ep=11] loss=0.046 src_acc=0.984 tgt_acc=0.677 time=42.3s\n",
            "12\n",
            "[deltaW_subspace | seed=42 | ep=12] loss=0.035 src_acc=0.990 tgt_acc=0.602 time=42.9s\n",
            "13\n",
            "[deltaW_subspace | seed=42 | ep=13] loss=0.034 src_acc=0.987 tgt_acc=0.556 time=45.7s\n",
            "14\n",
            "[deltaW_subspace | seed=42 | ep=14] loss=0.031 src_acc=0.991 tgt_acc=0.666 time=43.2s\n",
            "15\n",
            "[deltaW_subspace | seed=42 | ep=15] loss=0.036 src_acc=0.986 tgt_acc=0.673 time=42.8s\n",
            "16\n",
            "[deltaW_subspace | seed=42 | ep=16] loss=0.014 src_acc=0.996 tgt_acc=0.666 time=43.2s\n",
            "17\n",
            "[deltaW_subspace | seed=42 | ep=17] loss=0.013 src_acc=0.996 tgt_acc=0.613 time=44.1s\n",
            "18\n",
            "[deltaW_subspace | seed=42 | ep=18] loss=0.030 src_acc=0.989 tgt_acc=0.646 time=44.7s\n",
            "19\n",
            "[deltaW_subspace | seed=42 | ep=19] loss=0.028 src_acc=0.991 tgt_acc=0.583 time=43.4s\n",
            ">>>\n",
            "deltaW_subspace\n",
            "0\n",
            "[deltaW_subspace | seed=123 | ep=00] loss=0.564 src_acc=0.807 tgt_acc=0.471 time=44.1s\n",
            "1\n",
            "[deltaW_subspace | seed=123 | ep=01] loss=0.202 src_acc=0.928 tgt_acc=0.539 time=44.3s\n",
            "2\n",
            "[deltaW_subspace | seed=123 | ep=02] loss=0.163 src_acc=0.945 tgt_acc=0.517 time=44.7s\n",
            "3\n",
            "[deltaW_subspace | seed=123 | ep=03] loss=0.110 src_acc=0.964 tgt_acc=0.515 time=43.7s\n",
            "4\n",
            "[deltaW_subspace | seed=123 | ep=04] loss=0.092 src_acc=0.967 tgt_acc=0.548 time=43.2s\n",
            "5\n",
            "[deltaW_subspace | seed=123 | ep=05] loss=0.081 src_acc=0.972 tgt_acc=0.554 time=44.0s\n",
            "6\n",
            "[deltaW_subspace | seed=123 | ep=06] loss=0.046 src_acc=0.985 tgt_acc=0.536 time=43.9s\n",
            "7\n",
            "[deltaW_subspace | seed=123 | ep=07] loss=0.061 src_acc=0.980 tgt_acc=0.575 time=44.0s\n",
            "8\n",
            "[deltaW_subspace | seed=123 | ep=08] loss=0.047 src_acc=0.985 tgt_acc=0.516 time=44.0s\n",
            "9\n",
            "[deltaW_subspace | seed=123 | ep=09] loss=0.053 src_acc=0.985 tgt_acc=0.511 time=42.9s\n",
            "10\n",
            "[deltaW_subspace | seed=123 | ep=10] loss=0.059 src_acc=0.983 tgt_acc=0.569 time=43.2s\n",
            "11\n",
            "[deltaW_subspace | seed=123 | ep=11] loss=0.043 src_acc=0.987 tgt_acc=0.514 time=42.2s\n",
            "12\n",
            "[deltaW_subspace | seed=123 | ep=12] loss=0.027 src_acc=0.990 tgt_acc=0.607 time=42.2s\n",
            "13\n",
            "[deltaW_subspace | seed=123 | ep=13] loss=0.022 src_acc=0.994 tgt_acc=0.595 time=42.8s\n",
            "14\n",
            "[deltaW_subspace | seed=123 | ep=14] loss=0.023 src_acc=0.993 tgt_acc=0.478 time=42.2s\n",
            "15\n",
            "[deltaW_subspace | seed=123 | ep=15] loss=0.017 src_acc=0.995 tgt_acc=0.592 time=42.6s\n",
            "16\n",
            "[deltaW_subspace | seed=123 | ep=16] loss=0.015 src_acc=0.995 tgt_acc=0.600 time=42.2s\n",
            "17\n",
            "[deltaW_subspace | seed=123 | ep=17] loss=0.025 src_acc=0.991 tgt_acc=0.606 time=42.4s\n",
            "18\n",
            "[deltaW_subspace | seed=123 | ep=18] loss=0.026 src_acc=0.990 tgt_acc=0.579 time=42.1s\n",
            "19\n",
            "[deltaW_subspace | seed=123 | ep=19] loss=0.056 src_acc=0.980 tgt_acc=0.614 time=42.3s\n",
            ">>>\n",
            "yeahhh\n",
            "\n",
            "Saved:\n",
            "/content/drive/MyDrive/SoMA_PACS_E3/e3_adapter_hist_layer3_layer4.csv\n",
            "/content/drive/MyDrive/SoMA_PACS_E3/e3_adapter_summary_layer3_layer4.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Column not found: best_tgt_acc'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2573272143.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m \u001b[0mdf_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"variant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"best_tgt_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"std\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1949\u001b[0m                 \u001b[0;34m\"Use a list instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m             )\n\u001b[0;32m-> 1951\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column not found: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Column not found: best_tgt_acc'"
          ]
        }
      ]
    }
  ]
}