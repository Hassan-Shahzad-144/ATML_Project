{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a18867ea52c4b0ea29e82084950c060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c220f79188ac4394be33deda2a583265",
              "IPY_MODEL_b79526f01e2f448dab075080a04ebaae",
              "IPY_MODEL_35a0582092944ac59835bb68ead7f6d2"
            ],
            "layout": "IPY_MODEL_ca5dad1f37464c488780da199cab258c"
          }
        },
        "c220f79188ac4394be33deda2a583265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58c2694cdd7348599b5e4946b8b80d77",
            "placeholder": "​",
            "style": "IPY_MODEL_affe8c80be864c5f98a710784430a902",
            "value": "Exporting PACS: 100%"
          }
        },
        "b79526f01e2f448dab075080a04ebaae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef87ed7902a4212a80d99d240ea9dc7",
            "max": 9991,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad4b80bab21c4d7fb72dc067bf86ca43",
            "value": 9991
          }
        },
        "35a0582092944ac59835bb68ead7f6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdbc67563ae347158197a13b5cc685a7",
            "placeholder": "​",
            "style": "IPY_MODEL_a5f8b8fadc564a3dafd2c08616b31e61",
            "value": " 9991/9991 [01:36&lt;00:00, 108.53it/s]"
          }
        },
        "ca5dad1f37464c488780da199cab258c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c2694cdd7348599b5e4946b8b80d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "affe8c80be864c5f98a710784430a902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fef87ed7902a4212a80d99d240ea9dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad4b80bab21c4d7fb72dc067bf86ca43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdbc67563ae347158197a13b5cc685a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5f8b8fadc564a3dafd2c08616b31e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 0 — Baseline Training + Spectral Introspection (PACS, ResNet-18)"
      ],
      "metadata": {
        "id": "vDrAutzzqkBJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIljK3tIqWV9",
        "outputId": "eaef3fb9-88bb-4630-9e22-b08824ddb3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ===== Colab / Drive setup =====\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/SoMA_PACS\"\n",
        "import os\n",
        "os.makedirs(PROJECT_ROOT, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install datasets huggingface_hub pillow\n"
      ],
      "metadata": {
        "id": "rDyYBQY4voPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "VYUqDWR9vvuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os\n",
        "\n",
        "PACS_ROOT = \"/content/drive/MyDrive/NEW_PACS/PACS\"\n",
        "assert \"PACS\" in PACS_ROOT\n",
        "if not os.path.exists(PACS_ROOT):\n",
        "    os.makedirs(PACS_ROOT, exist_ok=True)\n",
        "    print(\"Created PACS folder.\")\n",
        "else:\n",
        "    print(\"PACS folder exists. Skipping deletion.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTAgGoZI9NQK",
        "outputId": "d79abb30-8e11-4321-951e-43d5f5710a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created PACS folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "\n",
        "ds = load_dataset(\"flwrlabs/pacs\")\n",
        "\n",
        "DOMAIN_MAP = {\n",
        "    \"photo\": \"photo\",\n",
        "    \"art_painting\": \"art_painting\",\n",
        "    \"cartoon\": \"cartoon\",\n",
        "    \"sketch\": \"sketch\",\n",
        "}\n",
        "\n",
        "def safe(s):\n",
        "    return str(s).strip().lower().replace(\" \", \"_\")\n",
        "\n",
        "# Per-domain counters to ensure unique filenames\n",
        "counters = {d: { } for d in DOMAIN_MAP.values()}\n",
        "\n",
        "for ex in tqdm(ds[\"train\"], desc=\"Exporting PACS\"):\n",
        "    img = ex[\"image\"]\n",
        "\n",
        "    domain = ex[\"domain\"]\n",
        "    label  = ex[\"label\"]\n",
        "\n",
        "    if not isinstance(domain, str):\n",
        "        domain = ds[\"train\"].features[\"domain\"].int2str(domain)\n",
        "    if not isinstance(label, str):\n",
        "        label = ds[\"train\"].features[\"label\"].int2str(label)\n",
        "\n",
        "    domain = DOMAIN_MAP[safe(domain)]\n",
        "    label  = safe(label)\n",
        "\n",
        "    # initialize counter\n",
        "    counters[domain].setdefault(label, 0)\n",
        "    idx = counters[domain][label]\n",
        "    counters[domain][label] += 1\n",
        "\n",
        "    out_dir = os.path.join(PACS_ROOT, domain, label)\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    out_path = os.path.join(out_dir, f\"{label}_{idx:05d}.jpg\")\n",
        "    img.save(out_path, quality=95)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176,
          "referenced_widgets": [
            "3a18867ea52c4b0ea29e82084950c060",
            "c220f79188ac4394be33deda2a583265",
            "b79526f01e2f448dab075080a04ebaae",
            "35a0582092944ac59835bb68ead7f6d2",
            "ca5dad1f37464c488780da199cab258c",
            "58c2694cdd7348599b5e4946b8b80d77",
            "affe8c80be864c5f98a710784430a902",
            "fef87ed7902a4212a80d99d240ea9dc7",
            "ad4b80bab21c4d7fb72dc067bf86ca43",
            "bdbc67563ae347158197a13b5cc685a7",
            "a5f8b8fadc564a3dafd2c08616b31e61"
          ]
        },
        "id": "gZclgg-4v4Rv",
        "outputId": "2a289979-eb45-4cdd-836f-4d30ea0a5b7f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Exporting PACS:   0%|          | 0/9991 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a18867ea52c4b0ea29e82084950c060"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import os\n",
        "\n",
        "for d in [\"sketch\",\"photo\",\"art_painting\",\"cartoon\"]:\n",
        "    ds = datasets.ImageFolder(os.path.join(PACS_ROOT, d))\n",
        "    print(d, ds.class_to_idx)\n",
        "    assert len(ds.class_to_idx) == 7, f\"{d} does not have 7 classes!\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APKKzaX9v7PE",
        "outputId": "712b4bae-7783-414e-bb3a-420a46045834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sketch {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "photo {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "art_painting {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "cartoon {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import os\n",
        "\n",
        "def get_class_to_idx(domain):\n",
        "    ds = datasets.ImageFolder(root=os.path.join(PACS_ROOT, domain))\n",
        "    return ds.class_to_idx\n",
        "\n",
        "mappings = {d: get_class_to_idx(d) for d in [\"photo\",\"art_painting\",\"cartoon\",\"sketch\"]}\n",
        "for d, m in mappings.items():\n",
        "    print(d, m)\n",
        "\n",
        "# Compare\n",
        "base = mappings[\"photo\"]\n",
        "for d in mappings:\n",
        "    print(d, \"matches photo:\", mappings[d] == base)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLeEk0W78h3U",
        "outputId": "c12d071d-3e7e-4663-bfd9-6a9e566d292e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "photo {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "art_painting {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "cartoon {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "sketch {'dog': 0, 'elephant': 1, 'giraffe': 2, 'guitar': 3, 'horse': 4, 'house': 5, 'person': 6}\n",
            "photo matches photo: True\n",
            "art_painting matches photo: True\n",
            "cartoon matches photo: True\n",
            "sketch matches photo: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Reproducibility =====\n",
        "import random, numpy as np, torch\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# ===== Imports =====\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "B1BKeNMtqweA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== PACS paths (edit if needed) =====\n",
        "PACS_ROOT = \"/content/drive/MyDrive/datasets/PACS\"\n",
        "\n",
        "SOURCE_DOMAINS = [\"photo\", \"art_painting\", \"cartoon\"]\n",
        "TARGET_DOMAIN = \"sketch\"\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n"
      ],
      "metadata": {
        "id": "nyuH-0aNqy94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "test_tf = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "vxXugoPcq68T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_loader(domain, tf, shuffle):\n",
        "    ds = datasets.ImageFolder(\n",
        "        root=os.path.join(PACS_ROOT, domain),\n",
        "        transform=tf\n",
        "    )\n",
        "    return DataLoader(ds, batch_size=BATCH_SIZE,\n",
        "                      shuffle=shuffle, num_workers=NUM_WORKERS)\n",
        "\n",
        "train_loaders = [make_loader(d, train_tf, True) for d in SOURCE_DOMAINS]\n",
        "test_loader = make_loader(TARGET_DOMAIN, test_tf, False)\n"
      ],
      "metadata": {
        "id": "ttQEGt7Wq77l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet18_FeatureHook(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
        "        self.backbone.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "        self._features = {}\n",
        "\n",
        "        def make_hook(name):\n",
        "            def hook(module, inp, out):\n",
        "                self._features[name] = out\n",
        "            return hook\n",
        "\n",
        "        # IMPORTANT: include layer1 now\n",
        "        for lname in [\"layer1\", \"layer2\", \"layer3\", \"layer4\"]:\n",
        "            layer = getattr(self.backbone, lname)\n",
        "            for i, block in enumerate(layer):\n",
        "                block.bn2.register_forward_hook(\n",
        "                    make_hook(f\"{lname}.{i}.bn2\")\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        self._features = {}\n",
        "        return self.backbone(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "l99DjWkirYoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop (Tier-0 backbone)"
      ],
      "metadata": {
        "id": "7Pi4sspmrclb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "DlRWTqesrZmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee44a602-d343-4238-fb8c-177cbd619de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 181MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(loaders):\n",
        "    model.train()\n",
        "    total_loss, total_correct, total = 0, 0, 0\n",
        "\n",
        "    for loader in loaders:\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            total_correct += (logits.argmax(1) == y).sum().item()\n",
        "            total += x.size(0)\n",
        "\n",
        "    return total_loss / total, total_correct / total\n"
      ],
      "metadata": {
        "id": "CLlKwixlri-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_epoch(loader):\n",
        "    model.eval()\n",
        "    total_correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        total_correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += x.size(0)\n",
        "    return total_correct / total\n"
      ],
      "metadata": {
        "id": "2IX_rRa1rmDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"
      ],
      "metadata": {
        "id": "hRN6Rvde_EXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "for ep in range(EPOCHS):\n",
        "    tr_loss, tr_acc = train_epoch(train_loaders)\n",
        "    te_acc = eval_epoch(test_loader)\n",
        "\n",
        "    print(f\"[{ep:02d}] loss={tr_loss:.3f} | src_acc={tr_acc:.3f} | tgt_acc={te_acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p88rTDJTrpo1",
        "outputId": "f40de4a0-4b56-409f-f794-e35982f4c7c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00] loss=0.386 | src_acc=0.874 | tgt_acc=0.661\n",
            "[01] loss=0.213 | src_acc=0.929 | tgt_acc=0.632\n",
            "[02] loss=0.144 | src_acc=0.953 | tgt_acc=0.680\n",
            "[03] loss=0.123 | src_acc=0.958 | tgt_acc=0.652\n",
            "[04] loss=0.085 | src_acc=0.972 | tgt_acc=0.725\n",
            "[05] loss=0.058 | src_acc=0.981 | tgt_acc=0.718\n",
            "[06] loss=0.105 | src_acc=0.967 | tgt_acc=0.733\n",
            "[07] loss=0.063 | src_acc=0.982 | tgt_acc=0.708\n",
            "[08] loss=0.061 | src_acc=0.981 | tgt_acc=0.688\n",
            "[09] loss=0.074 | src_acc=0.976 | tgt_acc=0.754\n",
            "[10] loss=0.031 | src_acc=0.990 | tgt_acc=0.722\n",
            "[11] loss=0.028 | src_acc=0.991 | tgt_acc=0.732\n",
            "[12] loss=0.063 | src_acc=0.979 | tgt_acc=0.699\n",
            "[13] loss=0.044 | src_acc=0.986 | tgt_acc=0.708\n",
            "[14] loss=0.038 | src_acc=0.987 | tgt_acc=0.736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save trained backbone"
      ],
      "metadata": {
        "id": "rhPHDh_2k18U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE_PATH = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "\n",
        "torch.save(model.state_dict(), BACKBONE_PATH)\n",
        "print(\"Saved PACS-trained backbone.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEjSvSJ4kQNh",
        "outputId": "2ce6a611-c9e2-45c0-a00e-28b5740a3cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PACS-trained backbone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TIER 0 — SPECTRAL INTROSPECTION"
      ],
      "metadata": {
        "id": "wzZQ1Auvrz-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy.linalg as LA\n",
        "\n",
        "def conv_svd(conv):\n",
        "    # conv.weight: [C_out, C_in, k, k]\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    Cout = W.shape[0]a\n",
        "    Wmat = W.reshape(Cout, -1)\n",
        "    U, S, Vt = LA.svd(Wmat, full_matrices=False)\n",
        "    return U, S\n"
      ],
      "metadata": {
        "id": "Yi-RCY5grvg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spectra = {}\n",
        "\n",
        "for lname in [\"layer2\", \"layer3\", \"layer4\"]:\n",
        "    for i, block in enumerate(getattr(model.backbone, lname)):\n",
        "        conv = block.conv2\n",
        "        U, S = conv_svd(conv)\n",
        "        spectra[f\"{lname}.{i}\"] = S\n"
      ],
      "metadata": {
        "id": "qjj5dqeur4O7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(f\"{PROJECT_ROOT}/tier0_spectra.pkl\", \"wb\") as f:\n",
        "    pickle.dump(spectra, f)\n"
      ],
      "metadata": {
        "id": "pAuAenK-r5Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-0 Feature Statistics (Energy by Spectral Rank)"
      ],
      "metadata": {
        "id": "LFyi2onlsIIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def collect_feature_energy(loader):\n",
        "    model.eval()\n",
        "    energy = {}\n",
        "\n",
        "    for x, _ in loader:\n",
        "        x = x.to(device)\n",
        "        _ = model(x)\n",
        "\n",
        "        for k, feat in model._features.items():\n",
        "            # GAP → channel vector\n",
        "            h = feat.mean(dim=[2,3])  # [B, C]\n",
        "            e = (h**2).mean(0).cpu().numpy()\n",
        "            energy.setdefault(k, []).append(e)\n",
        "\n",
        "    for k in energy:\n",
        "        energy[k] = np.mean(energy[k], axis=0)\n",
        "\n",
        "    return energy\n"
      ],
      "metadata": {
        "id": "_d_MnlDssABX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_energy = collect_feature_energy(train_loaders[0])\n",
        "tgt_energy = collect_feature_energy(test_loader)\n",
        "\n",
        "with open(f\"{PROJECT_ROOT}/tier0_feature_energy.pkl\", \"wb\") as f:\n",
        "    pickle.dump({\"src\": src_energy, \"tgt\": tgt_energy}, f)\n"
      ],
      "metadata": {
        "id": "vEZ4uVIbsMA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saved to Drive\n",
        "\n",
        "- tier0_spectra.pkl → singular values per conv layer\n",
        "\n",
        "- tier0_feature_energy.pkl → channel-wise activation energy (src vs tgt)\n",
        "\n",
        "- trained baseline checkpoint (implicitly in model state)\n",
        "\n",
        "\n",
        "\n",
        "Scientific baseline\n",
        "\n",
        "- no spectral intervention\n",
        "\n",
        "- no leakage\n",
        "\n",
        "- fixed feature definition\n",
        "\n",
        "- BN explicitly visible"
      ],
      "metadata": {
        "id": "4Luz-YI4scu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 1A — Do Minor Singular Subspaces Encode More Domain Information?"
      ],
      "metadata": {
        "id": "WsT1wwp0E6Ev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the minor singular subspace more domain-specific, while the major subspace is more class-semantic?"
      ],
      "metadata": {
        "id": "IMVoG-GiE_wi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import numpy.linalg as LA"
      ],
      "metadata": {
        "id": "5dPzmaJQssnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{PROJECT_ROOT}/tier0_spectra.pkl\", \"rb\") as f:\n",
        "    spectra = pickle.load(f)\n"
      ],
      "metadata": {
        "id": "P07aEerqFOQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_conv_svd(conv):\n",
        "    \"\"\"\n",
        "    Computes SVD of a conv layer in output-channel space.\n",
        "\n",
        "    conv.weight: [C_out, C_in, k, k]\n",
        "    Returns:\n",
        "        U: [C_out, r]\n",
        "        S: [r]\n",
        "    \"\"\"\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    C_out = W.shape[0]\n",
        "    W_mat = W.reshape(C_out, -1)\n",
        "    U, S, _ = LA.svd(W_mat, full_matrices=False)\n",
        "    return U, S\n",
        "\n"
      ],
      "metadata": {
        "id": "7hpgWpgrFPxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Subspace Bases (Major / Minor / Random)"
      ],
      "metadata": {
        "id": "iGd-88nHFiby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subspace(U, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Returns an orthonormal basis of shape [C_out, r]\n",
        "    \"\"\"\n",
        "    C = U.shape[0]\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    if kind == \"major\":\n",
        "        return U[:, :r]\n",
        "\n",
        "    if kind == \"minor\":\n",
        "        return U[:, -r:]\n",
        "\n",
        "    if kind == \"random\":\n",
        "        Q, _ = np.linalg.qr(rng.standard_normal((C, r)))\n",
        "        return Q\n",
        "\n",
        "    raise ValueError(f\"Unknown subspace kind: {kind}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NMQHtlawFWbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def extract_gap_features(domains, layer_name):\n",
        "    DOMAIN_TO_ID = {\n",
        "        \"photo\": 0,\n",
        "        \"art_painting\": 1,\n",
        "        \"cartoon\": 2,\n",
        "        \"sketch\": 3,\n",
        "    }\n",
        "\n",
        "    X, y_class, y_domain = [], [], []\n",
        "    model.eval()\n",
        "\n",
        "    for domain in domains:\n",
        "        loader = make_loader(domain, test_tf, shuffle=False)\n",
        "        d_id = DOMAIN_TO_ID[domain]\n",
        "\n",
        "        for x, y in loader:\n",
        "            x = x.to(device)\n",
        "            _ = model(x)\n",
        "\n",
        "            feat = model._features[f\"{layer_name}.bn2\"]\n",
        "            h = feat.mean(dim=[2, 3]).cpu().numpy()  # GAP\n",
        "\n",
        "            X.append(h)\n",
        "            y_class.append(y.numpy())\n",
        "            y_domain.append(np.full(h.shape[0], d_id))\n",
        "\n",
        "    return (\n",
        "        np.concatenate(X),\n",
        "        np.concatenate(y_class),\n",
        "        np.concatenate(y_domain),\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "qEgRXkPQhart"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectedDataset(Dataset):\n",
        "    def __init__(self, X, y, Usub):\n",
        "        Z = X @ Usub\n",
        "        self.X = torch.tensor(Z, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n"
      ],
      "metadata": {
        "id": "JkqxrCMGFu5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearProbe(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(in_dim, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "def train_probe(dataset, num_classes, seed=0, epochs=50, train_frac=0.7):\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    n = len(dataset)\n",
        "    n_train = int(train_frac * n)\n",
        "    n_val = n - n_train\n",
        "\n",
        "    train_ds, val_ds = random_split(dataset, [n_train, n_val])\n",
        "    train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "    probe = LinearProbe(dataset.X.shape[1], num_classes).to(device)\n",
        "    opt = torch.optim.Adam(probe.parameters(), lr=1e-2)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        for x, y in train_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss_fn(probe(x), y).backward()\n",
        "            opt.step()\n",
        "\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in val_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = probe(x).argmax(1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "biRDpv3ta-H8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-1.1: Domain probe (core SoMA assumption)"
      ],
      "metadata": {
        "id": "v3DLcM-Th1HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Tier 1.1: Domain Probing --------\n",
        "\n",
        "layers = {\n",
        "    \"layer2.1\": model.backbone.layer2[1].conv2,\n",
        "    \"layer3.1\": model.backbone.layer3[1].conv2,\n",
        "    \"layer4.1\": model.backbone.layer4[1].conv2,\n",
        "}\n",
        "\n",
        "domains = [\"photo\", \"art_painting\", \"cartoon\", \"sketch\"]\n",
        "ranks = [4, 8, 16]\n",
        "seeds = [0, 1, 2]\n",
        "\n",
        "for layer_name, conv in layers.items():\n",
        "    print(f\"\\n=== Domain Probe @ {layer_name} ===\")\n",
        "\n",
        "    U, S = get_conv_svd(conv)\n",
        "    X, _, y_domain = extract_gap_features(domains, model, layer_name)\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"\\nRank {r}\")\n",
        "        for kind in [\"major\", \"minor\", \"random\"]:\n",
        "            accs = []\n",
        "            for seed in seeds:\n",
        "                Usub = get_subspace(U, kind, r, seed)\n",
        "                ds = ProjectedDataset(X, y_domain, Usub)\n",
        "                accs.append(train_probe(ds, num_classes=4, seed=seed))\n",
        "\n",
        "            print(f\"{kind:>6}: {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n"
      ],
      "metadata": {
        "id": "dg55ktTUFwi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ead5cb-0fa5-4af3-e652-3f7571347170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Domain Probe @ layer2.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.678 ± 0.007\n",
            " minor: 0.672 ± 0.003\n",
            "random: 0.624 ± 0.064\n",
            "\n",
            "Rank 8\n",
            " major: 0.752 ± 0.003\n",
            " minor: 0.750 ± 0.003\n",
            "random: 0.792 ± 0.023\n",
            "\n",
            "Rank 16\n",
            " major: 0.842 ± 0.003\n",
            " minor: 0.823 ± 0.003\n",
            "random: 0.826 ± 0.012\n",
            "\n",
            "=== Domain Probe @ layer3.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.704 ± 0.004\n",
            " minor: 0.547 ± 0.013\n",
            "random: 0.659 ± 0.040\n",
            "\n",
            "Rank 8\n",
            " major: 0.775 ± 0.007\n",
            " minor: 0.669 ± 0.010\n",
            "random: 0.714 ± 0.053\n",
            "\n",
            "Rank 16\n",
            " major: 0.800 ± 0.003\n",
            " minor: 0.731 ± 0.007\n",
            "random: 0.822 ± 0.017\n",
            "\n",
            "=== Domain Probe @ layer4.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.535 ± 0.016\n",
            " minor: 0.478 ± 0.004\n",
            "random: 0.583 ± 0.022\n",
            "\n",
            "Rank 8\n",
            " major: 0.654 ± 0.001\n",
            " minor: 0.528 ± 0.012\n",
            "random: 0.622 ± 0.012\n",
            "\n",
            "Rank 16\n",
            " major: 0.730 ± 0.005\n",
            " minor: 0.603 ± 0.010\n",
            "random: 0.708 ± 0.012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-1.2: Class probe (complementary assumption)"
      ],
      "metadata": {
        "id": "gW8TYkvYF01Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- Tier 1.2: Class Probing --------\n",
        "\n",
        "source_domains = [\"photo\", \"art_painting\", \"cartoon\"]\n",
        "\n",
        "for layer_name, conv in layers.items():\n",
        "    print(f\"\\n=== Class Probe @ {layer_name} ===\")\n",
        "\n",
        "    U, S = get_conv_svd(conv)\n",
        "    X, y_class, _ = extract_gap_features(source_domains, model, layer_name)\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"\\nRank {r}\")\n",
        "        for kind in [\"major\", \"minor\", \"random\"]:\n",
        "            accs = []\n",
        "            for seed in seeds:\n",
        "                Usub = get_subspace(U, kind, r, seed)\n",
        "                ds = ProjectedDataset(X, y_class, Usub)\n",
        "                accs.append(train_probe(ds, num_classes=7, seed=seed))\n",
        "\n",
        "            print(f\"{kind:>6}: {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt5vVKjxdieF",
        "outputId": "329f2d70-43c4-4daa-b3d8-b0f0bc20ed2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Class Probe @ layer2.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.245 ± 0.006\n",
            " minor: 0.299 ± 0.002\n",
            "random: 0.288 ± 0.016\n",
            "\n",
            "Rank 8\n",
            " major: 0.336 ± 0.010\n",
            " minor: 0.331 ± 0.004\n",
            "random: 0.361 ± 0.010\n",
            "\n",
            "Rank 16\n",
            " major: 0.402 ± 0.014\n",
            " minor: 0.374 ± 0.005\n",
            "random: 0.422 ± 0.012\n",
            "\n",
            "=== Class Probe @ layer3.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.342 ± 0.012\n",
            " minor: 0.285 ± 0.004\n",
            "random: 0.338 ± 0.012\n",
            "\n",
            "Rank 8\n",
            " major: 0.470 ± 0.002\n",
            " minor: 0.332 ± 0.010\n",
            "random: 0.416 ± 0.018\n",
            "\n",
            "Rank 16\n",
            " major: 0.624 ± 0.005\n",
            " minor: 0.431 ± 0.005\n",
            "random: 0.528 ± 0.013\n",
            "\n",
            "=== Class Probe @ layer4.1 ===\n",
            "\n",
            "Rank 4\n",
            " major: 0.938 ± 0.004\n",
            " minor: 0.471 ± 0.005\n",
            "random: 0.846 ± 0.018\n",
            "\n",
            "Rank 8\n",
            " major: 0.970 ± 0.004\n",
            " minor: 0.704 ± 0.011\n",
            "random: 0.936 ± 0.010\n",
            "\n",
            "Rank 16\n",
            " major: 0.975 ± 0.001\n",
            " minor: 0.821 ± 0.004\n",
            "random: 0.962 ± 0.007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Domain & Class Probe for all layers"
      ],
      "metadata": {
        "id": "ZxBpJHPnFsVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE_PATH = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "\n",
        "model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "\n",
        "state = torch.load(BACKBONE_PATH, map_location=device)\n",
        "model.load_state_dict(state)\n",
        "\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN3jny8JHATp",
        "outputId": "0800642a-914f-4f6b-a89a-c9cdc8db556d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet18_FeatureHook(\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing that the right model was loaded"
      ],
      "metadata": {
        "id": "Gh-QR59d0fpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "te_acc = eval_epoch(test_loader)\n",
        "print(\"Target accuracy:\", te_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGU-IgUhHN9l",
        "outputId": "e9fc85b1-0444-4dc8-e6be-cdfcb2427f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target accuracy: 0.7358106388393993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enumerate all conv2 layers in ResNet-18\n",
        "conv_blocks = {}\n",
        "\n",
        "for lname in [\"layer1\", \"layer2\", \"layer3\", \"layer4\"]:\n",
        "    layer = getattr(model.backbone, lname)\n",
        "    for i, block in enumerate(layer):\n",
        "        key = f\"{lname}.{i}\"\n",
        "        conv_blocks[key] = block.conv2\n"
      ],
      "metadata": {
        "id": "83zN9wzeFzrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domains_all = [\"photo\", \"art_painting\", \"cartoon\", \"sketch\"]\n",
        "domains_source = [\"photo\", \"art_painting\", \"cartoon\"]\n",
        "\n",
        "ranks = [4, 8, 16]\n",
        "seeds = [0, 1, 2]\n"
      ],
      "metadata": {
        "id": "UlOnxCa1GJxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"===== DOMAIN PROBES (ALL CONV BLOCKS) =====\")\n",
        "\n",
        "for layer_name, conv in conv_blocks.items():\n",
        "    print(f\"\\n=== Domain probe @ {layer_name} ===\")\n",
        "\n",
        "    # SVD of this conv layer\n",
        "    U, S = get_conv_svd(conv)\n",
        "\n",
        "    # Extract GAP features\n",
        "    X, _, y_domain = extract_gap_features(domains_all, layer_name)\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"Rank {r}\")\n",
        "        for kind in [\"major\", \"minor\", \"random\"]:\n",
        "            accs = []\n",
        "            for seed in seeds:\n",
        "                Usub = get_subspace(U, kind, r, seed)\n",
        "                ds = ProjectedDataset(X, y_domain, Usub)\n",
        "                accs.append(train_probe(ds, num_classes=4, seed=seed))\n",
        "\n",
        "            print(f\"{kind:>6}: {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-J705EvGNeR",
        "outputId": "67fe1f7f-9790-4093-cbbe-bc09ebc1e34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== DOMAIN PROBES (ALL CONV BLOCKS) =====\n",
            "\n",
            "=== Domain probe @ layer1.0 ===\n",
            "Rank 4\n",
            " major: 0.749 ± 0.004\n",
            " minor: 0.585 ± 0.016\n",
            "random: 0.656 ± 0.031\n",
            "Rank 8\n",
            " major: 0.772 ± 0.004\n",
            " minor: 0.715 ± 0.017\n",
            "random: 0.730 ± 0.026\n",
            "Rank 16\n",
            " major: 0.843 ± 0.004\n",
            " minor: 0.780 ± 0.003\n",
            "random: 0.828 ± 0.014\n",
            "\n",
            "=== Domain probe @ layer1.1 ===\n",
            "Rank 4\n",
            " major: 0.601 ± 0.010\n",
            " minor: 0.617 ± 0.013\n",
            "random: 0.626 ± 0.076\n",
            "Rank 8\n",
            " major: 0.700 ± 0.009\n",
            " minor: 0.706 ± 0.012\n",
            "random: 0.705 ± 0.030\n",
            "Rank 16\n",
            " major: 0.823 ± 0.002\n",
            " minor: 0.797 ± 0.004\n",
            "random: 0.805 ± 0.029\n",
            "\n",
            "=== Domain probe @ layer2.0 ===\n",
            "Rank 4\n",
            " major: 0.607 ± 0.008\n",
            " minor: 0.733 ± 0.015\n",
            "random: 0.661 ± 0.054\n",
            "Rank 8\n",
            " major: 0.739 ± 0.008\n",
            " minor: 0.775 ± 0.010\n",
            "random: 0.791 ± 0.018\n",
            "Rank 16\n",
            " major: 0.835 ± 0.006\n",
            " minor: 0.836 ± 0.007\n",
            "random: 0.836 ± 0.008\n",
            "\n",
            "=== Domain probe @ layer2.1 ===\n",
            "Rank 4\n",
            " major: 0.678 ± 0.007\n",
            " minor: 0.672 ± 0.003\n",
            "random: 0.624 ± 0.064\n",
            "Rank 8\n",
            " major: 0.752 ± 0.003\n",
            " minor: 0.750 ± 0.003\n",
            "random: 0.792 ± 0.023\n",
            "Rank 16\n",
            " major: 0.842 ± 0.003\n",
            " minor: 0.823 ± 0.003\n",
            "random: 0.826 ± 0.012\n",
            "\n",
            "=== Domain probe @ layer3.0 ===\n",
            "Rank 4\n",
            " major: 0.729 ± 0.008\n",
            " minor: 0.520 ± 0.010\n",
            "random: 0.660 ± 0.046\n",
            "Rank 8\n",
            " major: 0.810 ± 0.006\n",
            " minor: 0.636 ± 0.007\n",
            "random: 0.715 ± 0.022\n",
            "Rank 16\n",
            " major: 0.877 ± 0.009\n",
            " minor: 0.764 ± 0.008\n",
            "random: 0.833 ± 0.014\n",
            "\n",
            "=== Domain probe @ layer3.1 ===\n",
            "Rank 4\n",
            " major: 0.704 ± 0.004\n",
            " minor: 0.547 ± 0.013\n",
            "random: 0.659 ± 0.040\n",
            "Rank 8\n",
            " major: 0.775 ± 0.007\n",
            " minor: 0.669 ± 0.010\n",
            "random: 0.714 ± 0.053\n",
            "Rank 16\n",
            " major: 0.800 ± 0.003\n",
            " minor: 0.731 ± 0.007\n",
            "random: 0.822 ± 0.017\n",
            "\n",
            "=== Domain probe @ layer4.0 ===\n",
            "Rank 4\n",
            " major: 0.599 ± 0.002\n",
            " minor: 0.628 ± 0.015\n",
            "random: 0.606 ± 0.057\n",
            "Rank 8\n",
            " major: 0.651 ± 0.003\n",
            " minor: 0.671 ± 0.008\n",
            "random: 0.685 ± 0.009\n",
            "Rank 16\n",
            " major: 0.783 ± 0.004\n",
            " minor: 0.752 ± 0.004\n",
            "random: 0.783 ± 0.011\n",
            "\n",
            "=== Domain probe @ layer4.1 ===\n",
            "Rank 4\n",
            " major: 0.535 ± 0.016\n",
            " minor: 0.478 ± 0.004\n",
            "random: 0.583 ± 0.022\n",
            "Rank 8\n",
            " major: 0.654 ± 0.001\n",
            " minor: 0.528 ± 0.012\n",
            "random: 0.622 ± 0.012\n",
            "Rank 16\n",
            " major: 0.730 ± 0.005\n",
            " minor: 0.603 ± 0.010\n",
            "random: 0.708 ± 0.012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n===== CLASS PROBES (ALL CONV BLOCKS) =====\")\n",
        "\n",
        "for layer_name, conv in conv_blocks.items():\n",
        "    print(f\"\\n=== Class probe @ {layer_name} ===\")\n",
        "\n",
        "    # SVD of this conv layer\n",
        "    U, S = get_conv_svd(conv)\n",
        "\n",
        "    # Extract GAP features (source domains only)\n",
        "    X, y_class, _ = extract_gap_features(domains_source, layer_name)\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"Rank {r}\")\n",
        "        for kind in [\"major\", \"minor\", \"random\"]:\n",
        "            accs = []\n",
        "            for seed in seeds:\n",
        "                Usub = get_subspace(U, kind, r, seed)\n",
        "                ds = ProjectedDataset(X, y_class, Usub)\n",
        "                accs.append(train_probe(ds, num_classes=7, seed=seed))\n",
        "\n",
        "            print(f\"{kind:>6}: {np.mean(accs):.3f} ± {np.std(accs):.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4AmMVb6GU_R",
        "outputId": "6f1e3d6b-b1ac-4dce-cc4c-c9651160274f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== CLASS PROBES (ALL CONV BLOCKS) =====\n",
            "\n",
            "=== Class probe @ layer1.0 ===\n",
            "Rank 4\n",
            " major: 0.299 ± 0.008\n",
            " minor: 0.265 ± 0.007\n",
            "random: 0.278 ± 0.011\n",
            "Rank 8\n",
            " major: 0.332 ± 0.002\n",
            " minor: 0.296 ± 0.003\n",
            "random: 0.326 ± 0.017\n",
            "Rank 16\n",
            " major: 0.394 ± 0.004\n",
            " minor: 0.348 ± 0.013\n",
            "random: 0.366 ± 0.004\n",
            "\n",
            "=== Class probe @ layer1.1 ===\n",
            "Rank 4\n",
            " major: 0.279 ± 0.008\n",
            " minor: 0.236 ± 0.005\n",
            "random: 0.274 ± 0.018\n",
            "Rank 8\n",
            " major: 0.331 ± 0.006\n",
            " minor: 0.292 ± 0.005\n",
            "random: 0.301 ± 0.020\n",
            "Rank 16\n",
            " major: 0.397 ± 0.005\n",
            " minor: 0.363 ± 0.007\n",
            "random: 0.373 ± 0.005\n",
            "\n",
            "=== Class probe @ layer2.0 ===\n",
            "Rank 4\n",
            " major: 0.262 ± 0.012\n",
            " minor: 0.234 ± 0.008\n",
            "random: 0.287 ± 0.017\n",
            "Rank 8\n",
            " major: 0.378 ± 0.009\n",
            " minor: 0.321 ± 0.011\n",
            "random: 0.358 ± 0.019\n",
            "Rank 16\n",
            " major: 0.439 ± 0.007\n",
            " minor: 0.366 ± 0.002\n",
            "random: 0.409 ± 0.005\n",
            "\n",
            "=== Class probe @ layer2.1 ===\n",
            "Rank 4\n",
            " major: 0.245 ± 0.006\n",
            " minor: 0.299 ± 0.002\n",
            "random: 0.288 ± 0.016\n",
            "Rank 8\n",
            " major: 0.336 ± 0.010\n",
            " minor: 0.331 ± 0.004\n",
            "random: 0.361 ± 0.010\n",
            "Rank 16\n",
            " major: 0.402 ± 0.014\n",
            " minor: 0.374 ± 0.005\n",
            "random: 0.422 ± 0.012\n",
            "\n",
            "=== Class probe @ layer3.0 ===\n",
            "Rank 4\n",
            " major: 0.374 ± 0.006\n",
            " minor: 0.265 ± 0.012\n",
            "random: 0.319 ± 0.015\n",
            "Rank 8\n",
            " major: 0.482 ± 0.011\n",
            " minor: 0.344 ± 0.004\n",
            "random: 0.377 ± 0.005\n",
            "Rank 16\n",
            " major: 0.564 ± 0.014\n",
            " minor: 0.407 ± 0.004\n",
            "random: 0.489 ± 0.029\n",
            "\n",
            "=== Class probe @ layer3.1 ===\n",
            "Rank 4\n",
            " major: 0.342 ± 0.012\n",
            " minor: 0.285 ± 0.004\n",
            "random: 0.338 ± 0.012\n",
            "Rank 8\n",
            " major: 0.470 ± 0.002\n",
            " minor: 0.332 ± 0.010\n",
            "random: 0.416 ± 0.018\n",
            "Rank 16\n",
            " major: 0.624 ± 0.005\n",
            " minor: 0.431 ± 0.005\n",
            "random: 0.528 ± 0.013\n",
            "\n",
            "=== Class probe @ layer4.0 ===\n",
            "Rank 4\n",
            " major: 0.546 ± 0.007\n",
            " minor: 0.264 ± 0.012\n",
            "random: 0.390 ± 0.025\n",
            "Rank 8\n",
            " major: 0.810 ± 0.001\n",
            " minor: 0.392 ± 0.012\n",
            "random: 0.583 ± 0.019\n",
            "Rank 16\n",
            " major: 0.928 ± 0.005\n",
            " minor: 0.574 ± 0.001\n",
            "random: 0.727 ± 0.010\n",
            "\n",
            "=== Class probe @ layer4.1 ===\n",
            "Rank 4\n",
            " major: 0.938 ± 0.004\n",
            " minor: 0.471 ± 0.005\n",
            "random: 0.846 ± 0.018\n",
            "Rank 8\n",
            " major: 0.970 ± 0.004\n",
            " minor: 0.704 ± 0.011\n",
            "random: 0.936 ± 0.010\n",
            "Rank 16\n",
            " major: 0.975 ± 0.001\n",
            " minor: 0.821 ± 0.004\n",
            "random: 0.962 ± 0.007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-2: ΔW-Based Domain-Sensitive Subspace Discovery"
      ],
      "metadata": {
        "id": "Ywa9lmNS0G0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy.linalg as LA\n"
      ],
      "metadata": {
        "id": "PC_Z6HLT0JIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GZyeyPNBZ4Q",
        "outputId": "9dbe403f-a3c9-4f86-cd81-c5a8d37e1e49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load frozen Tier-0 backbone"
      ],
      "metadata": {
        "id": "aGgDrzPa6QZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE_PATH = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "\n",
        "def load_base_model():\n",
        "    model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "    state = torch.load(BACKBONE_PATH, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "_tjKt4hz6NSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze BatchNorm running statistics: This prevents BN from silently encoding domain identity."
      ],
      "metadata": {
        "id": "ES6TFCeR6cPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_bn_stats(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            m.eval()                  # freeze running mean/var\n",
        "            m.weight.requires_grad = True\n",
        "            m.bias.requires_grad = True\n"
      ],
      "metadata": {
        "id": "AK1t6si36ZIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class-balanced domain loader - This ensures ΔW reflects domain, not class imbalance.\n",
        "\n"
      ],
      "metadata": {
        "id": "3SbadGn56f0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def make_balanced_loader(domain, tf, batch_size):\n",
        "    ds = datasets.ImageFolder(\n",
        "        root=os.path.join(PACS_ROOT, domain),\n",
        "        transform=tf\n",
        "    )\n",
        "\n",
        "    # group indices by class\n",
        "    class_to_indices = defaultdict(list)\n",
        "    for idx, (_, y) in enumerate(ds.samples):\n",
        "        class_to_indices[y].append(idx)\n",
        "\n",
        "    # sample equal counts per class\n",
        "    min_count = min(len(v) for v in class_to_indices.values())\n",
        "    balanced_indices = []\n",
        "    for v in class_to_indices.values():\n",
        "        balanced_indices.extend(v[:min_count])\n",
        "\n",
        "    sampler = torch.utils.data.SubsetRandomSampler(balanced_indices)\n",
        "\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        sampler=sampler,\n",
        "        num_workers=NUM_WORKERS\n",
        "    )\n"
      ],
      "metadata": {
        "id": "tKH5qw1W6iG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train single-domain model (light adaptation)"
      ],
      "metadata": {
        "id": "KRJsL0OS6tMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_single_domain(domain, epochs=2, lr=1e-4):\n",
        "    model = load_base_model()\n",
        "    freeze_bn_stats(model)\n",
        "\n",
        "    loader = make_balanced_loader(domain, train_tf, BATCH_SIZE)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(x), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Note:\n",
        "\n",
        "# Few epochs\n",
        "\n",
        "# Small learning rate\n",
        "\n",
        "# No over-fitting\n",
        "\n",
        "# This captures early domain pressure.\n"
      ],
      "metadata": {
        "id": "NFmjvh_J6tnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract ΔW for a convolutional layer - ΔW lives in exactly the same space as Tier-1 SVD."
      ],
      "metadata": {
        "id": "bEq6f_nj6wBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_delta_W(base_model, adapted_model, conv_path):\n",
        "    \"\"\"\n",
        "    conv_path example: (\"layer3\", 1, \"conv2\")\n",
        "    \"\"\"\n",
        "    base_conv = getattr(\n",
        "        getattr(base_model.backbone, conv_path[0])[conv_path[1]],\n",
        "        conv_path[2]\n",
        "    )\n",
        "\n",
        "    adapt_conv = getattr(\n",
        "        getattr(adapted_model.backbone, conv_path[0])[conv_path[1]],\n",
        "        conv_path[2]\n",
        "    )\n",
        "\n",
        "    W0 = base_conv.weight.detach().cpu().numpy()\n",
        "    W1 = adapt_conv.weight.detach().cpu().numpy()\n",
        "\n",
        "    dW = W1 - W0\n",
        "    C_out = dW.shape[0]\n",
        "    return dW.reshape(C_out, -1)\n"
      ],
      "metadata": {
        "id": "bqoG4KAD681y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collect ΔW across domains"
      ],
      "metadata": {
        "id": "gRO0cBHT7GeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Layer1 is intentionally excluded because it mostly captures low-level visual primitives (edges, textures), where ΔW is dominated by generic statistics rather than domain-specific adaptation.\n",
        "\n",
        "conv_layers = {\n",
        "    \"layer2.1\": (\"layer2\", 1, \"conv2\"),\n",
        "    \"layer3.1\": (\"layer3\", 1, \"conv2\"),\n",
        "    \"layer4.1\": (\"layer4\", 1, \"conv2\"),\n",
        "}\n",
        "\n",
        "base_model = load_base_model()\n",
        "deltaWs = {k: [] for k in conv_layers}\n",
        "\n",
        "for domain in SOURCE_DOMAINS:\n",
        "    print(f\"Adapting to domain: {domain}\")\n",
        "    adapted = train_single_domain(domain)\n",
        "\n",
        "    for lname, path in conv_layers.items():\n",
        "        dW = extract_delta_W(base_model, adapted, path)\n",
        "        deltaWs[lname].append(dW)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD3T8SFm7G6t",
        "outputId": "556698b7-c64f-40cb-9ad4-07f6e64b3975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapting to domain: photo\n",
            "Adapting to domain: art_painting\n",
            "Adapting to domain: cartoon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "SAVE_PATH = f\"{PROJECT_ROOT}/tier2_deltaWs_source.npz\"\n",
        "\n",
        "np.savez(\n",
        "    SAVE_PATH,\n",
        "    **{\n",
        "        f\"{lname}_{i}\": dW\n",
        "        for lname, dW_list in deltaWs.items()\n",
        "        for i, dW in enumerate(dW_list)\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Saved raw ΔW matrices to:\", SAVE_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DIU2mRishWI",
        "outputId": "6705e785-68a5-400a-b2f9-cf9f4e5469b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved raw ΔW matrices to: /content/drive/MyDrive/SoMA_PACS/tier2_deltaWs_source.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_deltaWs(path, conv_layers, num_domains=3):\n",
        "    data = np.load(path)\n",
        "    deltaWs = {lname: [] for lname in conv_layers}\n",
        "\n",
        "    for lname in conv_layers:\n",
        "        for i in range(num_domains):\n",
        "            deltaWs[lname].append(data[f\"{lname}_{i}\"])\n",
        "\n",
        "    return deltaWs\n",
        "\n",
        "deltaWs = load_deltaWs(\n",
        "    f\"{PROJECT_ROOT}/tier2_deltaWs_source.npz\",\n",
        "    conv_layers,\n",
        "    num_domains=len(SOURCE_DOMAINS)\n",
        ")\n",
        "\n",
        "print(\"Loaded ΔW matrices from disk.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHgEwJLRsmvp",
        "outputId": "2b3a7ff3-a0db-4fa6-fba4-320d1626b771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded ΔW matrices from disk.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez(\n",
        "    f\"{PROJECT_ROOT}/tier2_deltaW_subspaces.npz\",\n",
        "    **{\n",
        "        f\"{lname}_U\": U\n",
        "        for lname, (U, S) in delta_subspaces.items()\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Saved ΔW subspaces.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddVDF9NYsrGz",
        "outputId": "6de8bfc6-75ba-4aeb-e663-9076516d4bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved ΔW subspaces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_deltaW_subspaces(path, conv_layers):\n",
        "    data = np.load(path)\n",
        "    return {\n",
        "        lname: (data[f\"{lname}_U\"], None)\n",
        "        for lname in conv_layers\n",
        "    }\n",
        "\n",
        "delta_subspaces = load_deltaW_subspaces(\n",
        "    f\"{PROJECT_ROOT}/tier2_deltaW_subspaces.npz\",\n",
        "    conv_layers\n",
        ")\n",
        "\n",
        "print(\"Loaded ΔW subspaces.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-Q8XXNhssxU",
        "outputId": "5ffd3eeb-12b1-4768-8c1c-9f3f98fbb2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded ΔW subspaces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier-2.2 — Empirical Domain-Sensitive Subspace (Channel Space)"
      ],
      "metadata": {
        "id": "i5_587V-MmWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build channel–channel covariance from ΔW"
      ],
      "metadata": {
        "id": "boPFkp4R6DPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_deltaW_channel_subspace(dW_list):\n",
        "    \"\"\"\n",
        "    dW_list: list of ΔW matrices for one layer\n",
        "             each ΔW has shape [C_out, D]\n",
        "\n",
        "    Returns:\n",
        "        U_domain: [C_out, C_out] eigenvectors (descending order)\n",
        "        S_domain: eigenvalues\n",
        "    \"\"\"\n",
        "    C_out = dW_list[0].shape[0]\n",
        "    C = np.zeros((C_out, C_out))\n",
        "\n",
        "    for dW in dW_list:\n",
        "        C += dW @ dW.T   # channel-channel covariance\n",
        "\n",
        "    # Eigen-decomposition (symmetric PSD matrix)\n",
        "    eigvals, eigvecs = np.linalg.eigh(C)\n",
        "\n",
        "    # Sort descending\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "    eigvals = eigvals[idx]\n",
        "    eigvecs = eigvecs[:, idx]\n",
        "\n",
        "    return eigvecs, eigvals\n"
      ],
      "metadata": {
        "id": "OrB-hf-y5goB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construct ΔW domain subspaces per layer"
      ],
      "metadata": {
        "id": "XHJie84q6UnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delta_subspaces = {}\n",
        "\n",
        "for lname, dW_list in deltaWs.items():\n",
        "    U_domain, S_domain = build_deltaW_channel_subspace(dW_list)\n",
        "    delta_subspaces[lname] = (U_domain, S_domain)\n",
        "\n",
        "print(\"Constructed empirical ΔW domain-sensitive subspaces.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwtdmJpS6WAJ",
        "outputId": "b671a339-2580-4c84-9bde-30b2131d50db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constructed empirical ΔW domain-sensitive subspaces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E2.3 — ALIGNMENT WITH SoMA MINOR SUBSPACE"
      ],
      "metadata": {
        "id": "vXDqlmSc7ukm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SoMA subspace constructor"
      ],
      "metadata": {
        "id": "kc5Wea0b757J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_soma_subspace(conv, kind, r):\n",
        "#     \"\"\"\n",
        "#     kind: 'minor', 'major', or 'random'\n",
        "#     Returns: [C_out, r] orthonormal basis\n",
        "#     \"\"\"\n",
        "#     W = conv.weight.detach().cpu().numpy()\n",
        "#     C_out = W.shape[0]\n",
        "#     Wmat = W.reshape(C_out, -1)\n",
        "\n",
        "#     U, S, _ = np.linalg.svd(Wmat, full_matrices=False)\n",
        "\n",
        "#     if kind == \"minor\":\n",
        "#         return U[:, -r:]\n",
        "#     if kind == \"major\":\n",
        "#         return U[:, :r]\n",
        "#     if kind == \"random\":\n",
        "#         Q, _ = np.linalg.qr(np.random.randn(C_out, r))\n",
        "#         return Q\n",
        "\n",
        "#     raise ValueError"
      ],
      "metadata": {
        "id": "e1v9raWM7_Be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alignment metric computation"
      ],
      "metadata": {
        "id": "8fu_nFtrO1TC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_alignment_metrics(U, V):\n",
        "    \"\"\"\n",
        "    U, V: [C_out, r] orthonormal basis matrices\n",
        "\n",
        "    Returns:\n",
        "        mean_angle_deg\n",
        "        overlap (mean cos^2)\n",
        "        projection_energy\n",
        "    \"\"\"\n",
        "    # Cross-subspace matrix\n",
        "    M = U.T @ V   # [r, r]\n",
        "\n",
        "    # Singular values = cos(theta_i)\n",
        "    sv = np.linalg.svd(M, compute_uv=False)\n",
        "    sv = np.clip(sv, -1.0, 1.0)\n",
        "\n",
        "    # Principal angles (degrees)\n",
        "    angles = np.degrees(np.arccos(sv))\n",
        "    mean_angle = angles.mean()\n",
        "\n",
        "    # Overlap (mean squared cosine)\n",
        "    overlap = np.mean(sv ** 2)\n",
        "\n",
        "    # Projection energy (equivalent to overlap)\n",
        "    proj_energy = np.linalg.norm(M, ord=\"fro\") ** 2 / V.shape[1]\n",
        "\n",
        "    return mean_angle, overlap, proj_energy\n"
      ],
      "metadata": {
        "id": "ePq6nYeOMn6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alignment sweep (SoMA vs ΔW)"
      ],
      "metadata": {
        "id": "qmpikXX0O4iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build conv_blocks mapping (SoMA reference layers)\n",
        "\n",
        "conv_layers = {\n",
        "    \"layer2.1\": (\"layer2\", 1, \"conv2\"),\n",
        "    \"layer3.1\": (\"layer3\", 1, \"conv2\"),\n",
        "    \"layer4.1\": (\"layer4\", 1, \"conv2\"),\n",
        "}\n",
        "base_model = load_base_model()\n",
        "conv_blocks = {\n",
        "    \"layer2.1\": base_model.backbone.layer2[1].conv2,\n",
        "    \"layer3.1\": base_model.backbone.layer3[1].conv2,\n",
        "    \"layer4.1\": base_model.backbone.layer4[1].conv2,\n",
        "}\n",
        "\n",
        "print(\"Defined conv_blocks:\", list(conv_blocks.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bWXt9OqNuCj",
        "outputId": "4662a18e-63b8-4852-b579-afd69aebbdcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined conv_blocks: ['layer2.1', 'layer3.1', 'layer4.1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = [2, 4, 8, 16]\n",
        "n_random = 10\n",
        "\n",
        "alignment_results = {}\n",
        "\n",
        "for lname, (U_domain, S_domain) in delta_subspaces.items():\n",
        "    print(f\"\\n=== Alignment @ {lname} ===\")\n",
        "    alignment_results[lname] = {}\n",
        "\n",
        "    conv = conv_blocks[lname]\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"\\nRank {r}\")\n",
        "        V = U_domain[:, :r]   # empirical ΔW subspace\n",
        "\n",
        "        alignment_results[lname][r] = {}\n",
        "\n",
        "        for kind in [\"minor\", \"major\", \"random\"]:\n",
        "            angles, overlaps, energies = [], [], []\n",
        "\n",
        "            for seed in range(n_random):\n",
        "                np.random.seed(seed)\n",
        "                U = get_soma_subspace(conv, kind, r)\n",
        "\n",
        "                mean_angle, overlap, proj_energy = compute_alignment_metrics(U, V)\n",
        "\n",
        "                angles.append(mean_angle)\n",
        "                overlaps.append(overlap)\n",
        "                energies.append(proj_energy)\n",
        "\n",
        "            alignment_results[lname][r][kind] = {\n",
        "                \"mean_angle_deg\": (np.mean(angles), np.std(angles)),\n",
        "                \"overlap\": (np.mean(overlaps), np.std(overlaps)),\n",
        "                \"proj_energy\": (np.mean(energies), np.std(energies)),\n",
        "            }\n",
        "\n",
        "            print(\n",
        "                f\"{kind:>6} | \"\n",
        "                f\"angle={np.mean(angles):.2f}° ± {np.std(angles):.2f} | \"\n",
        "                f\"overlap={np.mean(overlaps):.3f} ± {np.std(overlaps):.3f} | \"\n",
        "                f\"energy={np.mean(energies):.3f} ± {np.std(energies):.3f}\"\n",
        "            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xt7dxH-O6sP",
        "outputId": "303e593b-8cfb-476b-981f-a222e10e8261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Alignment @ layer2.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=88.70° ± 0.00 | overlap=0.001 ± 0.000 | energy=0.001 ± 0.000\n",
            " major | angle=71.25° ± 0.00 | overlap=0.123 ± 0.000 | energy=0.123 ± 0.000\n",
            "random | angle=84.26° ± 2.56 | overlap=0.014 ± 0.011 | energy=0.014 ± 0.011\n",
            "\n",
            "Rank 4\n",
            " minor | angle=84.59° ± 0.00 | overlap=0.012 ± 0.000 | energy=0.012 ± 0.000\n",
            " major | angle=75.95° ± 0.00 | overlap=0.085 ± 0.000 | energy=0.085 ± 0.000\n",
            "random | angle=81.61° ± 1.29 | overlap=0.031 ± 0.009 | energy=0.031 ± 0.009\n",
            "\n",
            "Rank 8\n",
            " minor | angle=82.35° ± 0.00 | overlap=0.024 ± 0.000 | energy=0.024 ± 0.000\n",
            " major | angle=70.81° ± 0.00 | overlap=0.146 ± 0.000 | energy=0.146 ± 0.000\n",
            "random | angle=77.92° ± 1.28 | overlap=0.061 ± 0.012 | energy=0.061 ± 0.012\n",
            "\n",
            "Rank 16\n",
            " minor | angle=78.92° ± 0.00 | overlap=0.051 ± 0.000 | energy=0.051 ± 0.000\n",
            " major | angle=61.52° ± 0.00 | overlap=0.271 ± 0.000 | energy=0.271 ± 0.000\n",
            "random | angle=72.06° ± 0.96 | overlap=0.125 ± 0.012 | energy=0.125 ± 0.012\n",
            "\n",
            "=== Alignment @ layer3.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=87.03° ± 0.00 | overlap=0.003 ± 0.000 | energy=0.003 ± 0.000\n",
            " major | angle=82.30° ± 0.00 | overlap=0.022 ± 0.000 | energy=0.022 ± 0.000\n",
            "random | angle=85.58° ± 0.98 | overlap=0.008 ± 0.003 | energy=0.008 ± 0.003\n",
            "\n",
            "Rank 4\n",
            " minor | angle=85.59° ± 0.00 | overlap=0.006 ± 0.000 | energy=0.006 ± 0.000\n",
            " major | angle=77.32° ± 0.00 | overlap=0.068 ± 0.000 | energy=0.068 ± 0.000\n",
            "random | angle=84.36° ± 0.96 | overlap=0.015 ± 0.005 | energy=0.015 ± 0.005\n",
            "\n",
            "Rank 8\n",
            " minor | angle=85.12° ± 0.00 | overlap=0.010 ± 0.000 | energy=0.010 ± 0.000\n",
            " major | angle=66.69° ± 0.00 | overlap=0.203 ± 0.000 | energy=0.203 ± 0.000\n",
            "random | angle=81.19° ± 0.76 | overlap=0.033 ± 0.005 | energy=0.033 ± 0.005\n",
            "\n",
            "Rank 16\n",
            " minor | angle=82.40° ± 0.00 | overlap=0.025 ± 0.000 | energy=0.025 ± 0.000\n",
            " major | angle=59.98° ± 0.00 | overlap=0.293 ± 0.000 | energy=0.293 ± 0.000\n",
            "random | angle=77.89° ± 0.33 | overlap=0.061 ± 0.004 | energy=0.061 ± 0.004\n",
            "\n",
            "=== Alignment @ layer4.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=89.54° ± 0.00 | overlap=0.000 ± 0.000 | energy=0.000 ± 0.000\n",
            " major | angle=61.46° ± 0.00 | overlap=0.255 ± 0.000 | energy=0.255 ± 0.000\n",
            "random | angle=87.05° ± 0.94 | overlap=0.005 ± 0.003 | energy=0.005 ± 0.003\n",
            "\n",
            "Rank 4\n",
            " minor | angle=89.50° ± 0.00 | overlap=0.000 ± 0.000 | energy=0.000 ± 0.000\n",
            " major | angle=37.02° ± 0.00 | overlap=0.646 ± 0.000 | energy=0.646 ± 0.000\n",
            "random | angle=86.04° ± 1.08 | overlap=0.007 ± 0.003 | energy=0.007 ± 0.003\n",
            "\n",
            "Rank 8\n",
            " minor | angle=88.71° ± 0.00 | overlap=0.001 ± 0.000 | energy=0.001 ± 0.000\n",
            " major | angle=24.99° ± 0.00 | overlap=0.801 ± 0.000 | energy=0.801 ± 0.000\n",
            "random | angle=83.85° ± 0.32 | overlap=0.016 ± 0.001 | energy=0.016 ± 0.001\n",
            "\n",
            "Rank 16\n",
            " minor | angle=86.35° ± 0.00 | overlap=0.007 ± 0.000 | energy=0.007 ± 0.000\n",
            " major | angle=47.10° ± 0.00 | overlap=0.478 ± 0.000 | energy=0.478 ± 0.000\n",
            "random | angle=81.47° ± 0.31 | overlap=0.031 ± 0.002 | energy=0.031 ± 0.002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Optional) Save results"
      ],
      "metadata": {
        "id": "dQf_z8v1PJ2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "for lname, layer_data in alignment_results.items():\n",
        "    for r, r_data in layer_data.items():\n",
        "        for kind, metrics in r_data.items():\n",
        "            rows.append({\n",
        "                \"layer\": lname,\n",
        "                \"rank\": r,\n",
        "                \"subspace\": kind,\n",
        "                \"mean_angle_deg\": metrics[\"mean_angle_deg\"][0],\n",
        "                \"angle_std\": metrics[\"mean_angle_deg\"][1],\n",
        "                \"overlap\": metrics[\"overlap\"][0],\n",
        "                \"overlap_std\": metrics[\"overlap\"][1],\n",
        "                \"proj_energy\": metrics[\"proj_energy\"][0],\n",
        "                \"energy_std\": metrics[\"proj_energy\"][1],\n",
        "            })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df.to_csv(f\"{PROJECT_ROOT}/tier2_alignment_metrics.csv\", index=False)\n",
        "\n",
        "print(\"Saved Tier-2.3 alignment results.\")"
      ],
      "metadata": {
        "id": "4uVbQ6H7uU-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Adapting baseline model to Sketch domain...\")\n",
        "adapted_sketch = train_single_domain(\"sketch\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJHKeetOiSO3",
        "outputId": "8bee406f-4609-4726-aecb-17310a59dcd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adapting baseline model to Sketch domain...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deltaWs_sketch = {}\n",
        "\n",
        "for lname, path in conv_layers.items():\n",
        "    dW = extract_delta_W(base_model, adapted_sketch, path)\n",
        "    deltaWs_sketch[lname] = dW\n",
        "    print(f\"{lname}: ΔW shape = {dW.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVwJfxVGiSwz",
        "outputId": "75ec2764-27b2-4b41-9b20-709e6a38ab41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer2.1: ΔW shape = (128, 1152)\n",
            "layer3.1: ΔW shape = (256, 2304)\n",
            "layer4.1: ΔW shape = (512, 4608)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Sketch ΔW into a subspace"
      ],
      "metadata": {
        "id": "NTpNbMSZihyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_deltaW_subspace(dW, r):\n",
        "    \"\"\"\n",
        "    Convert ΔW matrix into rank-r subspace via SVD.\n",
        "    \"\"\"\n",
        "    U, S, _ = np.linalg.svd(dW, full_matrices=False)\n",
        "    return U[:, :r]\n"
      ],
      "metadata": {
        "id": "79o_VSLDie6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Align Sketch ΔW subspace with SoMA subspaces"
      ],
      "metadata": {
        "id": "e_LUenC9ir4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = [2, 4, 8, 16]\n",
        "n_random = 10\n",
        "\n",
        "print(\"\\n=== Sketch ΔW vs SoMA Subspace Alignment ===\")\n",
        "\n",
        "sketch_alignment_results = {}\n",
        "\n",
        "for lname in conv_layers:\n",
        "    print(f\"\\n=== Layer {lname} ===\")\n",
        "    sketch_alignment_results[lname] = {}\n",
        "\n",
        "    dW = deltaWs_sketch[lname]\n",
        "    conv = conv_blocks[lname]\n",
        "\n",
        "    for r in ranks:\n",
        "        print(f\"\\nRank {r}\")\n",
        "        sketch_alignment_results[lname][r] = {}\n",
        "\n",
        "        # Sketch ΔW subspace\n",
        "        U_sketch = get_deltaW_subspace(dW, r)\n",
        "\n",
        "        for kind in [\"minor\", \"major\", \"random\"]:\n",
        "            angles, overlaps, energies = [], [], []\n",
        "\n",
        "            for seed in range(n_random):\n",
        "                np.random.seed(seed)\n",
        "\n",
        "                # SoMA subspace\n",
        "                U_soma = get_soma_subspace(conv, kind, r)\n",
        "\n",
        "                mean_angle, overlap, proj_energy = compute_alignment_metrics(\n",
        "                    U_soma, U_sketch\n",
        "                )\n",
        "\n",
        "                angles.append(mean_angle)\n",
        "                overlaps.append(overlap)\n",
        "                energies.append(proj_energy)\n",
        "\n",
        "            sketch_alignment_results[lname][r][kind] = {\n",
        "                \"mean_angle_deg\": (np.mean(angles), np.std(angles)),\n",
        "                \"overlap\": (np.mean(overlaps), np.std(overlaps)),\n",
        "                \"proj_energy\": (np.mean(energies), np.std(energies)),\n",
        "            }\n",
        "\n",
        "            print(\n",
        "                f\"{kind:>6} | \"\n",
        "                f\"angle={np.mean(angles):.2f}° ± {np.std(angles):.2f} | \"\n",
        "                f\"overlap={np.mean(overlaps):.3f} ± {np.std(overlaps):.3f} | \"\n",
        "                f\"energy={np.mean(energies):.3f} ± {np.std(energies):.3f}\"\n",
        "            )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m3r3ymqimvI",
        "outputId": "0393dd77-6625-49f0-d28d-b5a14cdf7142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sketch ΔW vs SoMA Subspace Alignment ===\n",
            "\n",
            "=== Layer layer2.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=86.56° ± 0.00 | overlap=0.006 ± 0.000 | energy=0.006 ± 0.000\n",
            " major | angle=80.82° ± 0.00 | overlap=0.035 ± 0.000 | energy=0.035 ± 0.000\n",
            "random | angle=85.68° ± 1.70 | overlap=0.008 ± 0.006 | energy=0.008 ± 0.006\n",
            "\n",
            "Rank 4\n",
            " minor | angle=84.65° ± 0.00 | overlap=0.014 ± 0.000 | energy=0.014 ± 0.000\n",
            " major | angle=79.65° ± 0.00 | overlap=0.052 ± 0.000 | energy=0.052 ± 0.000\n",
            "random | angle=81.75° ± 1.56 | overlap=0.030 ± 0.011 | energy=0.030 ± 0.011\n",
            "\n",
            "Rank 8\n",
            " minor | angle=81.52° ± 0.00 | overlap=0.033 ± 0.000 | energy=0.033 ± 0.000\n",
            " major | angle=72.98° ± 0.00 | overlap=0.119 ± 0.000 | energy=0.119 ± 0.000\n",
            "random | angle=77.64° ± 1.45 | overlap=0.065 ± 0.014 | energy=0.065 ± 0.014\n",
            "\n",
            "Rank 16\n",
            " minor | angle=77.17° ± 0.00 | overlap=0.072 ± 0.000 | energy=0.072 ± 0.000\n",
            " major | angle=64.74° ± 0.00 | overlap=0.224 ± 0.000 | energy=0.224 ± 0.000\n",
            "random | angle=72.19° ± 0.45 | overlap=0.123 ± 0.005 | energy=0.123 ± 0.005\n",
            "\n",
            "=== Layer layer3.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=85.05° ± 0.00 | overlap=0.008 ± 0.000 | energy=0.008 ± 0.000\n",
            " major | angle=85.64° ± 0.00 | overlap=0.008 ± 0.000 | energy=0.008 ± 0.000\n",
            "random | angle=86.47° ± 1.57 | overlap=0.006 ± 0.005 | energy=0.006 ± 0.005\n",
            "\n",
            "Rank 4\n",
            " minor | angle=86.65° ± 0.00 | overlap=0.006 ± 0.000 | energy=0.006 ± 0.000\n",
            " major | angle=81.91° ± 0.00 | overlap=0.031 ± 0.000 | energy=0.031 ± 0.000\n",
            "random | angle=83.73° ± 1.41 | overlap=0.018 ± 0.007 | energy=0.018 ± 0.007\n",
            "\n",
            "Rank 8\n",
            " minor | angle=84.73° ± 0.00 | overlap=0.013 ± 0.000 | energy=0.013 ± 0.000\n",
            " major | angle=73.54° ± 0.00 | overlap=0.109 ± 0.000 | energy=0.109 ± 0.000\n",
            "random | angle=81.43° ± 0.58 | overlap=0.031 ± 0.005 | energy=0.031 ± 0.005\n",
            "\n",
            "Rank 16\n",
            " minor | angle=82.21° ± 0.00 | overlap=0.026 ± 0.000 | energy=0.026 ± 0.000\n",
            " major | angle=63.72° ± 0.00 | overlap=0.235 ± 0.000 | energy=0.235 ± 0.000\n",
            "random | angle=77.59° ± 0.72 | overlap=0.063 ± 0.006 | energy=0.063 ± 0.006\n",
            "\n",
            "=== Layer layer4.1 ===\n",
            "\n",
            "Rank 2\n",
            " minor | angle=89.81° ± 0.00 | overlap=0.000 ± 0.000 | energy=0.000 ± 0.000\n",
            " major | angle=63.69° ± 0.00 | overlap=0.271 ± 0.000 | energy=0.271 ± 0.000\n",
            "random | angle=86.92° ± 0.80 | overlap=0.004 ± 0.002 | energy=0.004 ± 0.002\n",
            "\n",
            "Rank 4\n",
            " minor | angle=89.34° ± 0.00 | overlap=0.000 ± 0.000 | energy=0.000 ± 0.000\n",
            " major | angle=45.64° ± 0.00 | overlap=0.512 ± 0.000 | energy=0.512 ± 0.000\n",
            "random | angle=85.87° ± 0.78 | overlap=0.007 ± 0.003 | energy=0.007 ± 0.003\n",
            "\n",
            "Rank 8\n",
            " minor | angle=88.17° ± 0.00 | overlap=0.002 ± 0.000 | energy=0.002 ± 0.000\n",
            " major | angle=28.21° ± 0.00 | overlap=0.765 ± 0.000 | energy=0.765 ± 0.000\n",
            "random | angle=83.60° ± 0.43 | overlap=0.017 ± 0.002 | energy=0.017 ± 0.002\n",
            "\n",
            "Rank 16\n",
            " minor | angle=86.14° ± 0.00 | overlap=0.008 ± 0.000 | energy=0.008 ± 0.000\n",
            " major | angle=48.01° ± 0.00 | overlap=0.472 ± 0.000 | energy=0.472 ± 0.000\n",
            "random | angle=81.40° ± 0.47 | overlap=0.031 ± 0.003 | energy=0.031 ± 0.003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if Sketch's ΔW aligns with 3-domain ΔW subspace"
      ],
      "metadata": {
        "id": "MyGin4tUpeOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def project_matrix_onto_subspace(U, dW):\n",
        "    \"\"\"\n",
        "    U  : [C_out, r] subspace basis (3-domain ΔW subspace)\n",
        "    dW : [C_out, D] Sketch ΔW matrix\n",
        "\n",
        "    Returns:\n",
        "        projection_energy (fraction of ΔW energy captured)\n",
        "        effective_angle_deg\n",
        "    \"\"\"\n",
        "    # Project ΔW onto subspace\n",
        "    P = U.T @ dW\n",
        "\n",
        "    proj_energy = (np.linalg.norm(P, ord=\"fro\") ** 2) / \\\n",
        "                  (np.linalg.norm(dW, ord=\"fro\") ** 2)\n",
        "\n",
        "    # Effective angle (for interpretability)\n",
        "    eff_angle = np.degrees(\n",
        "        np.arccos(np.sqrt(np.clip(proj_energy, 0.0, 1.0)))\n",
        "    )\n",
        "\n",
        "    return proj_energy, eff_angle\n"
      ],
      "metadata": {
        "id": "ymnO12Cgpg6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = [2, 4, 8, 16]\n",
        "\n",
        "print(\"\\n=== Sketch ΔW vs 3-Domain ΔW Subspace (Approach B) ===\")\n",
        "\n",
        "sketch_vs_deltaW_results = {}\n",
        "\n",
        "for lname, (U_domain, S_domain) in delta_subspaces.items():\n",
        "    print(f\"\\n=== Layer {lname} ===\")\n",
        "    sketch_vs_deltaW_results[lname] = {}\n",
        "\n",
        "    dW_sketch = deltaWs_sketch[lname]\n",
        "    C_out = dW_sketch.shape[0]\n",
        "\n",
        "    for r in ranks:\n",
        "        U_sub = U_domain[:, :r]\n",
        "\n",
        "        proj_energy, eff_angle = project_matrix_onto_subspace(\n",
        "            U_sub, dW_sketch\n",
        "        )\n",
        "\n",
        "        random_baseline = r / C_out\n",
        "\n",
        "        sketch_vs_deltaW_results[lname][r] = {\n",
        "            \"projection_energy\": proj_energy,\n",
        "            \"effective_angle_deg\": eff_angle,\n",
        "            \"random_baseline\": random_baseline\n",
        "        }\n",
        "\n",
        "        print(\n",
        "            f\"Rank {r:2d} | \"\n",
        "            f\"proj={proj_energy:.3f} | \"\n",
        "            f\"angle={eff_angle:.1f}° | \"\n",
        "            f\"random≈{random_baseline:.3f}\"\n",
        "        )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EnU_vqdprpE",
        "outputId": "57c1c648-f239-43f1-8e25-22e988c5e794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Sketch ΔW vs 3-Domain ΔW Subspace (Approach B) ===\n",
            "\n",
            "=== Layer layer2.1 ===\n",
            "Rank  2 | proj=0.041 | angle=78.4° | random≈0.016\n",
            "Rank  4 | proj=0.097 | angle=71.8° | random≈0.031\n",
            "Rank  8 | proj=0.173 | angle=65.4° | random≈0.062\n",
            "Rank 16 | proj=0.289 | angle=57.5° | random≈0.125\n",
            "\n",
            "=== Layer layer3.1 ===\n",
            "Rank  2 | proj=0.039 | angle=78.6° | random≈0.008\n",
            "Rank  4 | proj=0.083 | angle=73.3° | random≈0.016\n",
            "Rank  8 | proj=0.154 | angle=66.9° | random≈0.031\n",
            "Rank 16 | proj=0.256 | angle=59.6° | random≈0.062\n",
            "\n",
            "=== Layer layer4.1 ===\n",
            "Rank  2 | proj=0.208 | angle=62.8° | random≈0.004\n",
            "Rank  4 | proj=0.482 | angle=46.0° | random≈0.008\n",
            "Rank  8 | proj=0.666 | angle=35.3° | random≈0.016\n",
            "Rank 16 | proj=0.708 | angle=32.7° | random≈0.031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 3.1 — Subspace Swap Experiment"
      ],
      "metadata": {
        "id": "7E_dunLL0JFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np, random\n",
        "\n",
        "def set_seed(seed=0):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(0)\n"
      ],
      "metadata": {
        "id": "4IN9DuBH0Kyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Path to the baseline (source-trained) ResNet-18\n",
        "base_model_path = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "\n",
        "def load_baseline_model(path):\n",
        "    model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "    state = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "7UJnYVkD0NVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_soma_subspace(conv, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Returns an orthonormal basis U [C_out, r]\n",
        "    for the requested subspace of conv2 weights.\n",
        "    \"\"\"\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    C_out = W.shape[0]\n",
        "    Wmat = W.reshape(C_out, -1)\n",
        "\n",
        "    U, S, _ = np.linalg.svd(Wmat, full_matrices=False)\n",
        "\n",
        "    if kind == \"major\":\n",
        "        return U[:, :r]\n",
        "\n",
        "    if kind == \"minor\":\n",
        "        return U[:, -r:]\n",
        "\n",
        "    if kind == \"middle\":\n",
        "        start = (C_out // 2) - (r // 2)\n",
        "        return U[:, start:start + r]\n",
        "\n",
        "    if kind == \"random\":\n",
        "        rng = np.random.default_rng(seed)\n",
        "        Q, _ = np.linalg.qr(rng.standard_normal((C_out, r)))\n",
        "        return Q\n",
        "\n",
        "    raise ValueError(f\"Unknown subspace kind: {kind}\")\n"
      ],
      "metadata": {
        "id": "jxHI4Ajp7-y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Tier-3 Data Loaders =====\n",
        "\n",
        "train_loaders = [\n",
        "    make_balanced_loader(\"photo\", train_tf, BATCH_SIZE),\n",
        "    make_balanced_loader(\"art_painting\", train_tf, BATCH_SIZE),\n",
        "    make_balanced_loader(\"cartoon\", train_tf, BATCH_SIZE),\n",
        "]\n",
        "\n",
        "test_loader = make_loader(\"sketch\", test_tf, shuffle=False)\n",
        "\n",
        "print(\"Tier-3 loaders ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1dKPart2F0s",
        "outputId": "b0472582-0e24-465c-cdf9-46c57dedf12d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tier-3 loaders ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient projection hook (core mechanism)"
      ],
      "metadata": {
        "id": "mPkNYPl70b-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def register_gradient_projection(param, U_np):\n",
        "    \"\"\"\n",
        "    param : torch.nn.Parameter\n",
        "    U_np  : numpy array [C_out, r]\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert once, outside the hook\n",
        "    U = torch.tensor(U_np, dtype=torch.float32, device=param.device)\n",
        "    U.requires_grad_(False)\n",
        "\n",
        "    def hook(grad):\n",
        "        # grad: [C_out, C_in, k, k]\n",
        "        g = grad.view(grad.shape[0], -1)     # [C_out, D]\n",
        "        g_proj = U @ (U.T @ g)               # projection in torch\n",
        "        return g_proj.view_as(grad)\n",
        "\n",
        "    param.register_hook(hook)\n",
        "\n"
      ],
      "metadata": {
        "id": "0QDnj23a0Qgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply subspace constraint to selected layers"
      ],
      "metadata": {
        "id": "LUzdQ18z0fp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_subspace_constraints(model, conv_layers, subspaces):\n",
        "    \"\"\"\n",
        "    subspaces: {layer_name: U (C_out x r)}\n",
        "    \"\"\"\n",
        "    for lname, U in subspaces.items():\n",
        "        layer, idx, conv_name = conv_layers[lname]\n",
        "        conv = getattr(getattr(model.backbone, layer)[idx], conv_name)\n",
        "        register_gradient_projection(conv.weight, U)\n"
      ],
      "metadata": {
        "id": "K6HiUJaM0UtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop (shared across all variants)"
      ],
      "metadata": {
        "id": "bIlCNxDk0kjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_constraints(\n",
        "    model,\n",
        "    train_loaders,\n",
        "    epochs=3,\n",
        "    lr=1e-4\n",
        "):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for ep in range(epochs):\n",
        "        for loader in train_loaders:\n",
        "            for x, y in loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(model(x), y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "id": "Zg9H345N0YsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation (target domain)"
      ],
      "metadata": {
        "id": "j-gx3Ez40paZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        preds = model(x).argmax(1)\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / total\n"
      ],
      "metadata": {
        "id": "d5MwIdKb0mwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = [4, 8, 16]\n",
        "variants = [\"minor\", \"major\", \"middle\", \"random\"]\n",
        "\n",
        "tier3_results = {}\n",
        "\n",
        "for r in ranks:\n",
        "    print(f\"\\n=== Rank {r} ===\")\n",
        "    tier3_results[r] = {}\n",
        "\n",
        "    for variant in variants:\n",
        "        print(f\"\\nVariant: {variant}\")\n",
        "\n",
        "        # 1. Fresh baseline\n",
        "        model = load_baseline_model(base_model_path)\n",
        "\n",
        "        # 2. Build subspaces\n",
        "        subspaces = {}\n",
        "        for lname, (layer, idx, conv_name) in conv_layers.items():\n",
        "            conv = getattr(getattr(model.backbone, layer)[idx], conv_name)\n",
        "            U = get_soma_subspace(conv, variant, r)\n",
        "            subspaces[lname] = U\n",
        "\n",
        "        # 3. Apply constraints\n",
        "        apply_subspace_constraints(model, conv_layers, subspaces)\n",
        "\n",
        "        # 4. Train\n",
        "        train_with_constraints(model, train_loaders)\n",
        "\n",
        "        # 5. Evaluate\n",
        "        acc = eval_accuracy(model, test_loader)\n",
        "        tier3_results[r][variant] = acc\n",
        "\n",
        "        print(f\"Target accuracy: {acc:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGUmZT6v1ACW",
        "outputId": "47bc65ce-e63a-4092-88b0-e72e0cc56391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Rank 4 ===\n",
            "\n",
            "Variant: minor\n",
            "Target accuracy: 0.711\n",
            "\n",
            "Variant: major\n",
            "Target accuracy: 0.744\n",
            "\n",
            "Variant: middle\n",
            "Target accuracy: 0.735\n",
            "\n",
            "Variant: random\n",
            "Target accuracy: 0.728\n",
            "\n",
            "=== Rank 8 ===\n",
            "\n",
            "Variant: minor\n",
            "Target accuracy: 0.658\n",
            "\n",
            "Variant: major\n",
            "Target accuracy: 0.745\n",
            "\n",
            "Variant: middle\n",
            "Target accuracy: 0.717\n",
            "\n",
            "Variant: random\n",
            "Target accuracy: 0.728\n",
            "\n",
            "=== Rank 16 ===\n",
            "\n",
            "Variant: minor\n",
            "Target accuracy: 0.729\n",
            "\n",
            "Variant: major\n",
            "Target accuracy: 0.737\n",
            "\n",
            "Variant: middle\n",
            "Target accuracy: 0.712\n",
            "\n",
            "Variant: random\n",
            "Target accuracy: 0.730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 3.4 — BatchNorm Confound Controls"
      ],
      "metadata": {
        "id": "03pXpiGaBr9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, copy, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def set_seed(seed=0):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "yZNnhPEKBvQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You must have PROJECT_ROOT already\n",
        "base_model_path = f\"{PROJECT_ROOT}/resnet18_pacs_base.pt\"\n",
        "assert os.path.exists(base_model_path), f\"Missing baseline weights at {base_model_path}\"\n",
        "\n",
        "def load_baseline_model():\n",
        "    model = ResNet18_FeatureHook(num_classes=7).to(device)\n",
        "    state = torch.load(base_model_path, map_location=device)\n",
        "    model.load_state_dict(state)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Mc4ppNFNBygn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Uses your existing make_balanced_loader, make_loader, train_tf, test_tf, BATCH_SIZE\n",
        "train_loaders = [\n",
        "    make_balanced_loader(\"photo\", train_tf, BATCH_SIZE),\n",
        "    make_balanced_loader(\"art_painting\", train_tf, BATCH_SIZE),\n",
        "    make_balanced_loader(\"cartoon\", train_tf, BATCH_SIZE),\n",
        "]\n",
        "test_loader = make_loader(\"sketch\", test_tf, shuffle=False)\n",
        "\n",
        "print(\"Tier-3 data loaders ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7CUENHQB0oU",
        "outputId": "04f2ee04-38c5-451e-ebe6-2a6a8c667491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tier-3 data loaders ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_subspace_constraints(model, conv_layers, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Apply gradient projection constraints to conv2 weights.\n",
        "\n",
        "    model       : nn.Module\n",
        "    conv_layers : dict {lname: (layer, idx, conv_name)}\n",
        "    kind        : {\"minor\", \"major\", \"middle\", \"random\"}\n",
        "    r           : rank of subspace\n",
        "    seed        : random seed (used only for 'random')\n",
        "    \"\"\"\n",
        "    for lname, (layer, idx, conv_name) in conv_layers.items():\n",
        "        conv = getattr(getattr(model.backbone, layer)[idx], conv_name)\n",
        "\n",
        "        # get subspace basis (numpy)\n",
        "        U = get_soma_subspace(conv, kind, r, seed=seed)\n",
        "\n",
        "        # register gradient projection hook\n",
        "        register_gradient_projection(conv.weight, U)\n"
      ],
      "metadata": {
        "id": "a4hH2OAeCTvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_bn_mode(model, mode: str):\n",
        "    \"\"\"\n",
        "    mode in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\"}\n",
        "    \"\"\"\n",
        "    assert mode in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\"}\n",
        "\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.BatchNorm2d):\n",
        "            if mode == \"bn_default\":\n",
        "                m.train()  # stats update\n",
        "                m.weight.requires_grad_(True)\n",
        "                m.bias.requires_grad_(True)\n",
        "\n",
        "            elif mode == \"bn_frozen\":\n",
        "                m.eval()   # stats frozen\n",
        "                m.weight.requires_grad_(False)\n",
        "                m.bias.requires_grad_(False)\n",
        "\n",
        "            elif mode == \"bn_affine_only\":\n",
        "                m.eval()   # stats frozen\n",
        "                m.weight.requires_grad_(True)\n",
        "                m.bias.requires_grad_(True)\n",
        "\n",
        "\n",
        "def replace_bn_with_gn(module: nn.Module, num_groups: int = 32):\n",
        "    \"\"\"\n",
        "    Recursively replace all BatchNorm2d layers with GroupNorm.\n",
        "    This removes running-stat confounds entirely.\n",
        "    \"\"\"\n",
        "    for name, child in module.named_children():\n",
        "        if isinstance(child, nn.BatchNorm2d):\n",
        "            num_channels = child.num_features\n",
        "            # GN requires num_channels divisible by num_groups; adjust safely.\n",
        "            g = min(num_groups, num_channels)\n",
        "            while num_channels % g != 0 and g > 1:\n",
        "                g -= 1\n",
        "            gn = nn.GroupNorm(num_groups=g, num_channels=num_channels, affine=True)\n",
        "            setattr(module, name, gn)\n",
        "        else:\n",
        "            replace_bn_with_gn(child, num_groups=num_groups)\n",
        "\n",
        "\n",
        "def apply_norm_config(model, norm_cfg: str):\n",
        "    \"\"\"\n",
        "    norm_cfg in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\", \"groupnorm\"}\n",
        "    \"\"\"\n",
        "    assert norm_cfg in {\"bn_default\", \"bn_frozen\", \"bn_affine_only\", \"groupnorm\"}\n",
        "\n",
        "    if norm_cfg == \"groupnorm\":\n",
        "        replace_bn_with_gn(model)\n",
        "        # GroupNorm has no running stats; keep train mode.\n",
        "        model.train()\n",
        "    else:\n",
        "        set_bn_mode(model, norm_cfg)\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "HxyNA4GkB32l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_soma_subspace(conv, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Returns U basis [C_out, r] as numpy array (orthonormal).\n",
        "    \"\"\"\n",
        "    W = conv.weight.detach().cpu().numpy()\n",
        "    C_out = W.shape[0]\n",
        "    Wmat = W.reshape(C_out, -1)\n",
        "    U, S, _ = np.linalg.svd(Wmat, full_matrices=False)\n",
        "\n",
        "    if kind == \"major\":\n",
        "        return U[:, :r]\n",
        "    if kind == \"minor\":\n",
        "        return U[:, -r:]\n",
        "    if kind == \"middle\":\n",
        "        start = (C_out // 2) - (r // 2)\n",
        "        return U[:, start:start + r]\n",
        "    if kind == \"random\":\n",
        "        rng = np.random.default_rng(seed)\n",
        "        Q, _ = np.linalg.qr(rng.standard_normal((C_out, r)))\n",
        "        return Q\n",
        "\n",
        "    raise ValueError(f\"Unknown kind: {kind}\")\n"
      ],
      "metadata": {
        "id": "IXZsy980B5d6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def register_gradient_projection(param, U_np):\n",
        "    \"\"\"\n",
        "    Project gradient onto span(U).\n",
        "    U_np is numpy [C_out, r].\n",
        "    \"\"\"\n",
        "    U = torch.tensor(U_np, dtype=torch.float32, device=param.device)\n",
        "    U.requires_grad_(False)\n",
        "\n",
        "    def hook(grad):\n",
        "        g = grad.view(grad.shape[0], -1)         # [C_out, D]\n",
        "        g_proj = U @ (U.T @ g)                   # [C_out, D]\n",
        "        return g_proj.view_as(grad)\n",
        "\n",
        "    param.register_hook(hook)\n",
        "\n",
        "\n",
        "def apply_subspace_constraints(model, conv_layers, kind, r, seed=0):\n",
        "    \"\"\"\n",
        "    Apply gradient projection to conv2 weights for selected layers.\n",
        "    conv_layers: dict {lname: (layer, idx, \"conv2\")}\n",
        "    \"\"\"\n",
        "    for lname, (layer, idx, conv_name) in conv_layers.items():\n",
        "        conv = getattr(getattr(model.backbone, layer)[idx], conv_name)\n",
        "        U = get_soma_subspace(conv, kind, r, seed=seed)\n",
        "        register_gradient_projection(conv.weight, U)\n"
      ],
      "metadata": {
        "id": "xXEZg180B87y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def eval_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        pred = model(x).argmax(1)\n",
        "        correct += (pred == y).sum().item()\n",
        "        total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "def train_with_logging(model, train_loaders, epochs=3, lr=1e-4):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    logs = {\n",
        "        \"epoch_loss\": [],\n",
        "        \"grad_norm\": [],\n",
        "        \"update_norm\": [],\n",
        "    }\n",
        "\n",
        "    # snapshot params for update norm\n",
        "    with torch.no_grad():\n",
        "        init_params = {n: p.detach().clone() for n, p in model.named_parameters() if p.requires_grad}\n",
        "\n",
        "    model.train()\n",
        "    for ep in range(epochs):\n",
        "        ep_loss_sum, ep_n = 0.0, 0\n",
        "        grad_norm_sum, grad_n = 0.0, 0\n",
        "\n",
        "        for loader in train_loaders:\n",
        "            for x, y in loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                logits = model(x)\n",
        "                loss = criterion(logits, y)\n",
        "                loss.backward()\n",
        "\n",
        "                # grad norm (after projection, since hooks already applied)\n",
        "                with torch.no_grad():\n",
        "                    total_g = 0.0\n",
        "                    for p in model.parameters():\n",
        "                        if p.grad is not None:\n",
        "                            total_g += p.grad.detach().float().norm().item() ** 2\n",
        "                    grad_norm_sum += total_g ** 0.5\n",
        "                    grad_n += 1\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                ep_loss_sum += loss.item() * x.size(0)\n",
        "                ep_n += x.size(0)\n",
        "\n",
        "        logs[\"epoch_loss\"].append(ep_loss_sum / max(ep_n, 1))\n",
        "        logs[\"grad_norm\"].append(grad_norm_sum / max(grad_n, 1))\n",
        "\n",
        "    # update norm (final minus initial)\n",
        "    with torch.no_grad():\n",
        "        total_u = 0.0\n",
        "        for n, p in model.named_parameters():\n",
        "            if n in init_params:\n",
        "                total_u += (p.detach() - init_params[n]).float().norm().item() ** 2\n",
        "        logs[\"update_norm\"].append(total_u ** 0.5)\n",
        "\n",
        "    return logs\n"
      ],
      "metadata": {
        "id": "SrUCtn62CBSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "norm_cfgs = [\"bn_default\", \"bn_affine_only\", \"bn_frozen\", \"groupnorm\"]\n",
        "subspaces = [\"minor\", \"major\", \"middle\", \"random\"]\n",
        "ranks = [4, 8, 16]\n",
        "seeds = [0, 1, 2]\n",
        "\n",
        "results = []\n",
        "\n",
        "for norm_cfg in norm_cfgs:\n",
        "    for r in ranks:\n",
        "        for kind in subspaces:\n",
        "            for seed in seeds:\n",
        "                set_seed(seed)\n",
        "\n",
        "                # 1) fresh baseline\n",
        "                model = load_baseline_model()\n",
        "\n",
        "                # 2) apply normalization configuration\n",
        "                model = apply_norm_config(model, norm_cfg)\n",
        "\n",
        "                # 3) apply subspace constraint (seed matters for random)\n",
        "                apply_subspace_constraints(model, conv_layers, kind, r, seed=seed)\n",
        "\n",
        "                # 4) train with logging\n",
        "                logs = train_with_logging(model, train_loaders, epochs=3, lr=1e-4)\n",
        "\n",
        "                # 5) eval\n",
        "                acc = eval_accuracy(model, test_loader)\n",
        "\n",
        "                row = {\n",
        "                    \"norm_cfg\": norm_cfg,\n",
        "                    \"rank\": r,\n",
        "                    \"subspace\": kind,\n",
        "                    \"seed\": seed,\n",
        "                    \"target_acc\": acc,\n",
        "                    \"loss_ep0\": logs[\"epoch_loss\"][0] if len(logs[\"epoch_loss\"]) > 0 else None,\n",
        "                    \"loss_ep1\": logs[\"epoch_loss\"][1] if len(logs[\"epoch_loss\"]) > 1 else None,\n",
        "                    \"loss_ep2\": logs[\"epoch_loss\"][2] if len(logs[\"epoch_loss\"]) > 2 else None,\n",
        "                    \"gradnorm_mean\": float(np.mean(logs[\"grad_norm\"])) if len(logs[\"grad_norm\"]) else None,\n",
        "                    \"update_norm\": logs[\"update_norm\"][0] if len(logs[\"update_norm\"]) else None,\n",
        "                }\n",
        "                results.append(row)\n",
        "\n",
        "                print(\n",
        "                    f\"[{norm_cfg}] r={r:2d} {kind:>6} seed={seed} \"\n",
        "                    f\"acc={acc:.3f} loss={logs['epoch_loss'][-1]:.3f} \"\n",
        "                    f\"gn={np.mean(logs['grad_norm']):.3f} upd={logs['update_norm'][0]:.3f}\"\n",
        "                )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYT5NgDxCBw2",
        "outputId": "ef074956-f9aa-4423-e292-6c024cf9c358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[bn_default] r= 4  minor seed=0 acc=0.735 loss=0.005 gn=0.610 upd=4.324\n",
            "[bn_default] r= 4  minor seed=1 acc=0.721 loss=0.007 gn=0.543 upd=4.498\n",
            "[bn_default] r= 4  minor seed=2 acc=0.674 loss=0.006 gn=0.661 upd=4.460\n",
            "[bn_default] r= 4  major seed=0 acc=0.731 loss=0.005 gn=0.654 upd=4.476\n",
            "[bn_default] r= 4  major seed=1 acc=0.733 loss=0.007 gn=0.537 upd=4.586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# Aggregate mean ± std by condition\n",
        "summary = (\n",
        "    df.groupby([\"norm_cfg\", \"rank\", \"subspace\"])\n",
        "      .agg(target_acc_mean=(\"target_acc\", \"mean\"),\n",
        "           target_acc_std=(\"target_acc\", \"std\"),\n",
        "           gradnorm_mean=(\"gradnorm_mean\", \"mean\"),\n",
        "           update_norm_mean=(\"update_norm\", \"mean\"))\n",
        "      .reset_index()\n",
        "      .sort_values([\"norm_cfg\", \"rank\", \"target_acc_mean\"], ascending=[True, True, False])\n",
        ")\n",
        "\n",
        "display(summary)\n",
        "\n",
        "# Save\n",
        "csv_path = f\"{PROJECT_ROOT}/tier3_bn_grid_results.csv\"\n",
        "summary_path = f\"{PROJECT_ROOT}/tier3_bn_grid_summary.csv\"\n",
        "npz_path = f\"{PROJECT_ROOT}/tier3_bn_grid_results.npz\"\n",
        "\n",
        "df.to_csv(csv_path, index=False)\n",
        "summary.to_csv(summary_path, index=False)\n",
        "\n",
        "# also save raw arrays in npz for safe reload\n",
        "np.savez(npz_path, **{f\"row_{i}\": np.array(list(row.values()), dtype=object) for i, row in enumerate(results)})\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\" -\", csv_path)\n",
        "print(\" -\", summary_path)\n",
        "print(\" -\", npz_path)\n"
      ],
      "metadata": {
        "id": "UlSVqH6dCEzc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}